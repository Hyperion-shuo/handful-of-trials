(base) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials/scripts[00m$ conda activate pets2
(pets2) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials/scripts[00m$ ls[K[Kpython[K[K[K[K[K[Kcd ..
(pets2) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials[00m$ ls
[0m[01;34mdmbrl[0m  Dockerfile  [01;34mimg[0m  LICENSE  [01;34mlog[0m  [01;34mplay[0m  plotter.ipynb  README.md  requirements.txt  [01;34mscripts[0m  test.py
(pets2) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials[00m$ python scripts/mbexp.py -env halfcheetah -ca model-type PE -ca prop-type TSinf -ca opt-type CEM -logdir log /halfcheetah_PE_TSinf_CEM
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/gpflow/session_manager.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/gpflow/misc.py:24: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.
  result = entry_point.load(False)
WARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/config/halfcheetah.py:26: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2020-11-25 22:44:27.588017: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-11-25 22:44:27.687318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100005000 Hz
2020-11-25 22:44:27.692392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558b9f6037a0 executing computations on platform Host. Devices:
2020-11-25 22:44:27.692686: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-11-25 22:44:27.717085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-11-25 22:44:30.967333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:04:00.0
2020-11-25 22:44:30.968519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:05:00.0
2020-11-25 22:44:30.969512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:08:00.0
2020-11-25 22:44:30.970469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:09:00.0
2020-11-25 22:44:30.995857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 22:44:31.170787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-11-25 22:44:31.263330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-11-25 22:44:31.300550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-11-25 22:44:31.484244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-11-25 22:44:31.514883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-11-25 22:44:31.865024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-11-25 22:44:31.874347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2020-11-25 22:44:31.879097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 22:44:31.890565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-25 22:44:31.890605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2020-11-25 22:44:31.890617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N N N 
2020-11-25 22:44:31.890628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N N N 
2020-11-25 22:44:31.890653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N N 
2020-11-25 22:44:31.890663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N N N 
2020-11-25 22:44:31.897198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2749 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:04:00.0, compute capability: 7.5)
2020-11-25 22:44:31.901687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7469 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080, pci bus id: 0000:05:00.0, compute capability: 7.5)
2020-11-25 22:44:31.905860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 7469 MB memory) -> physical GPU (device: 2, name: GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5)
2020-11-25 22:44:31.909987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 7469 MB memory) -> physical GPU (device: 3, name: GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5)
2020-11-25 22:44:31.927387: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ba2053e10 executing computations on platform CUDA. Devices:
2020-11-25 22:44:31.927424: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2020-11-25 22:44:31.927439: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce RTX 2080, Compute Capability 7.5
2020-11-25 22:44:31.927456: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): GeForce RTX 2080, Compute Capability 7.5
2020-11-25 22:44:31.927470: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): GeForce RTX 2080, Compute Capability 7.5
{'ctrl_cfg': {'env': <dmbrl.env.half_cheetah.HalfCheetahEnv object at 0x7f2bb007f518>,
              'opt_cfg': {'ac_cost_fn': <function HalfCheetahConfigModule.ac_cost_fn at 0x7f2bb007cd90>,
                          'cfg': {'alpha': 0.1,
                                  'max_iters': 5,
                                  'num_elites': 50,
                                  'popsize': 500},
                          'mode': 'CEM',
                          'obs_cost_fn': <function HalfCheetahConfigModule.obs_cost_fn at 0x7f2bb007cd08>,
                          'plan_hor': 30},
              'prop_cfg': {'mode': 'TSinf',
                           'model_init_cfg': {'model_class': <class 'dmbrl.modeling.models.BNN.BNN'>,
                                              'model_constructor': <bound method HalfCheetahConfigModule.nn_constructor of <halfcheetah.HalfCheetahConfigModule object at 0x7f2bb007f198>>,
                                              'num_nets': 5},
                           'model_train_cfg': {'epochs': 5},
                           'npart': 20,
                           'obs_postproc': <function HalfCheetahConfigModule.obs_postproc at 0x7f2bb007cbf8>,
                           'obs_preproc': <function HalfCheetahConfigModule.obs_preproc at 0x7f2bb007cb70>,
                           'targ_proc': <function HalfCheetahConfigModule.targ_proc at 0x7f2bb007cc80>}},
 'exp_cfg': {'exp_cfg': {'nrollouts_per_iter': 1, 'ntrain_iters': 300},
             'log_cfg': {'logdir': 'log/halfcheetah_PE_TSinf_CEM'},
             'sim_cfg': {'env': <dmbrl.env.half_cheetah.HalfCheetahEnv object at 0x7f2bb007f518>,
                         'task_hor': 1000}}}
Created an ensemble of 5 neural networks with variance predictions.
WARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/config/halfcheetah.py:83: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/modeling/models/BNN.py:158: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/modeling/utils/TensorStandardScaler.py:22: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[AWARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/controllers/MPC.py:322: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Created an MPC controller, prop mode TSinf, 20 particles. 
Trajectory prediction logging is disabled.
Average action selection time:  2.7106523513793945e-05
Rollout length:  1000
model train lenght 1000
WARNING:tensorflow:From /data/ShenShuo/workspace/handful-of-trials/dmbrl/modeling/utils/TensorStandardScaler.py:48: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]2020-11-25 22:44:41.268804: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Network training:   0%|                                        | 0/5 [00:02<?, ?epoch(s)/s, Training loss(es)=[32.781803 32.587032 33.966053 32.798786 32.77304 ]]Network training:  20%|██████▍                         | 1/5 [00:02<00:08,  2.02s/epoch(s), Training loss(es)=[32.781803 32.587032 33.966053 32.798786 32.77304 ]]Network training:  20%|██████▍                         | 1/5 [00:02<00:08,  2.15s/epoch(s), Training loss(es)=[32.5312   31.400707 32.896603 31.106222 32.655975]]Network training:  40%|████████████▊                   | 2/5 [00:02<00:03,  1.08s/epoch(s), Training loss(es)=[32.5312   31.400707 32.896603 31.106222 32.655975]]Network training:  40%|████████████▊                   | 2/5 [00:02<00:03,  1.14s/epoch(s), Training loss(es)=[32.04038  29.757133 30.125639 28.850725 31.767824]]Network training:  60%|███████████████████▏            | 3/5 [00:02<00:01,  1.32epoch(s)/s, Training loss(es)=[32.04038  29.757133 30.125639 28.850725 31.767824]]Network training:  60%|███████████████████▏            | 3/5 [00:02<00:01,  1.23epoch(s)/s, Training loss(es)=[30.116972 26.589567 27.129353 29.494238 30.054544]]Network training:  80%|█████████████████████████▌      | 4/5 [00:02<00:00,  1.64epoch(s)/s, Training loss(es)=[30.116972 26.589567 27.129353 29.494238 30.054544]]Network training:  80%|█████████████████████████▌      | 4/5 [00:02<00:00,  1.55epoch(s)/s, Training loss(es)=[26.808035 20.671059 23.261755 25.0092   28.0461  ]]Network training: 100%|████████████████████████████████| 5/5 [00:02<00:00,  1.94epoch(s)/s, Training loss(es)=[26.808035 20.671059 23.261755 25.0092   28.0461  ]]
####################################################################
Starting training iteration 1.
Average action selection time:  0.24937195014953614
Rollout length:  1000
Rewards obtained: [-458.536648278788]
model train lenght 2000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                        | 0/5 [00:00<?, ?epoch(s)/s, Training loss(es)=[15.584424 14.576317 14.374576 13.172158 19.243862]]Network training:  20%|██████▍                         | 1/5 [00:00<00:01,  3.39epoch(s)/s, Training loss(es)=[15.584424 14.576317 14.374576 13.172158 19.243862]]Network training:  20%|██████▍                         | 1/5 [00:00<00:02,  1.78epoch(s)/s, Training loss(es)=[11.975854 10.455409 12.856175  8.191429 14.649345]]Network training:  40%|████████████▊                   | 2/5 [00:00<00:00,  3.57epoch(s)/s, Training loss(es)=[11.975854 10.455409 12.856175  8.191429 14.649345]]Network training:  40%|████████████▊                   | 2/5 [00:00<00:01,  2.45epoch(s)/s, Training loss(es)=[ 8.756837  8.100875  9.927492  7.523553 13.042684]]Network training:  60%|███████████████████▏            | 3/5 [00:00<00:00,  3.67epoch(s)/s, Training loss(es)=[ 8.756837  8.100875  9.927492  7.523553 13.042684]]Network training:  60%|████████████████▏          | 3/5 [00:01<00:00,  2.78epoch(s)/s, Training loss(es)=[ 6.8181343  7.6467447  7.2913203  7.1295857 11.687492 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:01<00:00,  3.71epoch(s)/s, Training loss(es)=[ 6.8181343  7.6467447  7.2913203  7.1295857 11.687492 ]]Network training:  80%|█████████████████████████▌      | 4/5 [00:01<00:00,  2.96epoch(s)/s, Training loss(es)=[4.254738  7.150016  5.686435  6.0039177 8.687421 ]]Network training: 100%|████████████████████████████████| 5/5 [00:01<00:00,  3.70epoch(s)/s, Training loss(es)=[4.254738  7.150016  5.686435  6.0039177 8.687421 ]]
####################################################################
Starting training iteration 2.
Average action selection time:  0.5672171568870544
Rollout length:  1000
Rewards obtained: [-276.8586854528539]
model train lenght 3000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                        | 0/5 [00:02<?, ?epoch(s)/s, Training loss(es)=[3.2863672 3.7198262 2.381192  3.2545698 6.9923315]]Network training:  20%|██████▍                         | 1/5 [00:02<00:11,  2.81s/epoch(s), Training loss(es)=[3.2863672 3.7198262 2.381192  3.2545698 6.9923315]]Network training:  20%|██████▍                         | 1/5 [00:05<00:22,  5.61s/epoch(s), Training loss(es)=[2.0923076 3.00744   1.8672566 1.9517395 6.774482 ]]Network training:  40%|████████████▊                   | 2/5 [00:05<00:08,  2.80s/epoch(s), Training loss(es)=[2.0923076 3.00744   1.8672566 1.9517395 6.774482 ]]Network training:  40%|████████████▊                   | 2/5 [00:08<00:12,  4.21s/epoch(s), Training loss(es)=[1.6953603 1.7951156 1.7685866 1.6714909 5.9388866]]Network training:  60%|███████████████████▏            | 3/5 [00:08<00:05,  2.80s/epoch(s), Training loss(es)=[1.6953603 1.7951156 1.7685866 1.6714909 5.9388866]]Network training:  60%|███████████████████▏            | 3/5 [00:11<00:07,  3.74s/epoch(s), Training loss(es)=[1.5985776 1.6449193 1.6624395 1.6250522 2.9134643]]Network training:  80%|█████████████████████████▌      | 4/5 [00:11<00:02,  2.80s/epoch(s), Training loss(es)=[1.5985776 1.6449193 1.6624395 1.6250522 2.9134643]]Network training:  80%|█████████████████████████▌      | 4/5 [00:14<00:03,  3.50s/epoch(s), Training loss(es)=[1.5199127 1.5454869 1.5437998 1.5000957 2.1046689]]Network training: 100%|████████████████████████████████| 5/5 [00:14<00:00,  2.80s/epoch(s), Training loss(es)=[1.5199127 1.5454869 1.5437998 1.5000957 2.1046689]]
####################################################################
Starting training iteration 3.
Average action selection time:  1.3650775871276855
Rollout length:  1000
Rewards obtained: [-371.9781385913915]
model train lenght 4000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                        | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[1.4460047 1.3586612 1.4282743 1.4161066 1.6491679]]Network training:  20%|██████▍                         | 1/5 [00:06<00:25,  6.35s/epoch(s), Training loss(es)=[1.4460047 1.3586612 1.4282743 1.4161066 1.6491679]]Network training:  20%|██████▍                         | 1/5 [00:12<00:48, 12.19s/epoch(s), Training loss(es)=[1.3663511 1.2089431 1.3208762 1.3837138 1.4742377]]Network training:  40%|████████████▊                   | 2/5 [00:12<00:18,  6.09s/epoch(s), Training loss(es)=[1.3663511 1.2089431 1.3208762 1.3837138 1.4742377]]Network training:  40%|████████████▊                   | 2/5 [00:17<00:26,  8.79s/epoch(s), Training loss(es)=[1.3266966 1.0310035 1.1844829 1.332942  1.322969 ]]Network training:  60%|███████████████████▏            | 3/5 [00:17<00:11,  5.86s/epoch(s), Training loss(es)=[1.3266966 1.0310035 1.1844829 1.332942  1.322969 ]]Network training:  60%|████████████████▏          | 3/5 [00:22<00:14,  7.45s/epoch(s), Training loss(es)=[1.2738358  0.83220786 0.96055704 1.2673037  1.1275054 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:22<00:05,  5.59s/epoch(s), Training loss(es)=[1.2738358  0.83220786 0.96055704 1.2673037  1.1275054 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:27<00:06,  6.96s/epoch(s), Training loss(es)=[1.1618327  0.7313048  0.76678264 1.1859131  0.93641233]]Network training: 100%|███████████████████████████| 5/5 [00:27<00:00,  5.57s/epoch(s), Training loss(es)=[1.1618327  0.7313048  0.76678264 1.1859131  0.93641233]]
####################################################################
Starting training iteration 4.
Average action selection time:  1.2791793134212495
Rollout length:  1000
Rewards obtained: [-332.085618336919]
model train lenght 5000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:07<?, ?epoch(s)/s, Training loss(es)=[1.01689    0.80086356 0.8060786  1.063115   0.90086365]]Network training:  20%|█████▍                     | 1/5 [00:07<00:29,  7.32s/epoch(s), Training loss(es)=[1.01689    0.80086356 0.8060786  1.063115   0.90086365]]Network training:  20%|██████▍                         | 1/5 [00:14<00:56, 14.21s/epoch(s), Training loss(es)=[0.7632752 0.7398836 0.7782758 0.8428703 0.7778576]]Network training:  40%|████████████▊                   | 2/5 [00:14<00:21,  7.10s/epoch(s), Training loss(es)=[0.7632752 0.7398836 0.7782758 0.8428703 0.7778576]]Network training:  40%|██████████▊                | 2/5 [00:21<00:31, 10.54s/epoch(s), Training loss(es)=[0.7057256  0.67564833 0.73244566 0.73499894 0.7507082 ]]Network training:  60%|████████████████▏          | 3/5 [00:21<00:14,  7.03s/epoch(s), Training loss(es)=[0.7057256  0.67564833 0.73244566 0.73499894 0.7507082 ]]Network training:  60%|████████████████▏          | 3/5 [00:28<00:18,  9.48s/epoch(s), Training loss(es)=[0.67427665 0.6354685  0.6719579  0.7239955  0.7143074 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:28<00:07,  7.11s/epoch(s), Training loss(es)=[0.67427665 0.6354685  0.6719579  0.7239955  0.7143074 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:36<00:09,  9.11s/epoch(s), Training loss(es)=[0.62835866 0.61032957 0.6761862  0.6748955  0.6767593 ]]Network training: 100%|███████████████████████████| 5/5 [00:36<00:00,  7.29s/epoch(s), Training loss(es)=[0.62835866 0.61032957 0.6761862  0.6748955  0.6767593 ]]
####################################################################
Starting training iteration 5.
Average action selection time:  1.2356711905002593
Rollout length:  1000
Rewards obtained: [-10.119155138882402]
model train lenght 6000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:09<?, ?epoch(s)/s, Training loss(es)=[0.56296456 0.5441651  0.5753541  0.60058826 0.5953544 ]]Network training:  20%|█████▍                     | 1/5 [00:09<00:38,  9.56s/epoch(s), Training loss(es)=[0.56296456 0.5441651  0.5753541  0.60058826 0.5953544 ]]Network training:  20%|█████▍                     | 1/5 [00:19<01:16, 19.15s/epoch(s), Training loss(es)=[0.5034564  0.53042126 0.55904907 0.55895644 0.5503133 ]]Network training:  40%|██████████▊                | 2/5 [00:19<00:28,  9.58s/epoch(s), Training loss(es)=[0.5034564  0.53042126 0.55904907 0.55895644 0.5503133 ]]Network training:  40%|██████████▊                | 2/5 [00:28<00:43, 14.36s/epoch(s), Training loss(es)=[0.49156424 0.47924063 0.5051947  0.5477636  0.5366768 ]]Network training:  60%|████████████████▏          | 3/5 [00:28<00:19,  9.57s/epoch(s), Training loss(es)=[0.49156424 0.47924063 0.5051947  0.5477636  0.5366768 ]]Network training:  60%|████████████████▏          | 3/5 [00:38<00:25, 12.77s/epoch(s), Training loss(es)=[0.46271732 0.4623234  0.46980116 0.50426763 0.5255941 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:38<00:09,  9.57s/epoch(s), Training loss(es)=[0.46271732 0.4623234  0.46980116 0.50426763 0.5255941 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.97s/epoch(s), Training loss(es)=[0.44841495 0.43618417 0.49468756 0.50664747 0.4988343 ]]Network training: 100%|███████████████████████████| 5/5 [00:47<00:00,  9.58s/epoch(s), Training loss(es)=[0.44841495 0.43618417 0.49468756 0.50664747 0.4988343 ]]
####################################################################
Starting training iteration 6.
Average action selection time:  1.2073653528690338
Rollout length:  1000
Rewards obtained: [393.94153346645584]
model train lenght 7000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.5364208  0.5387238  0.5087386  0.57066333 0.56176096]]Network training:  20%|█████▍                     | 1/5 [00:08<00:34,  8.54s/epoch(s), Training loss(es)=[0.5364208  0.5387238  0.5087386  0.57066333 0.56176096]]Network training:  20%|█████▍                     | 1/5 [00:19<01:18, 19.53s/epoch(s), Training loss(es)=[0.5018685  0.5097628  0.47214746 0.5195168  0.537936  ]]Network training:  40%|██████████▊                | 2/5 [00:19<00:29,  9.77s/epoch(s), Training loss(es)=[0.5018685  0.5097628  0.47214746 0.5195168  0.537936  ]]Network training:  40%|██████████▊                | 2/5 [00:30<00:46, 15.34s/epoch(s), Training loss(es)=[0.46667257 0.4631376  0.45324078 0.4933189  0.5071011 ]]Network training:  60%|████████████████▏          | 3/5 [00:30<00:20, 10.23s/epoch(s), Training loss(es)=[0.46667257 0.4631376  0.45324078 0.4933189  0.5071011 ]]Network training:  60%|████████████████▏          | 3/5 [00:41<00:27, 13.94s/epoch(s), Training loss(es)=[0.46277887 0.4524269  0.43784565 0.46798292 0.47363937]]Network training:  80%|█████████████████████▌     | 4/5 [00:41<00:10, 10.46s/epoch(s), Training loss(es)=[0.46277887 0.4524269  0.43784565 0.46798292 0.47363937]]Network training:  80%|█████████████████████▌     | 4/5 [00:51<00:12, 12.91s/epoch(s), Training loss(es)=[0.43125698 0.4302288  0.43780282 0.4206815  0.47049096]]Network training: 100%|███████████████████████████| 5/5 [00:51<00:00, 10.33s/epoch(s), Training loss(es)=[0.43125698 0.4302288  0.43780282 0.4206815  0.47049096]]
####################################################################
Starting training iteration 7.
Average action selection time:  1.1893923740386962
Rollout length:  1000
Rewards obtained: [43.400525189954976]
model train lenght 8000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:10<?, ?epoch(s)/s, Training loss(es)=[0.44997716 0.45280233 0.4479224  0.43766367 0.46492618]]Network training:  20%|█████▍                     | 1/5 [00:10<00:43, 10.86s/epoch(s), Training loss(es)=[0.44997716 0.45280233 0.4479224  0.43766367 0.46492618]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.21s/epoch(s), Training loss(es)=[0.41720176 0.39835918 0.41675508 0.40457016 0.45813286]]Network training:  40%|██████████▊                | 2/5 [00:21<00:31, 10.61s/epoch(s), Training loss(es)=[0.41720176 0.39835918 0.41675508 0.40457016 0.45813286]]Network training:  40%|██████████▊                | 2/5 [00:30<00:45, 15.13s/epoch(s), Training loss(es)=[0.39662743 0.40167326 0.3952566  0.39516732 0.42796758]]Network training:  60%|████████████████▏          | 3/5 [00:30<00:20, 10.09s/epoch(s), Training loss(es)=[0.39662743 0.40167326 0.3952566  0.39516732 0.42796758]]Network training:  60%|████████████████▏          | 3/5 [00:40<00:27, 13.64s/epoch(s), Training loss(es)=[0.40411612 0.38162765 0.37359598 0.37363812 0.4452696 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:40<00:10, 10.23s/epoch(s), Training loss(es)=[0.40411612 0.38162765 0.37359598 0.37363812 0.4452696 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:51<00:12, 12.96s/epoch(s), Training loss(es)=[0.40163884 0.37799588 0.34300062 0.38628784 0.40603292]]Network training: 100%|███████████████████████████| 5/5 [00:51<00:00, 10.37s/epoch(s), Training loss(es)=[0.40163884 0.37799588 0.34300062 0.38628784 0.40603292]]
####################################################################
Starting training iteration 8.
Average action selection time:  1.157088002204895
Rollout length:  1000
Rewards obtained: [275.0713535041365]
model train lenght 9000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.4001465  0.39650348 0.40061283 0.39061576 0.4132421 ]]Network training:  20%|█████▍                     | 1/5 [00:14<00:57, 14.37s/epoch(s), Training loss(es)=[0.4001465  0.39650348 0.40061283 0.39061576 0.4132421 ]]Network training:  20%|█████▍                     | 1/5 [00:28<01:54, 28.70s/epoch(s), Training loss(es)=[0.40163624 0.37671605 0.36325467 0.36581877 0.3887662 ]]Network training:  40%|██████████▊                | 2/5 [00:28<00:43, 14.35s/epoch(s), Training loss(es)=[0.40163624 0.37671605 0.36325467 0.36581877 0.3887662 ]]Network training:  40%|██████████▊                | 2/5 [00:43<01:04, 21.52s/epoch(s), Training loss(es)=[0.37470156 0.3650223  0.3424336  0.36272714 0.3827649 ]]Network training:  60%|████████████████▏          | 3/5 [00:43<00:28, 14.35s/epoch(s), Training loss(es)=[0.37470156 0.3650223  0.3424336  0.36272714 0.3827649 ]]Network training:  60%|████████████████▏          | 3/5 [00:57<00:38, 19.12s/epoch(s), Training loss(es)=[0.34962973 0.3403138  0.34934375 0.3698042  0.38759264]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.34s/epoch(s), Training loss(es)=[0.34962973 0.3403138  0.34934375 0.3698042  0.38759264]]Network training:  80%|█████████████████████▌     | 4/5 [01:10<00:17, 17.61s/epoch(s), Training loss(es)=[0.3407778  0.33229965 0.33561775 0.33567354 0.34535876]]Network training: 100%|███████████████████████████| 5/5 [01:10<00:00, 14.09s/epoch(s), Training loss(es)=[0.3407778  0.33229965 0.33561775 0.33567354 0.34535876]]
####################################################################
Starting training iteration 9.
Average action selection time:  1.1236092088222505
Rollout length:  1000
Rewards obtained: [201.6295925653976]
model train lenght 10000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.3804364  0.3615758  0.3482895  0.35510233 0.4366245 ]]Network training:  20%|█████▍                     | 1/5 [00:15<01:03, 15.92s/epoch(s), Training loss(es)=[0.3804364  0.3615758  0.3482895  0.35510233 0.4366245 ]]Network training:  20%|█████▍                     | 1/5 [00:31<02:07, 31.83s/epoch(s), Training loss(es)=[0.35132873 0.35028926 0.32538053 0.36816007 0.37805298]]Network training:  40%|██████████▊                | 2/5 [00:31<00:47, 15.91s/epoch(s), Training loss(es)=[0.35132873 0.35028926 0.32538053 0.36816007 0.37805298]]Network training:  40%|██████████▊                | 2/5 [00:47<01:11, 23.87s/epoch(s), Training loss(es)=[0.36449704 0.34990057 0.32899994 0.36232758 0.3475019 ]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.91s/epoch(s), Training loss(es)=[0.36449704 0.34990057 0.32899994 0.36232758 0.3475019 ]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.22s/epoch(s), Training loss(es)=[0.3279538  0.3399808  0.32155633 0.3366176  0.33711386]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 15.92s/epoch(s), Training loss(es)=[0.3279538  0.3399808  0.32155633 0.3366176  0.33711386]]Network training:  80%|█████████████████████▌     | 4/5 [01:19<00:19, 19.90s/epoch(s), Training loss(es)=[0.3198178  0.32470268 0.31268844 0.3175276  0.32560238]]Network training: 100%|███████████████████████████| 5/5 [01:19<00:00, 15.92s/epoch(s), Training loss(es)=[0.3198178  0.32470268 0.31268844 0.3175276  0.32560238]]
####################################################################
Starting training iteration 10.
Average action selection time:  1.1227345421314239
Rollout length:  1000
Rewards obtained: [368.4007352582323]
model train lenght 11000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.31408265 0.30333608 0.30449158 0.339835   0.34164083]]Network training:  20%|█████▍                     | 1/5 [00:14<00:57, 14.46s/epoch(s), Training loss(es)=[0.31408265 0.30333608 0.30449158 0.339835   0.34164083]]Network training:  20%|█████▍                     | 1/5 [00:26<01:47, 27.00s/epoch(s), Training loss(es)=[0.314144   0.30141225 0.29958054 0.32824013 0.33965632]]Network training:  40%|██████████▊                | 2/5 [00:26<00:40, 13.50s/epoch(s), Training loss(es)=[0.314144   0.30141225 0.29958054 0.32824013 0.33965632]]Network training:  40%|██████████▊                | 2/5 [00:40<01:01, 20.44s/epoch(s), Training loss(es)=[0.3239512  0.2856504  0.2763767  0.2987794  0.31602687]]Network training:  60%|████████████████▏          | 3/5 [00:40<00:27, 13.63s/epoch(s), Training loss(es)=[0.3239512  0.2856504  0.2763767  0.2987794  0.31602687]]Network training:  60%|████████████████▏          | 3/5 [00:54<00:36, 18.27s/epoch(s), Training loss(es)=[0.27819332 0.29755333 0.28366894 0.32228905 0.3183606 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:54<00:13, 13.70s/epoch(s), Training loss(es)=[0.27819332 0.29755333 0.28366894 0.32228905 0.3183606 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:04<00:16, 16.23s/epoch(s), Training loss(es)=[0.29167444 0.32603252 0.27105606 0.28816122 0.31824505]]Network training: 100%|███████████████████████████| 5/5 [01:04<00:00, 12.98s/epoch(s), Training loss(es)=[0.29167444 0.32603252 0.27105606 0.28816122 0.31824505]]
####################################################################
Starting training iteration 11.
Average action selection time:  1.1040167427062988
Rollout length:  1000
Rewards obtained: [2053.862401718198]
model train lenght 12000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.33535004 0.31285688 0.3270888  0.31363794 0.33977658]]Network training:  20%|█████▍                     | 1/5 [00:13<00:55, 13.76s/epoch(s), Training loss(es)=[0.33535004 0.31285688 0.3270888  0.31363794 0.33977658]]Network training:  20%|█████▍                     | 1/5 [00:28<01:52, 28.13s/epoch(s), Training loss(es)=[0.32742885 0.3073176  0.33388    0.31110424 0.33324003]]Network training:  40%|██████████▊                | 2/5 [00:28<00:42, 14.07s/epoch(s), Training loss(es)=[0.32742885 0.3073176  0.33388    0.31110424 0.33324003]]Network training:  40%|██████████▊                | 2/5 [00:45<01:07, 22.51s/epoch(s), Training loss(es)=[0.29395807 0.30071265 0.31583023 0.31229374 0.33562592]]Network training:  60%|████████████████▏          | 3/5 [00:45<00:30, 15.01s/epoch(s), Training loss(es)=[0.29395807 0.30071265 0.31583023 0.31229374 0.33562592]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:41, 20.59s/epoch(s), Training loss(es)=[0.3018146  0.29060248 0.28800616 0.30134898 0.30470127]]Network training:  80%|█████████████████████▌     | 4/5 [01:01<00:15, 15.44s/epoch(s), Training loss(es)=[0.3018146  0.29060248 0.28800616 0.30134898 0.30470127]]Network training:  80%|█████████████████████▌     | 4/5 [01:16<00:19, 19.21s/epoch(s), Training loss(es)=[0.30370915 0.28843096 0.28974113 0.29277694 0.29831696]]Network training: 100%|███████████████████████████| 5/5 [01:16<00:00, 15.37s/epoch(s), Training loss(es)=[0.30370915 0.28843096 0.28974113 0.29277694 0.29831696]]
####################################################################
Starting training iteration 12.
Average action selection time:  1.0846625621318817
Rollout length:  1000
Rewards obtained: [1223.9151505143511]
model train lenght 13000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.33878997 0.30235583 0.30379686 0.33161432 0.31854653]]Network training:  20%|█████▍                     | 1/5 [00:14<00:57, 14.37s/epoch(s), Training loss(es)=[0.33878997 0.30235583 0.30379686 0.33161432 0.31854653]]Network training:  20%|█████▍                     | 1/5 [00:29<01:56, 29.05s/epoch(s), Training loss(es)=[0.30889744 0.29038432 0.312955   0.33186266 0.32219318]]Network training:  40%|██████████▊                | 2/5 [00:29<00:43, 14.52s/epoch(s), Training loss(es)=[0.30889744 0.29038432 0.312955   0.33186266 0.32219318]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.87s/epoch(s), Training loss(es)=[0.28969646 0.29472086 0.3037283  0.31902933 0.31021774]]Network training:  60%|████████████████▏          | 3/5 [00:43<00:29, 14.58s/epoch(s), Training loss(es)=[0.28969646 0.29472086 0.3037283  0.31902933 0.31021774]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.06s/epoch(s), Training loss(es)=[0.29579082 0.29258612 0.29436183 0.30304435 0.3350917 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:00<00:15, 15.05s/epoch(s), Training loss(es)=[0.29579082 0.29258612 0.29436183 0.30304435 0.3350917 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:20<00:20, 20.03s/epoch(s), Training loss(es)=[0.27317595 0.27909765 0.2895272  0.3170857  0.3076068 ]]Network training: 100%|███████████████████████████| 5/5 [01:20<00:00, 16.03s/epoch(s), Training loss(es)=[0.27317595 0.27909765 0.2895272  0.3170857  0.3076068 ]]
####################################################################
Starting training iteration 13.
Average action selection time:  1.077612512588501
Rollout length:  1000
Rewards obtained: [2766.2924586549325]
model train lenght 14000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.3012358  0.32545862 0.303287   0.3417629  0.31595275]]Network training:  20%|█████▍                     | 1/5 [00:12<00:51, 12.82s/epoch(s), Training loss(es)=[0.3012358  0.32545862 0.303287   0.3417629  0.31595275]]Network training:  20%|█████▍                     | 1/5 [00:28<01:54, 28.70s/epoch(s), Training loss(es)=[0.3163505  0.31266043 0.28590232 0.31460732 0.29662067]]Network training:  40%|██████████▊                | 2/5 [00:28<00:43, 14.35s/epoch(s), Training loss(es)=[0.3163505  0.31266043 0.28590232 0.31460732 0.29662067]]Network training:  40%|██████████▊                | 2/5 [00:44<01:07, 22.35s/epoch(s), Training loss(es)=[0.2935487  0.30790257 0.2918448  0.30558756 0.28112277]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.90s/epoch(s), Training loss(es)=[0.2935487  0.30790257 0.2918448  0.30558756 0.28112277]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.28s/epoch(s), Training loss(es)=[0.27446333 0.28600723 0.29099032 0.32444757 0.26758873]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 15.96s/epoch(s), Training loss(es)=[0.27446333 0.28600723 0.29099032 0.32444757 0.26758873]]Network training:  80%|█████████████████████▌     | 4/5 [01:25<00:21, 21.41s/epoch(s), Training loss(es)=[0.27653313 0.2884695  0.26624388 0.31061828 0.30170226]]Network training: 100%|███████████████████████████| 5/5 [01:25<00:00, 17.13s/epoch(s), Training loss(es)=[0.27653313 0.2884695  0.26624388 0.31061828 0.30170226]]
####################################################################
Starting training iteration 14.
Average action selection time:  1.0636548113822937
Rollout length:  1000
Rewards obtained: [3141.3902292861508]
model train lenght 15000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.3065967  0.31008506 0.30198634 0.3211992  0.32293862]]Network training:  20%|█████▍                     | 1/5 [00:12<00:48, 12.11s/epoch(s), Training loss(es)=[0.3065967  0.31008506 0.30198634 0.3211992  0.32293862]]Network training:  20%|█████▍                     | 1/5 [00:22<01:29, 22.41s/epoch(s), Training loss(es)=[0.2861819  0.29426676 0.2908024  0.31602424 0.31394973]]Network training:  40%|██████████▊                | 2/5 [00:22<00:33, 11.20s/epoch(s), Training loss(es)=[0.2861819  0.29426676 0.2908024  0.31602424 0.31394973]]Network training:  40%|██████████▊                | 2/5 [00:33<00:49, 16.61s/epoch(s), Training loss(es)=[0.27779177 0.30235946 0.2684551  0.30434    0.33587262]]Network training:  60%|████████████████▏          | 3/5 [00:33<00:22, 11.07s/epoch(s), Training loss(es)=[0.27779177 0.30235946 0.2684551  0.30434    0.33587262]]Network training:  60%|████████████████▏          | 3/5 [00:54<00:36, 18.03s/epoch(s), Training loss(es)=[0.27427775 0.301693   0.26051286 0.30185157 0.30289593]]Network training:  80%|█████████████████████▌     | 4/5 [00:54<00:13, 13.53s/epoch(s), Training loss(es)=[0.27427775 0.301693   0.26051286 0.30185157 0.30289593]]Network training:  80%|█████████████████████▌     | 4/5 [01:17<00:19, 19.41s/epoch(s), Training loss(es)=[0.27743995 0.2840986  0.28202853 0.30271086 0.32061866]]Network training: 100%|███████████████████████████| 5/5 [01:17<00:00, 15.53s/epoch(s), Training loss(es)=[0.27743995 0.2840986  0.28202853 0.30271086 0.32061866]]
####################################################################
Starting training iteration 15.
Average action selection time:  1.0520706388950347
Rollout length:  1000
Rewards obtained: [3572.6753605370864]
model train lenght 16000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.2764546  0.28969365 0.28648546 0.2944089  0.3207359 ]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.30s/epoch(s), Training loss(es)=[0.2764546  0.28969365 0.28648546 0.2944089  0.3207359 ]]Network training:  20%|█████▍                     | 1/5 [00:39<02:37, 39.49s/epoch(s), Training loss(es)=[0.28625992 0.30047828 0.24814561 0.3033898  0.31238708]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.75s/epoch(s), Training loss(es)=[0.28625992 0.30047828 0.24814561 0.3033898  0.31238708]]Network training:  40%|██████████▊                | 2/5 [00:54<01:21, 27.06s/epoch(s), Training loss(es)=[0.27003944 0.29035947 0.25942537 0.2947674  0.30714592]]Network training:  60%|████████████████▏          | 3/5 [00:54<00:36, 18.04s/epoch(s), Training loss(es)=[0.27003944 0.29035947 0.25942537 0.2947674  0.30714592]]Network training:  60%|████████████████▏          | 3/5 [01:08<00:45, 22.91s/epoch(s), Training loss(es)=[0.26818043 0.29066142 0.2634683  0.2917393  0.32413295]]Network training:  80%|█████████████████████▌     | 4/5 [01:08<00:17, 17.19s/epoch(s), Training loss(es)=[0.26818043 0.29066142 0.2634683  0.2917393  0.32413295]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.87s/epoch(s), Training loss(es)=[0.27025008 0.3007387  0.24395457 0.29149917 0.30628368]]Network training: 100%|███████████████████████████| 5/5 [01:23<00:00, 16.69s/epoch(s), Training loss(es)=[0.27025008 0.3007387  0.24395457 0.29149917 0.30628368]]
####################################################################
Starting training iteration 16.
Average action selection time:  0.9700841491222382
Rollout length:  1000
Rewards obtained: [3939.0395395878204]
model train lenght 17000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:10<?, ?epoch(s)/s, Training loss(es)=[0.27220768 0.29122293 0.2561315  0.2927444  0.2974159 ]]Network training:  20%|█████▍                     | 1/5 [00:10<00:42, 10.70s/epoch(s), Training loss(es)=[0.27220768 0.29122293 0.2561315  0.2927444  0.2974159 ]]Network training:  20%|█████▍                     | 1/5 [00:24<01:38, 24.68s/epoch(s), Training loss(es)=[0.27097133 0.28377098 0.2455582  0.30238536 0.30466706]]Network training:  40%|██████████▊                | 2/5 [00:24<00:37, 12.34s/epoch(s), Training loss(es)=[0.27097133 0.28377098 0.2455582  0.30238536 0.30466706]]Network training:  40%|██████████▊                | 2/5 [00:37<00:55, 18.54s/epoch(s), Training loss(es)=[0.24938755 0.258161   0.26423475 0.28048548 0.29935578]]Network training:  60%|████████████████▏          | 3/5 [00:37<00:24, 12.36s/epoch(s), Training loss(es)=[0.24938755 0.258161   0.26423475 0.28048548 0.29935578]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.90s/epoch(s), Training loss(es)=[0.24780303 0.26782182 0.2517363  0.27017638 0.3034866 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.92s/epoch(s), Training loss(es)=[0.24780303 0.26782182 0.2517363  0.27017638 0.3034866 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.27s/epoch(s), Training loss(es)=[0.2496427  0.26454416 0.26169103 0.28373042 0.29355058]]Network training: 100%|███████████████████████████| 5/5 [00:57<00:00, 11.41s/epoch(s), Training loss(es)=[0.2496427  0.26454416 0.26169103 0.28373042 0.29355058]]
####################################################################
Starting training iteration 17.
Average action selection time:  0.49232954955101016
Rollout length:  1000
Rewards obtained: [4217.493210771856]
model train lenght 18000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:02<?, ?epoch(s)/s, Training loss(es)=[0.27464503 0.292549   0.24395405 0.29138428 0.2965261 ]]Network training:  20%|█████▍                     | 1/5 [00:02<00:10,  2.66s/epoch(s), Training loss(es)=[0.27464503 0.292549   0.24395405 0.29138428 0.2965261 ]]Network training:  20%|█████▍                     | 1/5 [00:07<00:31,  7.85s/epoch(s), Training loss(es)=[0.27054465 0.3069595  0.2591037  0.2904316  0.3011104 ]]Network training:  40%|██████████▊                | 2/5 [00:07<00:11,  3.93s/epoch(s), Training loss(es)=[0.27054465 0.3069595  0.2591037  0.2904316  0.3011104 ]]Network training:  40%|██████████▊                | 2/5 [00:13<00:19,  6.50s/epoch(s), Training loss(es)=[0.25714743 0.26745212 0.24513581 0.286735   0.2668469 ]]Network training:  60%|████████████████▏          | 3/5 [00:13<00:08,  4.33s/epoch(s), Training loss(es)=[0.25714743 0.26745212 0.24513581 0.286735   0.2668469 ]]Network training:  60%|████████████████▏          | 3/5 [00:19<00:13,  6.67s/epoch(s), Training loss(es)=[0.25445426 0.275764   0.2449301  0.2642059  0.28907907]]Network training:  80%|█████████████████████▌     | 4/5 [00:19<00:04,  5.00s/epoch(s), Training loss(es)=[0.25445426 0.275764   0.2449301  0.2642059  0.28907907]]Network training:  80%|█████████████████████▌     | 4/5 [00:29<00:07,  7.47s/epoch(s), Training loss(es)=[0.25531727 0.29121548 0.23342927 0.26245895 0.26767623]]Network training: 100%|███████████████████████████| 5/5 [00:29<00:00,  5.97s/epoch(s), Training loss(es)=[0.25531727 0.29121548 0.23342927 0.26245895 0.26767623]]
####################################################################
Starting training iteration 18.
Average action selection time:  0.40449902653694153
Rollout length:  1000
Rewards obtained: [4005.2457935252423]
model train lenght 19000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:02<?, ?epoch(s)/s, Training loss(es)=[0.28413397 0.29615727 0.24194765 0.27611464 0.29255953]]Network training:  20%|█████▍                     | 1/5 [00:02<00:11,  2.99s/epoch(s), Training loss(es)=[0.28413397 0.29615727 0.24194765 0.27611464 0.29255953]]Network training:  20%|█████▍                     | 1/5 [00:08<00:35,  8.81s/epoch(s), Training loss(es)=[0.24292165 0.310151   0.24261276 0.2511999  0.2882878 ]]Network training:  40%|██████████▊                | 2/5 [00:08<00:13,  4.41s/epoch(s), Training loss(es)=[0.24292165 0.310151   0.24261276 0.2511999  0.2882878 ]]Network training:  40%|██████████▊                | 2/5 [00:14<00:21,  7.32s/epoch(s), Training loss(es)=[0.2618475  0.26803467 0.2418978  0.27521703 0.28871188]]Network training:  60%|████████████████▏          | 3/5 [00:14<00:09,  4.88s/epoch(s), Training loss(es)=[0.2618475  0.26803467 0.2418978  0.27521703 0.28871188]]Network training:  60%|████████████████▏          | 3/5 [00:20<00:13,  6.83s/epoch(s), Training loss(es)=[0.2411325  0.2776704  0.22151445 0.26255953 0.26938155]]Network training:  80%|█████████████████████▌     | 4/5 [00:20<00:05,  5.12s/epoch(s), Training loss(es)=[0.2411325  0.2776704  0.22151445 0.26255953 0.26938155]]Network training:  80%|█████████████████████▌     | 4/5 [00:26<00:06,  6.58s/epoch(s), Training loss(es)=[0.24357298 0.2657874  0.23143399 0.23940317 0.26992372]]Network training: 100%|███████████████████████████| 5/5 [00:26<00:00,  5.27s/epoch(s), Training loss(es)=[0.24357298 0.2657874  0.23143399 0.23940317 0.26992372]]
####################################################################
Starting training iteration 19.
Average action selection time:  0.3696507601737976
Rollout length:  1000
Rewards obtained: [4366.6928422055025]
model train lenght 20000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.25246415 0.27893296 0.2714507  0.27361125 0.26872754]]Network training:  20%|█████▍                     | 1/5 [00:06<00:24,  6.10s/epoch(s), Training loss(es)=[0.25246415 0.27893296 0.2714507  0.27361125 0.26872754]]Network training:  20%|█████▍                     | 1/5 [00:12<00:48, 12.20s/epoch(s), Training loss(es)=[0.24398665 0.28357017 0.24456905 0.24933167 0.25958422]]Network training:  40%|██████████▊                | 2/5 [00:12<00:18,  6.10s/epoch(s), Training loss(es)=[0.24398665 0.28357017 0.24456905 0.24933167 0.25958422]]Network training:  40%|██████████▊                | 2/5 [00:18<00:27,  9.18s/epoch(s), Training loss(es)=[0.24303736 0.26717207 0.22231877 0.26292354 0.27790284]]Network training:  60%|████████████████▏          | 3/5 [00:18<00:12,  6.12s/epoch(s), Training loss(es)=[0.24303736 0.26717207 0.22231877 0.26292354 0.27790284]]Network training:  60%|████████████████▏          | 3/5 [00:24<00:16,  8.16s/epoch(s), Training loss(es)=[0.22940908 0.28519717 0.23844805 0.26368496 0.2483794 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:24<00:06,  6.12s/epoch(s), Training loss(es)=[0.22940908 0.28519717 0.23844805 0.26368496 0.2483794 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:30<00:07,  7.67s/epoch(s), Training loss(es)=[0.23656084 0.25145736 0.22737485 0.23754695 0.24979314]]Network training: 100%|███████████████████████████| 5/5 [00:30<00:00,  6.14s/epoch(s), Training loss(es)=[0.23656084 0.25145736 0.22737485 0.23754695 0.24979314]]
####################################################################
Starting training iteration 20.
Average action selection time:  0.36854249930381777
Rollout length:  1000
Rewards obtained: [4647.071468924657]
model train lenght 21000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.2637125  0.28242207 0.2483633  0.27951357 0.27404967]]Network training:  20%|█████▍                     | 1/5 [00:06<00:25,  6.45s/epoch(s), Training loss(es)=[0.2637125  0.28242207 0.2483633  0.27951357 0.27404967]]Network training:  20%|█████▍                     | 1/5 [00:12<00:51, 12.96s/epoch(s), Training loss(es)=[0.23322845 0.28793827 0.23042916 0.28139508 0.30655313]]Network training:  40%|██████████▊                | 2/5 [00:12<00:19,  6.48s/epoch(s), Training loss(es)=[0.23322845 0.28793827 0.23042916 0.28139508 0.30655313]]Network training:  40%|██████████▊                | 2/5 [00:19<00:29,  9.72s/epoch(s), Training loss(es)=[0.24078974 0.27876484 0.22772539 0.23506899 0.27239066]]Network training:  60%|████████████████▏          | 3/5 [00:19<00:12,  6.48s/epoch(s), Training loss(es)=[0.24078974 0.27876484 0.22772539 0.23506899 0.27239066]]Network training:  60%|████████████████▏          | 3/5 [00:25<00:17,  8.63s/epoch(s), Training loss(es)=[0.24266426 0.26994088 0.23474397 0.2694326  0.26757002]]Network training:  80%|█████████████████████▌     | 4/5 [00:25<00:06,  6.47s/epoch(s), Training loss(es)=[0.24266426 0.26994088 0.23474397 0.2694326  0.26757002]]Network training:  80%|█████████████████████▌     | 4/5 [00:32<00:08,  8.08s/epoch(s), Training loss(es)=[0.24198462 0.2651035  0.2585909  0.25677675 0.2316067 ]]Network training: 100%|███████████████████████████| 5/5 [00:32<00:00,  6.46s/epoch(s), Training loss(es)=[0.24198462 0.2651035  0.2585909  0.25677675 0.2316067 ]]
####################################################################
Starting training iteration 21.
Average action selection time:  0.36748697972297667
Rollout length:  1000
Rewards obtained: [4742.361689311183]
model train lenght 22000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.251887   0.27920997 0.23762026 0.25004447 0.2519471 ]]Network training:  20%|█████▍                     | 1/5 [00:06<00:27,  6.79s/epoch(s), Training loss(es)=[0.251887   0.27920997 0.23762026 0.25004447 0.2519471 ]]Network training:  20%|█████▍                     | 1/5 [00:13<00:54, 13.58s/epoch(s), Training loss(es)=[0.2450321  0.2631015  0.2180939  0.24140967 0.24959378]]Network training:  40%|██████████▊                | 2/5 [00:13<00:20,  6.79s/epoch(s), Training loss(es)=[0.2450321  0.2631015  0.2180939  0.24140967 0.24959378]]Network training:  40%|██████████▊                | 2/5 [00:20<00:30, 10.17s/epoch(s), Training loss(es)=[0.26208732 0.26921335 0.21481678 0.23960862 0.23430076]]Network training:  60%|████████████████▏          | 3/5 [00:20<00:13,  6.78s/epoch(s), Training loss(es)=[0.26208732 0.26921335 0.21481678 0.23960862 0.23430076]]Network training:  60%|████████████████▏          | 3/5 [00:27<00:18,  9.08s/epoch(s), Training loss(es)=[0.2478731  0.2540595  0.24950959 0.24647029 0.2325581 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:27<00:06,  6.81s/epoch(s), Training loss(es)=[0.2478731  0.2540595  0.24950959 0.24647029 0.2325581 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:34<00:08,  8.53s/epoch(s), Training loss(es)=[0.23005113 0.24190708 0.22859398 0.22673248 0.23985703]]Network training: 100%|███████████████████████████| 5/5 [00:34<00:00,  6.82s/epoch(s), Training loss(es)=[0.23005113 0.24190708 0.22859398 0.22673248 0.23985703]]
####################################################################
Starting training iteration 22.
Average action selection time:  0.3662742545604706
Rollout length:  1000
Rewards obtained: [4012.992154930132]
model train lenght 23000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:07<?, ?epoch(s)/s, Training loss(es)=[0.2428143  0.28553003 0.27674487 0.28788128 0.26833475]]Network training:  20%|█████▍                     | 1/5 [00:07<00:28,  7.08s/epoch(s), Training loss(es)=[0.2428143  0.28553003 0.27674487 0.28788128 0.26833475]]Network training:  20%|█████▍                     | 1/5 [00:14<00:56, 14.17s/epoch(s), Training loss(es)=[0.2463436  0.25623623 0.23050244 0.27598998 0.24360132]]Network training:  40%|██████████▊                | 2/5 [00:14<00:21,  7.08s/epoch(s), Training loss(es)=[0.2463436  0.25623623 0.23050244 0.27598998 0.24360132]]Network training:  40%|██████████▊                | 2/5 [00:21<00:31, 10.63s/epoch(s), Training loss(es)=[0.23003761 0.28145224 0.23257959 0.25648758 0.27624682]]Network training:  60%|████████████████▏          | 3/5 [00:21<00:14,  7.09s/epoch(s), Training loss(es)=[0.23003761 0.28145224 0.23257959 0.25648758 0.27624682]]Network training:  60%|████████████████▏          | 3/5 [00:28<00:18,  9.45s/epoch(s), Training loss(es)=[0.2343595  0.26633188 0.23720276 0.25056058 0.24934243]]Network training:  80%|█████████████████████▌     | 4/5 [00:28<00:07,  7.08s/epoch(s), Training loss(es)=[0.2343595  0.26633188 0.23720276 0.25056058 0.24934243]]Network training:  80%|█████████████████████▌     | 4/5 [00:35<00:08,  8.85s/epoch(s), Training loss(es)=[0.21735445 0.2830458  0.22761963 0.24644035 0.25118852]]Network training: 100%|███████████████████████████| 5/5 [00:35<00:00,  7.08s/epoch(s), Training loss(es)=[0.21735445 0.2830458  0.22761963 0.24644035 0.25118852]]
####################################################################
Starting training iteration 23.
Average action selection time:  0.3649918489456177
Rollout length:  1000
Rewards obtained: [5096.554518780899]
model train lenght 24000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:07<?, ?epoch(s)/s, Training loss(es)=[0.24353196 0.28800803 0.22965533 0.2683061  0.25935712]]Network training:  20%|█████▍                     | 1/5 [00:07<00:29,  7.42s/epoch(s), Training loss(es)=[0.24353196 0.28800803 0.22965533 0.2683061  0.25935712]]Network training:  20%|█████▍                     | 1/5 [00:14<00:59, 14.82s/epoch(s), Training loss(es)=[0.24472521 0.28962424 0.22361037 0.23225012 0.24578652]]Network training:  40%|██████████▊                | 2/5 [00:14<00:22,  7.41s/epoch(s), Training loss(es)=[0.24472521 0.28962424 0.22361037 0.23225012 0.24578652]]Network training:  40%|██████████▊                | 2/5 [00:22<00:33, 11.09s/epoch(s), Training loss(es)=[0.26676607 0.26039675 0.21362217 0.24919014 0.25851926]]Network training:  60%|████████████████▏          | 3/5 [00:22<00:14,  7.39s/epoch(s), Training loss(es)=[0.26676607 0.26039675 0.21362217 0.24919014 0.25851926]]Network training:  60%|████████████████▏          | 3/5 [00:29<00:19,  9.86s/epoch(s), Training loss(es)=[0.2261867  0.26925063 0.21836504 0.24183288 0.25205442]]Network training:  80%|█████████████████████▌     | 4/5 [00:29<00:07,  7.40s/epoch(s), Training loss(es)=[0.2261867  0.26925063 0.21836504 0.24183288 0.25205442]]Network training:  80%|█████████████████████▌     | 4/5 [00:37<00:09,  9.25s/epoch(s), Training loss(es)=[0.21800336 0.27991673 0.2083344  0.23338345 0.26973158]]Network training: 100%|███████████████████████████| 5/5 [00:37<00:00,  7.40s/epoch(s), Training loss(es)=[0.21800336 0.27991673 0.2083344  0.23338345 0.26973158]]
####################################################################
Starting training iteration 24.
Average action selection time:  0.36402878451347354
Rollout length:  1000
Rewards obtained: [4742.730880206543]
model train lenght 25000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:07<?, ?epoch(s)/s, Training loss(es)=[0.24467884 0.2592458  0.22864556 0.27100524 0.25154716]]Network training:  20%|█████▍                     | 1/5 [00:07<00:30,  7.69s/epoch(s), Training loss(es)=[0.24467884 0.2592458  0.22864556 0.27100524 0.25154716]]Network training:  20%|█████▍                     | 1/5 [00:15<01:01, 15.39s/epoch(s), Training loss(es)=[0.22387117 0.26363102 0.21736364 0.24399652 0.23649585]]Network training:  40%|██████████▊                | 2/5 [00:15<00:23,  7.70s/epoch(s), Training loss(es)=[0.22387117 0.26363102 0.21736364 0.24399652 0.23649585]]Network training:  40%|██████████▊                | 2/5 [00:23<00:34, 11.58s/epoch(s), Training loss(es)=[0.25035614 0.27008024 0.23077095 0.2305585  0.24901609]]Network training:  60%|████████████████▏          | 3/5 [00:23<00:15,  7.72s/epoch(s), Training loss(es)=[0.25035614 0.27008024 0.23077095 0.2305585  0.24901609]]Network training:  60%|████████████████▏          | 3/5 [00:30<00:20, 10.30s/epoch(s), Training loss(es)=[0.22124943 0.25279015 0.20408088 0.2446717  0.24612989]]Network training:  80%|█████████████████████▌     | 4/5 [00:30<00:07,  7.73s/epoch(s), Training loss(es)=[0.22124943 0.25279015 0.20408088 0.2446717  0.24612989]]Network training:  80%|█████████████████████▌     | 4/5 [00:38<00:09,  9.66s/epoch(s), Training loss(es)=[0.23082195 0.26463553 0.20271568 0.2400247  0.24704355]]Network training: 100%|███████████████████████████| 5/5 [00:38<00:00,  7.73s/epoch(s), Training loss(es)=[0.23082195 0.26463553 0.20271568 0.2400247  0.24704355]]
####################################################################
Starting training iteration 25.
Average action selection time:  0.36316424107551576
Rollout length:  1000
Rewards obtained: [5095.728444913246]
model train lenght 26000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:07<?, ?epoch(s)/s, Training loss(es)=[0.257717   0.26522252 0.21510005 0.24476328 0.25562882]]Network training:  20%|█████▍                     | 1/5 [00:07<00:31,  7.96s/epoch(s), Training loss(es)=[0.257717   0.26522252 0.21510005 0.24476328 0.25562882]]Network training:  20%|█████▍                     | 1/5 [00:15<01:03, 15.98s/epoch(s), Training loss(es)=[0.2365199  0.26826075 0.23316635 0.2593082  0.24795698]]Network training:  40%|██████████▊                | 2/5 [00:15<00:23,  7.99s/epoch(s), Training loss(es)=[0.2365199  0.26826075 0.23316635 0.2593082  0.24795698]]Network training:  40%|██████████▊                | 2/5 [00:23<00:35, 11.97s/epoch(s), Training loss(es)=[0.22714272 0.24961099 0.21194948 0.22249731 0.24364278]]Network training:  60%|████████████████▏          | 3/5 [00:23<00:15,  7.98s/epoch(s), Training loss(es)=[0.22714272 0.24961099 0.21194948 0.22249731 0.24364278]]Network training:  60%|████████████████▏          | 3/5 [00:31<00:21, 10.66s/epoch(s), Training loss(es)=[0.21631011 0.25161907 0.20531474 0.23645039 0.22781777]]Network training:  80%|█████████████████████▌     | 4/5 [00:31<00:07,  8.00s/epoch(s), Training loss(es)=[0.21631011 0.25161907 0.20531474 0.23645039 0.22781777]]Network training:  80%|█████████████████████▌     | 4/5 [00:39<00:09,  9.99s/epoch(s), Training loss(es)=[0.22180845 0.2487663  0.20445655 0.23337208 0.2475833 ]]Network training: 100%|███████████████████████████| 5/5 [00:39<00:00,  7.99s/epoch(s), Training loss(es)=[0.22180845 0.2487663  0.20445655 0.23337208 0.2475833 ]]
####################################################################
Starting training iteration 26.
Average action selection time:  0.36153334999084474
Rollout length:  1000
Rewards obtained: [762.6566398664684]
model train lenght 27000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.24894428 0.283933   0.24332839 0.24271438 0.24378154]]Network training:  20%|█████▍                     | 1/5 [00:08<00:33,  8.29s/epoch(s), Training loss(es)=[0.24894428 0.283933   0.24332839 0.24271438 0.24378154]]Network training:  20%|█████▍                     | 1/5 [00:16<01:06, 16.57s/epoch(s), Training loss(es)=[0.218247   0.2760273  0.23797469 0.24362537 0.23786587]]Network training:  40%|██████████▊                | 2/5 [00:16<00:24,  8.29s/epoch(s), Training loss(es)=[0.218247   0.2760273  0.23797469 0.24362537 0.23786587]]Network training:  40%|██████████▊                | 2/5 [00:24<00:37, 12.43s/epoch(s), Training loss(es)=[0.22232729 0.268388   0.23369993 0.2339457  0.2422167 ]]Network training:  60%|████████████████▏          | 3/5 [00:24<00:16,  8.29s/epoch(s), Training loss(es)=[0.22232729 0.268388   0.23369993 0.2339457  0.2422167 ]]Network training:  60%|████████████████▏          | 3/5 [00:33<00:22, 11.05s/epoch(s), Training loss(es)=[0.22960228 0.2701344  0.2079106  0.22109476 0.23219688]]Network training:  80%|█████████████████████▌     | 4/5 [00:33<00:08,  8.29s/epoch(s), Training loss(es)=[0.22960228 0.2701344  0.2079106  0.22109476 0.23219688]]Network training:  80%|█████████████████████▌     | 4/5 [00:41<00:10, 10.37s/epoch(s), Training loss(es)=[0.22806026 0.240475   0.2062379  0.24050015 0.2167358 ]]Network training: 100%|███████████████████████████| 5/5 [00:41<00:00,  8.30s/epoch(s), Training loss(es)=[0.22806026 0.240475   0.2062379  0.24050015 0.2167358 ]]
####################################################################
Starting training iteration 27.
Average action selection time:  0.3602381105422974
Rollout length:  1000
Rewards obtained: [5108.699346252394]
model train lenght 28000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.22707583 0.26103738 0.22276607 0.24249865 0.25477225]]Network training:  20%|█████▍                     | 1/5 [00:08<00:34,  8.64s/epoch(s), Training loss(es)=[0.22707583 0.26103738 0.22276607 0.24249865 0.25477225]]Network training:  20%|█████▍                     | 1/5 [00:17<01:08, 17.20s/epoch(s), Training loss(es)=[0.23390302 0.2532181  0.21982442 0.22955398 0.23918994]]Network training:  40%|██████████▊                | 2/5 [00:17<00:25,  8.60s/epoch(s), Training loss(es)=[0.23390302 0.2532181  0.21982442 0.22955398 0.23918994]]Network training:  40%|██████████▊                | 2/5 [00:25<00:38, 12.90s/epoch(s), Training loss(es)=[0.21881682 0.254072   0.211971   0.21573752 0.24164954]]Network training:  60%|████████████████▏          | 3/5 [00:25<00:17,  8.60s/epoch(s), Training loss(es)=[0.21881682 0.254072   0.211971   0.21573752 0.24164954]]Network training:  60%|████████████████▏          | 3/5 [00:34<00:22, 11.46s/epoch(s), Training loss(es)=[0.21310414 0.26946878 0.20659141 0.23541255 0.24962388]]Network training:  80%|█████████████████████▌     | 4/5 [00:34<00:08,  8.60s/epoch(s), Training loss(es)=[0.21310414 0.26946878 0.20659141 0.23541255 0.24962388]]Network training:  80%|█████████████████████▌     | 4/5 [00:42<00:10, 10.75s/epoch(s), Training loss(es)=[0.19051978 0.24373144 0.20296755 0.21447124 0.23420979]]Network training: 100%|███████████████████████████| 5/5 [00:42<00:00,  8.60s/epoch(s), Training loss(es)=[0.19051978 0.24373144 0.20296755 0.21447124 0.23420979]]
####################################################################
Starting training iteration 28.
Average action selection time:  0.35904655694961546
Rollout length:  1000
Rewards obtained: [5364.211837210257]
model train lenght 29000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.24156655 0.2500953  0.22073914 0.27728364 0.2547231 ]]Network training:  20%|█████▍                     | 1/5 [00:08<00:35,  8.83s/epoch(s), Training loss(es)=[0.24156655 0.2500953  0.22073914 0.27728364 0.2547231 ]]Network training:  20%|█████▍                     | 1/5 [00:17<01:10, 17.68s/epoch(s), Training loss(es)=[0.22227915 0.25909743 0.24480307 0.24044406 0.23543   ]]Network training:  40%|██████████▊                | 2/5 [00:17<00:26,  8.84s/epoch(s), Training loss(es)=[0.22227915 0.25909743 0.24480307 0.24044406 0.23543   ]]Network training:  40%|██████████▊                | 2/5 [00:26<00:39, 13.27s/epoch(s), Training loss(es)=[0.22065063 0.25551066 0.22976138 0.24160469 0.22511089]]Network training:  60%|████████████████▏          | 3/5 [00:26<00:17,  8.85s/epoch(s), Training loss(es)=[0.22065063 0.25551066 0.22976138 0.24160469 0.22511089]]Network training:  60%|████████████████▏          | 3/5 [00:35<00:23, 11.81s/epoch(s), Training loss(es)=[0.21694101 0.2378587  0.20648247 0.23634961 0.22667539]]Network training:  80%|█████████████████████▌     | 4/5 [00:35<00:08,  8.86s/epoch(s), Training loss(es)=[0.21694101 0.2378587  0.20648247 0.23634961 0.22667539]]Network training:  80%|█████████████████████▌     | 4/5 [00:44<00:11, 11.09s/epoch(s), Training loss(es)=[0.20297529 0.240644   0.2005593  0.23630762 0.22367454]]Network training: 100%|███████████████████████████| 5/5 [00:44<00:00,  8.87s/epoch(s), Training loss(es)=[0.20297529 0.240644   0.2005593  0.23630762 0.22367454]]
####################################################################
Starting training iteration 29.
Average action selection time:  0.35807103419303893
Rollout length:  1000
Rewards obtained: [5361.151598449036]
model train lenght 30000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:09<?, ?epoch(s)/s, Training loss(es)=[0.23218018 0.2741592  0.22054614 0.23719041 0.23647493]]Network training:  20%|█████▍                     | 1/5 [00:09<00:36,  9.19s/epoch(s), Training loss(es)=[0.23218018 0.2741592  0.22054614 0.23719041 0.23647493]]Network training:  20%|█████▍                     | 1/5 [00:18<01:13, 18.37s/epoch(s), Training loss(es)=[0.22090061 0.2518516  0.20726545 0.23118752 0.22464594]]Network training:  40%|██████████▊                | 2/5 [00:18<00:27,  9.19s/epoch(s), Training loss(es)=[0.22090061 0.2518516  0.20726545 0.23118752 0.22464594]]Network training:  40%|██████████▊                | 2/5 [00:27<00:41, 13.77s/epoch(s), Training loss(es)=[0.21122605 0.27726126 0.21991146 0.22637923 0.22483696]]Network training:  60%|████████████████▏          | 3/5 [00:27<00:18,  9.18s/epoch(s), Training loss(es)=[0.21122605 0.27726126 0.21991146 0.22637923 0.22483696]]Network training:  60%|████████████████▏          | 3/5 [00:36<00:24, 12.24s/epoch(s), Training loss(es)=[0.20365737 0.24516009 0.21247645 0.21905419 0.24173078]]Network training:  80%|█████████████████████▌     | 4/5 [00:36<00:09,  9.18s/epoch(s), Training loss(es)=[0.20365737 0.24516009 0.21247645 0.21905419 0.24173078]]Network training:  80%|█████████████████████▌     | 4/5 [00:40<00:10, 10.17s/epoch(s), Training loss(es)=[0.20262705 0.23917061 0.19412819 0.22486678 0.21379843]]Network training: 100%|███████████████████████████| 5/5 [00:40<00:00,  8.13s/epoch(s), Training loss(es)=[0.20262705 0.23917061 0.19412819 0.22486678 0.21379843]]
####################################################################
Starting training iteration 30.
Average action selection time:  0.3640069923400879
Rollout length:  1000
Rewards obtained: [1962.077816176158]
model train lenght 31000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:09<?, ?epoch(s)/s, Training loss(es)=[0.21890493 0.24893989 0.22868928 0.21188743 0.23406905]]Network training:  20%|█████▍                     | 1/5 [00:09<00:37,  9.49s/epoch(s), Training loss(es)=[0.21890493 0.24893989 0.22868928 0.21188743 0.23406905]]Network training:  20%|█████▍                     | 1/5 [00:19<01:16, 19.02s/epoch(s), Training loss(es)=[0.20456734 0.26889545 0.23736235 0.2752249  0.19824526]]Network training:  40%|██████████▊                | 2/5 [00:19<00:28,  9.51s/epoch(s), Training loss(es)=[0.20456734 0.26889545 0.23736235 0.2752249  0.19824526]]Network training:  40%|██████████▊                | 2/5 [00:24<00:36, 12.08s/epoch(s), Training loss(es)=[0.21035081 0.22623399 0.20962122 0.23478352 0.22383037]]Network training:  60%|████████████████▏          | 3/5 [00:24<00:16,  8.05s/epoch(s), Training loss(es)=[0.21035081 0.22623399 0.20962122 0.23478352 0.22383037]]Network training:  60%|████████████████▏          | 3/5 [00:28<00:19,  9.51s/epoch(s), Training loss(es)=[0.204973   0.2633853  0.22551583 0.2250292  0.2131499 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:28<00:07,  7.13s/epoch(s), Training loss(es)=[0.204973   0.2633853  0.22551583 0.2250292  0.2131499 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:32<00:08,  8.19s/epoch(s), Training loss(es)=[0.20874658 0.2399583  0.2048827  0.20627612 0.1957552 ]]Network training: 100%|███████████████████████████| 5/5 [00:32<00:00,  6.56s/epoch(s), Training loss(es)=[0.20874658 0.2399583  0.2048827  0.20627612 0.1957552 ]]
####################################################################
Starting training iteration 31.
Average action selection time:  0.3793400814533234
Rollout length:  1000
Rewards obtained: [5256.52636580851]
model train lenght 32000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:04<?, ?epoch(s)/s, Training loss(es)=[0.2081269  0.25293314 0.21489131 0.21664141 0.25450507]]Network training:  20%|█████▍                     | 1/5 [00:04<00:18,  4.75s/epoch(s), Training loss(es)=[0.2081269  0.25293314 0.21489131 0.21664141 0.25450507]]Network training:  20%|█████▍                     | 1/5 [00:08<00:35,  8.98s/epoch(s), Training loss(es)=[0.21477674 0.24323906 0.20564124 0.21820322 0.21865083]]Network training:  40%|██████████▊                | 2/5 [00:08<00:13,  4.49s/epoch(s), Training loss(es)=[0.21477674 0.24323906 0.20564124 0.21820322 0.21865083]]Network training:  40%|██████████▊                | 2/5 [00:13<00:19,  6.63s/epoch(s), Training loss(es)=[0.18472773 0.22345652 0.23223215 0.21755002 0.21805246]]Network training:  60%|████████████████▏          | 3/5 [00:13<00:08,  4.42s/epoch(s), Training loss(es)=[0.18472773 0.22345652 0.23223215 0.21755002 0.21805246]]Network training:  60%|████████████████▏          | 3/5 [00:17<00:11,  5.85s/epoch(s), Training loss(es)=[0.18820491 0.24062736 0.23082533 0.2167584  0.20392759]]Network training:  80%|█████████████████████▌     | 4/5 [00:17<00:04,  4.39s/epoch(s), Training loss(es)=[0.18820491 0.24062736 0.23082533 0.2167584  0.20392759]]Network training:  80%|█████████████████████▌     | 4/5 [00:23<00:05,  5.82s/epoch(s), Training loss(es)=[0.22114734 0.21378681 0.19749841 0.22083047 0.19867453]]Network training: 100%|███████████████████████████| 5/5 [00:23<00:00,  4.65s/epoch(s), Training loss(es)=[0.22114734 0.21378681 0.19749841 0.22083047 0.19867453]]
####################################################################
Starting training iteration 32.
Average action selection time:  0.37828497767448427
Rollout length:  1000
Rewards obtained: [5991.3362840678565]
model train lenght 33000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:04<?, ?epoch(s)/s, Training loss(es)=[0.20198977 0.23919797 0.20882013 0.22668758 0.20968367]]Network training:  20%|█████▍                     | 1/5 [00:04<00:18,  4.58s/epoch(s), Training loss(es)=[0.20198977 0.23919797 0.20882013 0.22668758 0.20968367]]Network training:  20%|█████▍                     | 1/5 [00:09<00:36,  9.19s/epoch(s), Training loss(es)=[0.3722976  0.22685069 0.22598945 0.231448   0.2168584 ]]Network training:  40%|██████████▊                | 2/5 [00:09<00:13,  4.60s/epoch(s), Training loss(es)=[0.3722976  0.22685069 0.22598945 0.231448   0.2168584 ]]Network training:  40%|██████████▊                | 2/5 [00:14<00:22,  7.41s/epoch(s), Training loss(es)=[0.1943658  0.22546957 0.19759011 0.21639337 0.21393277]]Network training:  60%|████████████████▏          | 3/5 [00:14<00:09,  4.94s/epoch(s), Training loss(es)=[0.1943658  0.22546957 0.19759011 0.21639337 0.21393277]]Network training:  60%|████████████████▏          | 3/5 [00:25<00:16,  8.33s/epoch(s), Training loss(es)=[0.19541876 0.2441688  0.20352481 0.2333322  0.19052742]]Network training:  80%|█████████████████████▌     | 4/5 [00:25<00:06,  6.25s/epoch(s), Training loss(es)=[0.19541876 0.2441688  0.20352481 0.2333322  0.19052742]]Network training:  80%|█████████████████████▌     | 4/5 [00:35<00:08,  8.80s/epoch(s), Training loss(es)=[0.22196195 0.23713352 0.19917038 0.21427412 0.20450677]]Network training: 100%|███████████████████████████| 5/5 [00:35<00:00,  7.04s/epoch(s), Training loss(es)=[0.22196195 0.23713352 0.19917038 0.21427412 0.20450677]]
####################################################################
Starting training iteration 33.
Average action selection time:  0.3630668716430664
Rollout length:  1000
Rewards obtained: [5957.501758715988]
model train lenght 34000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:04<?, ?epoch(s)/s, Training loss(es)=[0.23450086 0.25993207 0.21843237 0.23440306 0.21295622]]Network training:  20%|█████▍                     | 1/5 [00:04<00:18,  4.55s/epoch(s), Training loss(es)=[0.23450086 0.25993207 0.21843237 0.23440306 0.21295622]]Network training:  20%|█████▍                     | 1/5 [00:13<00:53, 13.46s/epoch(s), Training loss(es)=[0.20431124 0.23504393 0.22598067 0.24801873 0.21087325]]Network training:  40%|██████████▊                | 2/5 [00:13<00:20,  6.73s/epoch(s), Training loss(es)=[0.20431124 0.23504393 0.22598067 0.24801873 0.21087325]]Network training:  40%|██████████▊                | 2/5 [00:23<00:35, 11.95s/epoch(s), Training loss(es)=[0.20138481 0.23426065 0.22112589 0.20376913 0.22006634]]Network training:  60%|████████████████▏          | 3/5 [00:23<00:15,  7.97s/epoch(s), Training loss(es)=[0.20138481 0.23426065 0.22112589 0.20376913 0.22006634]]Network training:  60%|████████████████▏          | 3/5 [00:34<00:22, 11.46s/epoch(s), Training loss(es)=[0.18723875 0.2708679  0.19309103 0.21821281 0.21382542]]Network training:  80%|█████████████████████▌     | 4/5 [00:34<00:08,  8.60s/epoch(s), Training loss(es)=[0.18723875 0.2708679  0.19309103 0.21821281 0.21382542]]Network training:  80%|█████████████████████▌     | 4/5 [00:44<00:11, 11.21s/epoch(s), Training loss(es)=[0.18122423 0.2459     0.20210034 0.20515952 0.20649952]]Network training: 100%|███████████████████████████| 5/5 [00:44<00:00,  8.97s/epoch(s), Training loss(es)=[0.18122423 0.2459     0.20210034 0.20515952 0.20649952]]
####################################################################
Starting training iteration 34.
Average action selection time:  0.35160124182701114
Rollout length:  1000
Rewards obtained: [5585.610292160528]
model train lenght 35000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:10<?, ?epoch(s)/s, Training loss(es)=[0.18748178 0.2513271  0.19626455 0.20949534 0.22160317]]Network training:  20%|█████▍                     | 1/5 [00:10<00:43, 10.75s/epoch(s), Training loss(es)=[0.18748178 0.2513271  0.19626455 0.20949534 0.22160317]]Network training:  20%|█████▍                     | 1/5 [00:21<01:26, 21.50s/epoch(s), Training loss(es)=[0.20252728 0.23244177 0.19113119 0.21222165 0.19269855]]Network training:  40%|██████████▊                | 2/5 [00:21<00:32, 10.75s/epoch(s), Training loss(es)=[0.20252728 0.23244177 0.19113119 0.21222165 0.19269855]]Network training:  40%|██████████▊                | 2/5 [00:32<00:48, 16.15s/epoch(s), Training loss(es)=[0.19395943 0.2270257  0.19764796 0.20677392 0.2121013 ]]Network training:  60%|████████████████▏          | 3/5 [00:32<00:21, 10.77s/epoch(s), Training loss(es)=[0.19395943 0.2270257  0.19764796 0.20677392 0.2121013 ]]Network training:  60%|████████████████▏          | 3/5 [00:43<00:28, 14.38s/epoch(s), Training loss(es)=[0.20286272 0.2300007  0.2193416  0.18514487 0.19752969]]Network training:  80%|█████████████████████▌     | 4/5 [00:43<00:10, 10.79s/epoch(s), Training loss(es)=[0.20286272 0.2300007  0.2193416  0.18514487 0.19752969]]Network training:  80%|█████████████████████▌     | 4/5 [00:53<00:13, 13.48s/epoch(s), Training loss(es)=[0.18307476 0.21179824 0.1879179  0.20842695 0.24657324]]Network training: 100%|███████████████████████████| 5/5 [00:53<00:00, 10.79s/epoch(s), Training loss(es)=[0.18307476 0.21179824 0.1879179  0.20842695 0.24657324]]
####################################################################
Starting training iteration 35.
Average action selection time:  0.3503080966472626
Rollout length:  1000
Rewards obtained: [5216.7645634329765]
model train lenght 36000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.20933583 0.24842857 0.21534665 0.2220615  0.212397  ]]Network training:  20%|█████▍                     | 1/5 [00:11<00:44, 11.09s/epoch(s), Training loss(es)=[0.20933583 0.24842857 0.21534665 0.2220615  0.212397  ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:28, 22.13s/epoch(s), Training loss(es)=[0.18638192 0.2140503  0.2215671  0.22396155 0.19207062]]Network training:  40%|██████████▊                | 2/5 [00:22<00:33, 11.06s/epoch(s), Training loss(es)=[0.18638192 0.2140503  0.2215671  0.22396155 0.19207062]]Network training:  40%|██████████▊                | 2/5 [00:33<00:49, 16.61s/epoch(s), Training loss(es)=[0.20158187 0.20976387 0.20245641 0.22402163 0.18937841]]Network training:  60%|████████████████▏          | 3/5 [00:33<00:22, 11.07s/epoch(s), Training loss(es)=[0.20158187 0.20976387 0.20245641 0.22402163 0.18937841]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.77s/epoch(s), Training loss(es)=[0.2000286  0.22939588 0.2047103  0.22118457 0.21993494]]Network training:  80%|█████████████████████▌     | 4/5 [00:44<00:11, 11.08s/epoch(s), Training loss(es)=[0.2000286  0.22939588 0.2047103  0.22118457 0.21993494]]Network training:  80%|█████████████████████▌     | 4/5 [00:55<00:13, 13.85s/epoch(s), Training loss(es)=[0.20595598 0.2241595  0.18989985 0.22617453 0.18591292]]Network training: 100%|███████████████████████████| 5/5 [00:55<00:00, 11.08s/epoch(s), Training loss(es)=[0.20595598 0.2241595  0.18989985 0.22617453 0.18591292]]
####################################################################
Starting training iteration 36.
Average action selection time:  0.34865316152572634
Rollout length:  1000
Rewards obtained: [5978.16100732864]
model train lenght 37000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.24922143 0.2397414  0.25855947 0.22798108 0.25156164]]Network training:  20%|█████▍                     | 1/5 [00:11<00:45, 11.43s/epoch(s), Training loss(es)=[0.24922143 0.2397414  0.25855947 0.22798108 0.25156164]]Network training:  20%|█████▍                     | 1/5 [00:22<01:31, 22.81s/epoch(s), Training loss(es)=[0.20504238 0.22138311 0.21207055 0.1881505  0.19935854]]Network training:  40%|██████████▊                | 2/5 [00:22<00:34, 11.40s/epoch(s), Training loss(es)=[0.20504238 0.22138311 0.21207055 0.1881505  0.19935854]]Network training:  40%|██████████▊                | 2/5 [00:34<00:51, 17.09s/epoch(s), Training loss(es)=[0.3242693  0.22299872 0.20288126 0.21958908 0.18883497]]Network training:  60%|████████████████▏          | 3/5 [00:34<00:22, 11.39s/epoch(s), Training loss(es)=[0.3242693  0.22299872 0.20288126 0.21958908 0.18883497]]Network training:  60%|████████████████▏          | 3/5 [00:45<00:30, 15.19s/epoch(s), Training loss(es)=[0.18365799 0.2266324  0.19420445 0.19480832 0.17911337]]Network training:  80%|█████████████████████▌     | 4/5 [00:45<00:11, 11.39s/epoch(s), Training loss(es)=[0.18365799 0.2266324  0.19420445 0.19480832 0.17911337]]Network training:  80%|█████████████████████▌     | 4/5 [00:56<00:14, 14.24s/epoch(s), Training loss(es)=[0.19804917 0.20535137 0.19816352 0.20389517 0.1978769 ]]Network training: 100%|███████████████████████████| 5/5 [00:56<00:00, 11.39s/epoch(s), Training loss(es)=[0.19804917 0.20535137 0.19816352 0.20389517 0.1978769 ]]
####################################################################
Starting training iteration 37.
Average action selection time:  0.3478473675251007
Rollout length:  1000
Rewards obtained: [6085.132609393086]
model train lenght 38000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.38648677 0.2517728  0.22494908 0.20701306 0.20474102]]Network training:  20%|█████▍                     | 1/5 [00:11<00:46, 11.65s/epoch(s), Training loss(es)=[0.38648677 0.2517728  0.22494908 0.20701306 0.20474102]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.30s/epoch(s), Training loss(es)=[0.22704978 0.2335329  0.21178706 0.20364758 0.20684148]]Network training:  40%|██████████▊                | 2/5 [00:23<00:34, 11.65s/epoch(s), Training loss(es)=[0.22704978 0.2335329  0.21178706 0.20364758 0.20684148]]Network training:  40%|██████████▊                | 2/5 [00:34<00:52, 17.49s/epoch(s), Training loss(es)=[0.19299564 0.250979   0.22413301 0.20790535 0.18642035]]Network training:  60%|████████████████▏          | 3/5 [00:34<00:23, 11.66s/epoch(s), Training loss(es)=[0.19299564 0.250979   0.22413301 0.20790535 0.18642035]]Network training:  60%|████████████████▏          | 3/5 [00:46<00:31, 15.57s/epoch(s), Training loss(es)=[0.1968128  0.2195825  0.2085629  0.20567785 0.20411474]]Network training:  80%|█████████████████████▌     | 4/5 [00:46<00:11, 11.68s/epoch(s), Training loss(es)=[0.1968128  0.2195825  0.2085629  0.20567785 0.20411474]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.61s/epoch(s), Training loss(es)=[0.20432991 0.20757934 0.20666225 0.20929731 0.19333547]]Network training: 100%|███████████████████████████| 5/5 [00:58<00:00, 11.69s/epoch(s), Training loss(es)=[0.20432991 0.20757934 0.20666225 0.20929731 0.19333547]]
####################################################################
Starting training iteration 38.
Average action selection time:  0.346463906288147
Rollout length:  1000
Rewards obtained: [1904.3748766419067]
model train lenght 39000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.19128747 0.22678809 0.20665345 0.19587886 0.2245047 ]]Network training:  20%|█████▍                     | 1/5 [00:11<00:47, 11.96s/epoch(s), Training loss(es)=[0.19128747 0.22678809 0.20665345 0.19587886 0.2245047 ]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 23.91s/epoch(s), Training loss(es)=[0.1764479  0.22677246 0.20843667 0.20464517 0.20078218]]Network training:  40%|██████████▊                | 2/5 [00:23<00:35, 11.95s/epoch(s), Training loss(es)=[0.1764479  0.22677246 0.20843667 0.20464517 0.20078218]]Network training:  40%|██████████▊                | 2/5 [00:35<00:53, 17.97s/epoch(s), Training loss(es)=[0.18859267 0.22496201 0.20206489 0.19069013 0.22009102]]Network training:  60%|████████████████▏          | 3/5 [00:35<00:23, 11.98s/epoch(s), Training loss(es)=[0.18859267 0.22496201 0.20206489 0.19069013 0.22009102]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.95s/epoch(s), Training loss(es)=[0.21613857 0.23083049 0.19291778 0.1963305  0.20157166]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.96s/epoch(s), Training loss(es)=[0.21613857 0.23083049 0.19291778 0.1963305  0.20157166]]Network training:  80%|█████████████████████▌     | 4/5 [00:59<00:14, 14.96s/epoch(s), Training loss(es)=[0.1757326  0.2735107  0.2085284  0.20387462 0.1701703 ]]Network training: 100%|███████████████████████████| 5/5 [00:59<00:00, 11.97s/epoch(s), Training loss(es)=[0.1757326  0.2735107  0.2085284  0.20387462 0.1701703 ]]
####################################################################
Starting training iteration 39.
Average action selection time:  0.3452120926380157
Rollout length:  1000
Rewards obtained: [6099.4909024802355]
model train lenght 40000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.18103671 0.22223249 0.20821372 0.21624362 0.20336737]]Network training:  20%|█████▍                     | 1/5 [00:12<00:49, 12.25s/epoch(s), Training loss(es)=[0.18103671 0.22223249 0.20821372 0.21624362 0.20336737]]Network training:  20%|█████▍                     | 1/5 [00:24<01:38, 24.54s/epoch(s), Training loss(es)=[0.17875628 0.2167516  0.22019319 0.22101025 0.2179538 ]]Network training:  40%|██████████▊                | 2/5 [00:24<00:36, 12.27s/epoch(s), Training loss(es)=[0.17875628 0.2167516  0.22019319 0.22101025 0.2179538 ]]Network training:  40%|██████████▊                | 2/5 [00:36<00:55, 18.34s/epoch(s), Training loss(es)=[0.19002016 0.21939301 0.21151029 0.28684297 0.20275015]]Network training:  60%|████████████████▏          | 3/5 [00:36<00:24, 12.23s/epoch(s), Training loss(es)=[0.19002016 0.21939301 0.21151029 0.28684297 0.20275015]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.31s/epoch(s), Training loss(es)=[0.20421991 0.22647473 0.20260467 0.28224176 0.19405152]]Network training:  80%|█████████████████████▌     | 4/5 [00:48<00:12, 12.23s/epoch(s), Training loss(es)=[0.20421991 0.22647473 0.20260467 0.28224176 0.19405152]]Network training:  80%|█████████████████████▌     | 4/5 [01:01<00:15, 15.31s/epoch(s), Training loss(es)=[0.17750032 0.22903591 0.20713557 0.19681256 0.19829012]]Network training: 100%|███████████████████████████| 5/5 [01:01<00:00, 12.24s/epoch(s), Training loss(es)=[0.17750032 0.22903591 0.20713557 0.19681256 0.19829012]]
####################################################################
Starting training iteration 40.
Average action selection time:  0.3438353261947632
Rollout length:  1000
Rewards obtained: [6399.569416398832]
model train lenght 41000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.22542569 0.24799514 0.22739631 0.2231142  0.2123379 ]]Network training:  20%|█████▍                     | 1/5 [00:12<00:50, 12.64s/epoch(s), Training loss(es)=[0.22542569 0.24799514 0.22739631 0.2231142  0.2123379 ]]Network training:  20%|█████▍                     | 1/5 [00:25<01:40, 25.22s/epoch(s), Training loss(es)=[0.19609441 0.21829146 0.2074595  0.20647654 0.20508711]]Network training:  40%|██████████▊                | 2/5 [00:25<00:37, 12.61s/epoch(s), Training loss(es)=[0.19609441 0.21829146 0.2074595  0.20647654 0.20508711]]Network training:  40%|██████████▊                | 2/5 [00:37<00:56, 18.91s/epoch(s), Training loss(es)=[0.34248284 0.21598926 0.20809004 0.19549705 0.18158682]]Network training:  60%|████████████████▏          | 3/5 [00:37<00:25, 12.61s/epoch(s), Training loss(es)=[0.34248284 0.21598926 0.20809004 0.19549705 0.18158682]]Network training:  60%|████████████████▏          | 3/5 [00:50<00:33, 16.85s/epoch(s), Training loss(es)=[0.18951519 0.2077174  0.19533427 0.18379709 0.19210574]]Network training:  80%|█████████████████████▌     | 4/5 [00:50<00:12, 12.64s/epoch(s), Training loss(es)=[0.18951519 0.2077174  0.19533427 0.18379709 0.19210574]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 15.80s/epoch(s), Training loss(es)=[0.1830957  0.22238596 0.19532995 0.18896724 0.19772382]]Network training: 100%|███████████████████████████| 5/5 [01:03<00:00, 12.64s/epoch(s), Training loss(es)=[0.1830957  0.22238596 0.19532995 0.18896724 0.19772382]]
####################################################################
Starting training iteration 41.
Average action selection time:  0.34348072099685667
Rollout length:  1000
Rewards obtained: [6124.520571697048]
model train lenght 42000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.19512981 0.24718775 0.2098666  0.2982843  0.19292797]]Network training:  20%|█████▍                     | 1/5 [00:12<00:51, 12.86s/epoch(s), Training loss(es)=[0.19512981 0.24718775 0.2098666  0.2982843  0.19292797]]Network training:  20%|█████▍                     | 1/5 [00:25<01:43, 25.82s/epoch(s), Training loss(es)=[0.18517563 0.21017075 0.20249821 0.17647412 0.19671181]]Network training:  40%|██████████▊                | 2/5 [00:25<00:38, 12.91s/epoch(s), Training loss(es)=[0.18517563 0.21017075 0.20249821 0.17647412 0.19671181]]Network training:  40%|██████████▊                | 2/5 [00:38<00:58, 19.40s/epoch(s), Training loss(es)=[0.16949873 0.20960528 0.19454844 0.19334862 0.16635785]]Network training:  60%|████████████████▏          | 3/5 [00:38<00:25, 12.93s/epoch(s), Training loss(es)=[0.16949873 0.20960528 0.19454844 0.19334862 0.16635785]]Network training:  60%|████████████████▏          | 3/5 [00:51<00:34, 17.26s/epoch(s), Training loss(es)=[0.23349833 0.20646596 0.21329428 0.21299464 0.19250242]]Network training:  80%|█████████████████████▌     | 4/5 [00:51<00:12, 12.95s/epoch(s), Training loss(es)=[0.23349833 0.20646596 0.21329428 0.21299464 0.19250242]]Network training:  80%|█████████████████████▌     | 4/5 [01:04<00:16, 16.16s/epoch(s), Training loss(es)=[0.20421612 0.23344047 0.20955393 0.21140127 0.19357875]]Network training: 100%|███████████████████████████| 5/5 [01:04<00:00, 12.93s/epoch(s), Training loss(es)=[0.20421612 0.23344047 0.20955393 0.21140127 0.19357875]]
####################################################################
Starting training iteration 42.
Average action selection time:  0.3420529198646545
Rollout length:  1000
Rewards obtained: [5768.878339659968]
model train lenght 43000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.23163088 0.23805213 0.2143398  0.21162552 0.19552574]]Network training:  20%|█████▍                     | 1/5 [00:13<00:52, 13.11s/epoch(s), Training loss(es)=[0.23163088 0.23805213 0.2143398  0.21162552 0.19552574]]Network training:  20%|█████▍                     | 1/5 [00:26<01:45, 26.29s/epoch(s), Training loss(es)=[0.19077262 0.2346239  0.37046042 0.18933193 0.22912537]]Network training:  40%|██████████▊                | 2/5 [00:26<00:39, 13.14s/epoch(s), Training loss(es)=[0.19077262 0.2346239  0.37046042 0.18933193 0.22912537]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.72s/epoch(s), Training loss(es)=[0.18513834 0.22542639 0.20036161 0.20725425 0.18950962]]Network training:  60%|████████████████▏          | 3/5 [00:39<00:26, 13.14s/epoch(s), Training loss(es)=[0.18513834 0.22542639 0.20036161 0.20725425 0.18950962]]Network training:  60%|████████████████▏          | 3/5 [00:52<00:35, 17.56s/epoch(s), Training loss(es)=[0.17959999 0.23302683 0.19623649 0.1866259  0.20705451]]Network training:  80%|█████████████████████▌     | 4/5 [00:52<00:13, 13.17s/epoch(s), Training loss(es)=[0.17959999 0.23302683 0.19623649 0.1866259  0.20705451]]Network training:  80%|█████████████████████▌     | 4/5 [01:05<00:16, 16.47s/epoch(s), Training loss(es)=[0.17780551 0.21156915 0.1852792  0.17888118 0.21093604]]Network training: 100%|███████████████████████████| 5/5 [01:05<00:00, 13.18s/epoch(s), Training loss(es)=[0.17780551 0.21156915 0.1852792  0.17888118 0.21093604]]
####################################################################
Starting training iteration 43.
Average action selection time:  0.34023623991012575
Rollout length:  1000
Rewards obtained: [2407.4396025203077]
model train lenght 44000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.18566616 0.23887429 0.5868156  0.20202197 0.20408666]]Network training:  20%|█████▍                     | 1/5 [00:13<00:54, 13.53s/epoch(s), Training loss(es)=[0.18566616 0.23887429 0.5868156  0.20202197 0.20408666]]Network training:  20%|█████▍                     | 1/5 [00:27<01:48, 27.10s/epoch(s), Training loss(es)=[0.19405451 0.20207949 0.21236219 0.18915352 0.18687908]]Network training:  40%|██████████▊                | 2/5 [00:27<00:40, 13.55s/epoch(s), Training loss(es)=[0.19405451 0.20207949 0.21236219 0.18915352 0.18687908]]Network training:  40%|██████████▊                | 2/5 [00:40<01:00, 20.33s/epoch(s), Training loss(es)=[0.17891267 0.2150851  0.19951592 0.19518864 0.18289758]]Network training:  60%|████████████████▏          | 3/5 [00:40<00:27, 13.55s/epoch(s), Training loss(es)=[0.17891267 0.2150851  0.19951592 0.19518864 0.18289758]]Network training:  60%|████████████████▏          | 3/5 [00:54<00:36, 18.05s/epoch(s), Training loss(es)=[0.17073151 0.23972207 0.20196739 0.20450507 0.18760476]]Network training:  80%|█████████████████████▌     | 4/5 [00:54<00:13, 13.53s/epoch(s), Training loss(es)=[0.17073151 0.23972207 0.20196739 0.20450507 0.18760476]]Network training:  80%|█████████████████████▌     | 4/5 [01:07<00:16, 16.92s/epoch(s), Training loss(es)=[0.19665582 0.2290127  0.20604892 0.19257675 0.16892469]]Network training: 100%|███████████████████████████| 5/5 [01:07<00:00, 13.53s/epoch(s), Training loss(es)=[0.19665582 0.2290127  0.20604892 0.19257675 0.16892469]]
####################################################################
Starting training iteration 44.
Average action selection time:  0.3395524299144745
Rollout length:  1000
Rewards obtained: [6522.316148055297]
model train lenght 45000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.17725752 0.20474933 0.21902661 0.19390954 0.19102588]]Network training:  20%|█████▍                     | 1/5 [00:13<00:55, 13.90s/epoch(s), Training loss(es)=[0.17725752 0.20474933 0.21902661 0.19390954 0.19102588]]Network training:  20%|█████▍                     | 1/5 [00:27<01:50, 27.72s/epoch(s), Training loss(es)=[0.19111069 0.23839755 0.34186906 0.18373044 0.19870387]]Network training:  40%|██████████▊                | 2/5 [00:27<00:41, 13.86s/epoch(s), Training loss(es)=[0.19111069 0.23839755 0.34186906 0.18373044 0.19870387]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.76s/epoch(s), Training loss(es)=[0.16678381 0.20489646 0.1913463  0.19822179 0.18599227]]Network training:  60%|████████████████▏          | 3/5 [00:41<00:27, 13.84s/epoch(s), Training loss(es)=[0.16678381 0.20489646 0.1913463  0.19822179 0.18599227]]Network training:  60%|████████████████▏          | 3/5 [00:53<00:35, 17.98s/epoch(s), Training loss(es)=[0.19829328 0.19759865 0.2037555  0.18962613 0.18499488]]Network training:  80%|█████████████████████▌     | 4/5 [00:53<00:13, 13.48s/epoch(s), Training loss(es)=[0.19829328 0.19759865 0.2037555  0.18962613 0.18499488]]Network training:  80%|█████████████████████▌     | 4/5 [00:59<00:14, 14.98s/epoch(s), Training loss(es)=[0.16958153 0.20221886 0.20951442 0.19507353 0.19390213]]Network training: 100%|███████████████████████████| 5/5 [00:59<00:00, 11.98s/epoch(s), Training loss(es)=[0.16958153 0.20221886 0.20951442 0.19507353 0.19390213]]
####################################################################
Starting training iteration 45.
Average action selection time:  0.3514263916015625
Rollout length:  1000
Rewards obtained: [6292.724203670847]
model train lenght 46000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.21759029 0.23436804 0.19485307 0.22090371 0.20742093]]Network training:  20%|█████▍                     | 1/5 [00:14<00:56, 14.09s/epoch(s), Training loss(es)=[0.21759029 0.23436804 0.19485307 0.22090371 0.20742093]]Network training:  20%|█████▍                     | 1/5 [00:28<01:52, 28.24s/epoch(s), Training loss(es)=[0.19531095 0.20013618 0.2093974  0.2000999  0.22604707]]Network training:  40%|██████████▊                | 2/5 [00:28<00:42, 14.12s/epoch(s), Training loss(es)=[0.19531095 0.20013618 0.2093974  0.2000999  0.22604707]]Network training:  40%|██████████▊                | 2/5 [00:39<00:58, 19.57s/epoch(s), Training loss(es)=[0.18072617 0.20621455 0.18085535 0.21091066 0.18179926]]Network training:  60%|████████████████▏          | 3/5 [00:39<00:26, 13.05s/epoch(s), Training loss(es)=[0.18072617 0.20621455 0.18085535 0.21091066 0.18179926]]Network training:  60%|████████████████▏          | 3/5 [00:45<00:30, 15.08s/epoch(s), Training loss(es)=[0.17359331 0.2267196  0.1998475  0.19225298 0.18299945]]Network training:  80%|█████████████████████▌     | 4/5 [00:45<00:11, 11.31s/epoch(s), Training loss(es)=[0.17359331 0.2267196  0.1998475  0.19225298 0.18299945]]Network training:  80%|█████████████████████▌     | 4/5 [00:51<00:12, 12.87s/epoch(s), Training loss(es)=[0.18567502 0.19974215 0.20878638 0.18493606 0.19762912]]Network training: 100%|███████████████████████████| 5/5 [00:51<00:00, 10.30s/epoch(s), Training loss(es)=[0.18567502 0.19974215 0.20878638 0.18493606 0.19762912]]
####################################################################
Starting training iteration 46.
Average action selection time:  0.3643891508579254
Rollout length:  1000
Rewards obtained: [6212.435752028563]
model train lenght 47000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.34761742 0.2319918  0.19653928 0.2045162  0.20679586]]Network training:  20%|█████▍                     | 1/5 [00:14<00:57, 14.46s/epoch(s), Training loss(es)=[0.34761742 0.2319918  0.19653928 0.2045162  0.20679586]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.16s/epoch(s), Training loss(es)=[0.17448701 0.22375627 0.19709982 0.20177622 0.21857256]]Network training:  40%|██████████▊                | 2/5 [00:24<00:36, 12.08s/epoch(s), Training loss(es)=[0.17448701 0.22375627 0.19709982 0.20177622 0.21857256]]Network training:  40%|██████████▊                | 2/5 [00:30<00:46, 15.35s/epoch(s), Training loss(es)=[0.30509815 0.21820754 0.20789607 0.19591688 0.19205967]]Network training:  60%|████████████████▏          | 3/5 [00:30<00:20, 10.23s/epoch(s), Training loss(es)=[0.30509815 0.21820754 0.20789607 0.19591688 0.19205967]]Network training:  60%|████████████████▏          | 3/5 [00:36<00:24, 12.33s/epoch(s), Training loss(es)=[0.20912129 0.21481617 0.17869303 0.20053874 0.18654704]]Network training:  80%|█████████████████████▌     | 4/5 [00:36<00:09,  9.25s/epoch(s), Training loss(es)=[0.20912129 0.21481617 0.17869303 0.20053874 0.18654704]]Network training:  80%|█████████████████████▌     | 4/5 [00:43<00:10, 10.88s/epoch(s), Training loss(es)=[0.17010196 0.20512708 0.20693305 0.1965566  0.20144367]]Network training: 100%|███████████████████████████| 5/5 [00:43<00:00,  8.71s/epoch(s), Training loss(es)=[0.17010196 0.20512708 0.20693305 0.1965566  0.20144367]]
####################################################################
Starting training iteration 47.
Average action selection time:  0.3803246309757233
Rollout length:  1000
Rewards obtained: [6611.868194932667]
model train lenght 48000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.17811213 0.24111186 0.192549   0.19524843 0.19951127]]Network training:  20%|█████▍                     | 1/5 [00:06<00:24,  6.14s/epoch(s), Training loss(es)=[0.17811213 0.24111186 0.192549   0.19524843 0.19951127]]Network training:  20%|█████▍                     | 1/5 [00:12<00:50, 12.62s/epoch(s), Training loss(es)=[0.18260092 0.20664497 0.19219872 0.20568052 0.18762285]]Network training:  40%|██████████▊                | 2/5 [00:12<00:18,  6.31s/epoch(s), Training loss(es)=[0.18260092 0.20664497 0.19219872 0.20568052 0.18762285]]Network training:  40%|██████████▊                | 2/5 [00:19<00:28,  9.57s/epoch(s), Training loss(es)=[0.19245785 0.22694692 0.20361648 0.19320896 0.17812939]]Network training:  60%|████████████████▏          | 3/5 [00:19<00:12,  6.38s/epoch(s), Training loss(es)=[0.19245785 0.22694692 0.20361648 0.19320896 0.17812939]]Network training:  60%|████████████████▏          | 3/5 [00:25<00:16,  8.49s/epoch(s), Training loss(es)=[0.18707831 0.2072622  0.1898312  0.22453567 0.1838623 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:25<00:06,  6.37s/epoch(s), Training loss(es)=[0.18707831 0.2072622  0.1898312  0.22453567 0.1838623 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:36<00:09,  9.00s/epoch(s), Training loss(es)=[0.17682974 0.21329565 0.23022366 0.19401664 0.18977892]]Network training: 100%|███████████████████████████| 5/5 [00:36<00:00,  7.20s/epoch(s), Training loss(es)=[0.17682974 0.21329565 0.23022366 0.19401664 0.18977892]]
####################################################################
Starting training iteration 48.
Average action selection time:  0.37454545307159426
Rollout length:  1000
Rewards obtained: [6456.8402220800335]
model train lenght 49000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.23666768 0.21727364 0.19597581 0.2114375  0.19012818]]Network training:  20%|█████▍                     | 1/5 [00:06<00:25,  6.49s/epoch(s), Training loss(es)=[0.23666768 0.21727364 0.19597581 0.2114375  0.19012818]]Network training:  20%|█████▍                     | 1/5 [00:13<00:52, 13.04s/epoch(s), Training loss(es)=[0.19522199 0.19638093 0.22719374 0.1851378  0.20572492]]Network training:  40%|██████████▊                | 2/5 [00:13<00:19,  6.52s/epoch(s), Training loss(es)=[0.19522199 0.19638093 0.22719374 0.1851378  0.20572492]]Network training:  40%|██████████▊                | 2/5 [00:19<00:29,  9.75s/epoch(s), Training loss(es)=[0.18911727 0.21433787 0.20935664 0.18781151 0.20421794]]Network training:  60%|████████████████▏          | 3/5 [00:19<00:13,  6.50s/epoch(s), Training loss(es)=[0.18911727 0.21433787 0.20935664 0.18781151 0.20421794]]Network training:  60%|████████████████▏          | 3/5 [00:32<00:21, 10.90s/epoch(s), Training loss(es)=[0.18582428 0.20889695 0.36771265 0.20894127 0.20797688]]Network training:  80%|█████████████████████▌     | 4/5 [00:32<00:08,  8.18s/epoch(s), Training loss(es)=[0.18582428 0.20889695 0.36771265 0.20894127 0.20797688]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.94s/epoch(s), Training loss(es)=[0.21056543 0.20629373 0.21141453 0.18355054 0.18465357]]Network training: 100%|███████████████████████████| 5/5 [00:47<00:00,  9.55s/epoch(s), Training loss(es)=[0.21056543 0.20629373 0.21141453 0.18355054 0.18465357]]
####################################################################
Starting training iteration 49.
Average action selection time:  0.3593221609592438
Rollout length:  1000
Rewards obtained: [4821.594576811745]
model train lenght 50000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.24736223 0.20693359 0.206812   0.19721292 0.20665918]]Network training:  20%|█████▍                     | 1/5 [00:06<00:26,  6.55s/epoch(s), Training loss(es)=[0.24736223 0.20693359 0.206812   0.19721292 0.20665918]]Network training:  20%|█████▍                     | 1/5 [00:13<00:53, 13.30s/epoch(s), Training loss(es)=[0.20087607 0.21139587 0.20442015 0.20747386 0.20184195]]Network training:  40%|██████████▊                | 2/5 [00:13<00:19,  6.65s/epoch(s), Training loss(es)=[0.20087607 0.21139587 0.20442015 0.20747386 0.20184195]]Network training:  40%|██████████▊                | 2/5 [00:27<00:41, 13.77s/epoch(s), Training loss(es)=[0.19329873 0.19913425 0.20397794 0.19821206 0.18755032]]Network training:  60%|████████████████▏          | 3/5 [00:27<00:18,  9.18s/epoch(s), Training loss(es)=[0.19329873 0.19913425 0.20397794 0.19821206 0.18755032]]Network training:  60%|████████████████▏          | 3/5 [00:42<00:28, 14.26s/epoch(s), Training loss(es)=[0.19049214 0.20549919 0.21449925 0.19830185 0.20304893]]Network training:  80%|█████████████████████▌     | 4/5 [00:42<00:10, 10.70s/epoch(s), Training loss(es)=[0.19049214 0.20549919 0.21449925 0.19830185 0.20304893]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.52s/epoch(s), Training loss(es)=[0.18785828 0.20262417 0.21168813 0.19817607 0.189452  ]]Network training: 100%|███████████████████████████| 5/5 [00:58<00:00, 11.62s/epoch(s), Training loss(es)=[0.18785828 0.20262417 0.21168813 0.19817607 0.189452  ]]
####################################################################
Starting training iteration 50.
Average action selection time:  0.3459491858482361
Rollout length:  1000
Rewards obtained: [1568.4880016557258]
model train lenght 51000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:06<?, ?epoch(s)/s, Training loss(es)=[0.3386303  0.24039814 0.21255215 0.20382155 0.22536188]]Network training:  20%|█████▍                     | 1/5 [00:06<00:27,  6.95s/epoch(s), Training loss(es)=[0.3386303  0.24039814 0.21255215 0.20382155 0.22536188]]Network training:  20%|█████▍                     | 1/5 [00:22<01:28, 22.14s/epoch(s), Training loss(es)=[0.20231996 0.20499077 0.19304897 0.18115264 0.21559612]]Network training:  40%|██████████▊                | 2/5 [00:22<00:33, 11.07s/epoch(s), Training loss(es)=[0.20231996 0.20499077 0.19304897 0.18115264 0.21559612]]Network training:  40%|██████████▊                | 2/5 [00:37<00:56, 18.90s/epoch(s), Training loss(es)=[0.18179695 0.17724511 0.33391106 0.17701916 0.1877654 ]]Network training:  60%|████████████████▏          | 3/5 [00:37<00:25, 12.60s/epoch(s), Training loss(es)=[0.18179695 0.17724511 0.33391106 0.17701916 0.1877654 ]]Network training:  60%|████████████████▏          | 3/5 [00:53<00:35, 17.81s/epoch(s), Training loss(es)=[0.1688166  0.19386207 0.20155108 0.17388391 0.16211875]]Network training:  80%|█████████████████████▌     | 4/5 [00:53<00:13, 13.36s/epoch(s), Training loss(es)=[0.1688166  0.19386207 0.20155108 0.17388391 0.16211875]]Network training:  80%|█████████████████████▌     | 4/5 [01:09<00:17, 17.29s/epoch(s), Training loss(es)=[0.18039306 0.20955709 0.22212078 0.19654636 0.19326468]]Network training: 100%|███████████████████████████| 5/5 [01:09<00:00, 13.83s/epoch(s), Training loss(es)=[0.18039306 0.20955709 0.22212078 0.19654636 0.19326468]]
####################################################################
Starting training iteration 51.
Average action selection time:  0.33203995633125305
Rollout length:  1000
Rewards obtained: [3000.8956390666026]
model train lenght 52000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.18767238 0.23257825 0.21394892 0.18430139 0.3547899 ]]Network training:  20%|█████▍                     | 1/5 [00:15<01:01, 15.28s/epoch(s), Training loss(es)=[0.18767238 0.23257825 0.21394892 0.18430139 0.3547899 ]]Network training:  20%|█████▍                     | 1/5 [00:31<02:04, 31.20s/epoch(s), Training loss(es)=[0.16469699 0.19907305 0.20147367 0.17500824 0.1746773 ]]Network training:  40%|██████████▊                | 2/5 [00:31<00:46, 15.60s/epoch(s), Training loss(es)=[0.16469699 0.19907305 0.20147367 0.17500824 0.1746773 ]]Network training:  40%|██████████▊                | 2/5 [00:47<01:10, 23.59s/epoch(s), Training loss(es)=[0.1913365  0.20556223 0.20240425 0.1707158  0.20761517]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.73s/epoch(s), Training loss(es)=[0.1913365  0.20556223 0.20240425 0.1707158  0.20761517]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.05s/epoch(s), Training loss(es)=[0.18445872 0.18869512 0.19278356 0.17975095 0.17480549]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 15.79s/epoch(s), Training loss(es)=[0.18445872 0.18869512 0.19278356 0.17975095 0.17480549]]Network training:  80%|█████████████████████▌     | 4/5 [01:19<00:19, 19.77s/epoch(s), Training loss(es)=[0.18044294 0.19680303 0.179587   0.18634892 0.1750735 ]]Network training: 100%|███████████████████████████| 5/5 [01:19<00:00, 15.82s/epoch(s), Training loss(es)=[0.18044294 0.19680303 0.179587   0.18634892 0.1750735 ]]
####################################################################
Starting training iteration 52.
Average action selection time:  0.32941428685188295
Rollout length:  1000
Rewards obtained: [5295.005675697366]
model train lenght 53000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.25808102 0.20079409 0.21339838 0.24054961 0.2252475 ]]Network training:  20%|█████▍                     | 1/5 [00:16<01:04, 16.24s/epoch(s), Training loss(es)=[0.25808102 0.20079409 0.21339838 0.24054961 0.2252475 ]]Network training:  20%|█████▍                     | 1/5 [00:32<02:09, 32.44s/epoch(s), Training loss(es)=[0.18494742 0.19269644 0.20034976 0.19913122 0.21581396]]Network training:  40%|██████████▊                | 2/5 [00:32<00:48, 16.22s/epoch(s), Training loss(es)=[0.18494742 0.19269644 0.20034976 0.19913122 0.21581396]]Network training:  40%|██████████▊                | 2/5 [00:48<01:13, 24.34s/epoch(s), Training loss(es)=[0.19027929 0.23238929 0.20051919 0.19892468 0.17328276]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.23s/epoch(s), Training loss(es)=[0.19027929 0.23238929 0.20051919 0.19892468 0.17328276]]Network training:  60%|████████████████▏          | 3/5 [01:04<00:43, 21.64s/epoch(s), Training loss(es)=[0.18705496 0.2059531  0.2120808  0.18616699 0.18715225]]Network training:  80%|█████████████████████▌     | 4/5 [01:04<00:16, 16.23s/epoch(s), Training loss(es)=[0.18705496 0.2059531  0.2120808  0.18616699 0.18715225]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.29s/epoch(s), Training loss(es)=[0.22980054 0.18868391 0.19171736 0.17569757 0.1902694 ]]Network training: 100%|███████████████████████████| 5/5 [01:21<00:00, 16.23s/epoch(s), Training loss(es)=[0.22980054 0.18868391 0.19171736 0.17569757 0.1902694 ]]
####################################################################
Starting training iteration 53.
Average action selection time:  0.32856967496871947
Rollout length:  1000
Rewards obtained: [1494.4045946300787]
model train lenght 54000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.19125417 0.21741125 0.19271113 0.19533257 0.17403801]]Network training:  20%|█████▍                     | 1/5 [00:16<01:06, 16.52s/epoch(s), Training loss(es)=[0.19125417 0.21741125 0.19271113 0.19533257 0.17403801]]Network training:  20%|█████▍                     | 1/5 [00:33<02:12, 33.16s/epoch(s), Training loss(es)=[0.18700412 0.20877491 0.1972877  0.17931782 0.2244024 ]]Network training:  40%|██████████▊                | 2/5 [00:33<00:49, 16.58s/epoch(s), Training loss(es)=[0.18700412 0.20877491 0.1972877  0.17931782 0.2244024 ]]Network training:  40%|██████████▊                | 2/5 [00:49<01:14, 24.91s/epoch(s), Training loss(es)=[0.17254533 0.19772893 0.20217398 0.20266236 0.23847903]]Network training:  60%|████████████████▏          | 3/5 [00:49<00:33, 16.61s/epoch(s), Training loss(es)=[0.17254533 0.19772893 0.20217398 0.20266236 0.23847903]]Network training:  60%|████████████████▏          | 3/5 [01:06<00:44, 22.14s/epoch(s), Training loss(es)=[0.17682669 0.19259876 0.2060951  0.20117263 0.16817336]]Network training:  80%|█████████████████████▌     | 4/5 [01:06<00:16, 16.60s/epoch(s), Training loss(es)=[0.17682669 0.19259876 0.2060951  0.20117263 0.16817336]]Network training:  80%|█████████████████████▌     | 4/5 [01:22<00:20, 20.75s/epoch(s), Training loss(es)=[0.19354865 0.18940252 0.19941923 0.16573855 0.16328725]]Network training: 100%|███████████████████████████| 5/5 [01:22<00:00, 16.60s/epoch(s), Training loss(es)=[0.19354865 0.18940252 0.19941923 0.16573855 0.16328725]]
####################################################################
Starting training iteration 54.
Average action selection time:  0.32750740480422974
Rollout length:  1000
Rewards obtained: [5070.885715153116]
model train lenght 55000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.3353534  0.2971262  0.19130853 0.18745348 0.18173432]]Network training:  20%|█████▍                     | 1/5 [00:16<01:07, 16.82s/epoch(s), Training loss(es)=[0.3353534  0.2971262  0.19130853 0.18745348 0.18173432]]Network training:  20%|█████▍                     | 1/5 [00:33<02:15, 33.78s/epoch(s), Training loss(es)=[0.18188585 0.20202596 0.19029313 0.19134854 0.20609221]]Network training:  40%|██████████▊                | 2/5 [00:33<00:50, 16.89s/epoch(s), Training loss(es)=[0.18188585 0.20202596 0.19029313 0.19134854 0.20609221]]Network training:  40%|██████████▊                | 2/5 [00:50<01:15, 25.33s/epoch(s), Training loss(es)=[0.17955069 0.18019687 0.17993234 0.2793422  0.16979511]]Network training:  60%|████████████████▏          | 3/5 [00:50<00:33, 16.89s/epoch(s), Training loss(es)=[0.17955069 0.18019687 0.17993234 0.2793422  0.16979511]]Network training:  60%|████████████████▏          | 3/5 [01:07<00:45, 22.54s/epoch(s), Training loss(es)=[0.2854232  0.19181743 0.18518603 0.21478896 0.24462818]]Network training:  80%|█████████████████████▌     | 4/5 [01:07<00:16, 16.90s/epoch(s), Training loss(es)=[0.2854232  0.19181743 0.18518603 0.21478896 0.24462818]]Network training:  80%|█████████████████████▌     | 4/5 [01:24<00:21, 21.13s/epoch(s), Training loss(es)=[0.1721655  0.1946086  0.1814308  0.19902083 0.17785455]]Network training: 100%|███████████████████████████| 5/5 [01:24<00:00, 16.91s/epoch(s), Training loss(es)=[0.1721655  0.1946086  0.1814308  0.19902083 0.17785455]]
####################################################################
Starting training iteration 55.
Average action selection time:  0.3260530683994293
Rollout length:  1000
Rewards obtained: [1774.3917811050287]
model train lenght 56000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.19505462 0.20911269 0.19038305 0.1856711  0.20062596]]Network training:  20%|█████▍                     | 1/5 [00:17<01:08, 17.12s/epoch(s), Training loss(es)=[0.19505462 0.20911269 0.19038305 0.1856711  0.20062596]]Network training:  20%|█████▍                     | 1/5 [00:34<02:17, 34.29s/epoch(s), Training loss(es)=[0.1875299  0.21131974 0.19754371 0.22009632 0.18563266]]Network training:  40%|██████████▊                | 2/5 [00:34<00:51, 17.15s/epoch(s), Training loss(es)=[0.1875299  0.21131974 0.19754371 0.22009632 0.18563266]]Network training:  40%|██████████▊                | 2/5 [00:51<01:17, 25.76s/epoch(s), Training loss(es)=[0.18333729 0.20931128 0.17762487 0.20070525 0.16989177]]Network training:  60%|████████████████▏          | 3/5 [00:51<00:34, 17.18s/epoch(s), Training loss(es)=[0.18333729 0.20931128 0.17762487 0.20070525 0.16989177]]Network training:  60%|████████████████▏          | 3/5 [01:08<00:45, 22.91s/epoch(s), Training loss(es)=[0.1932244  0.18887809 0.17698713 0.18995056 0.18424721]]Network training:  80%|█████████████████████▌     | 4/5 [01:08<00:17, 17.18s/epoch(s), Training loss(es)=[0.1932244  0.18887809 0.17698713 0.18995056 0.18424721]]Network training:  80%|█████████████████████▌     | 4/5 [01:25<00:21, 21.49s/epoch(s), Training loss(es)=[0.1930568  0.2058461  0.17563663 0.17955674 0.19370687]]Network training: 100%|███████████████████████████| 5/5 [01:25<00:00, 17.19s/epoch(s), Training loss(es)=[0.1930568  0.2058461  0.17563663 0.17955674 0.19370687]]
####################################################################
Starting training iteration 56.
Average action selection time:  0.3244726583957672
Rollout length:  1000
Rewards obtained: [1858.3470286997697]
model train lenght 57000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.19060145 0.19991103 0.19855005 0.18499365 0.18192525]]Network training:  20%|█████▍                     | 1/5 [00:17<01:09, 17.49s/epoch(s), Training loss(es)=[0.19060145 0.19991103 0.19855005 0.18499365 0.18192525]]Network training:  20%|█████▍                     | 1/5 [00:34<02:19, 34.95s/epoch(s), Training loss(es)=[0.21958338 0.20011565 0.19882786 0.19729525 0.18998966]]Network training:  40%|██████████▊                | 2/5 [00:34<00:52, 17.48s/epoch(s), Training loss(es)=[0.21958338 0.20011565 0.19882786 0.19729525 0.18998966]]Network training:  40%|██████████▊                | 2/5 [00:52<01:18, 26.19s/epoch(s), Training loss(es)=[0.1905414  0.17660317 0.19145353 0.1916094  0.18271358]]Network training:  60%|████████████████▏          | 3/5 [00:52<00:34, 17.46s/epoch(s), Training loss(es)=[0.1905414  0.17660317 0.19145353 0.1916094  0.18271358]]Network training:  60%|████████████████▏          | 3/5 [01:09<00:46, 23.30s/epoch(s), Training loss(es)=[0.20120789 0.19689696 0.2083824  0.18455729 0.1970843 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:09<00:17, 17.47s/epoch(s), Training loss(es)=[0.20120789 0.19689696 0.2083824  0.18455729 0.1970843 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:27<00:21, 21.86s/epoch(s), Training loss(es)=[0.22265644 0.17880307 0.18816264 0.19818957 0.19846389]]Network training: 100%|███████████████████████████| 5/5 [01:27<00:00, 17.49s/epoch(s), Training loss(es)=[0.22265644 0.17880307 0.18816264 0.19818957 0.19846389]]
####################################################################
Starting training iteration 57.
Average action selection time:  0.32427898144721984
Rollout length:  1000
Rewards obtained: [1938.6508857224228]
model train lenght 58000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.17223723 0.19071244 0.20399235 0.20400849 0.20532368]]Network training:  20%|█████▍                     | 1/5 [00:17<01:11, 17.91s/epoch(s), Training loss(es)=[0.17223723 0.19071244 0.20399235 0.20400849 0.20532368]]Network training:  20%|█████▍                     | 1/5 [00:35<02:22, 35.74s/epoch(s), Training loss(es)=[0.18432884 0.19367795 0.20715837 0.20594268 0.20201911]]Network training:  40%|██████████▊                | 2/5 [00:35<00:53, 17.87s/epoch(s), Training loss(es)=[0.18432884 0.19367795 0.20715837 0.20594268 0.20201911]]Network training:  40%|██████████▊                | 2/5 [00:53<01:20, 26.86s/epoch(s), Training loss(es)=[0.23296359 0.18049392 0.19271001 0.17766175 0.19903672]]Network training:  60%|████████████████▏          | 3/5 [00:53<00:35, 17.91s/epoch(s), Training loss(es)=[0.23296359 0.18049392 0.19271001 0.17766175 0.19903672]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.85s/epoch(s), Training loss(es)=[0.19060595 0.1691135  0.17958605 0.20045468 0.19099538]]Network training:  80%|█████████████████████▌     | 4/5 [01:11<00:17, 17.88s/epoch(s), Training loss(es)=[0.19060595 0.1691135  0.17958605 0.20045468 0.19099538]]Network training:  80%|█████████████████████▌     | 4/5 [01:29<00:22, 22.36s/epoch(s), Training loss(es)=[0.17101932 0.17399074 0.19147381 0.1781339  0.18496194]]Network training: 100%|███████████████████████████| 5/5 [01:29<00:00, 17.89s/epoch(s), Training loss(es)=[0.17101932 0.17399074 0.19147381 0.1781339  0.18496194]]
####################################################################
Starting training iteration 58.
Average action selection time:  0.3226889934539795
Rollout length:  1000
Rewards obtained: [1548.0621680497331]
model train lenght 59000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.17945778 0.19498713 0.20381708 0.1863638  0.18240136]]Network training:  20%|█████▍                     | 1/5 [00:18<01:12, 18.18s/epoch(s), Training loss(es)=[0.17945778 0.19498713 0.20381708 0.1863638  0.18240136]]Network training:  20%|█████▍                     | 1/5 [00:36<02:25, 36.41s/epoch(s), Training loss(es)=[0.18247771 0.18024124 0.18266462 0.19811317 0.18340135]]Network training:  40%|██████████▊                | 2/5 [00:36<00:54, 18.20s/epoch(s), Training loss(es)=[0.18247771 0.18024124 0.18266462 0.19811317 0.18340135]]Network training:  40%|██████████▊                | 2/5 [00:54<01:21, 27.29s/epoch(s), Training loss(es)=[0.1797501  0.19005021 0.1817235  0.16993158 0.19940574]]Network training:  60%|████████████████▏          | 3/5 [00:54<00:36, 18.19s/epoch(s), Training loss(es)=[0.1797501  0.19005021 0.1817235  0.16993158 0.19940574]]Network training:  60%|████████████████▏          | 3/5 [01:12<00:48, 24.25s/epoch(s), Training loss(es)=[0.20580615 0.18758631 0.18253382 0.17621233 0.15923259]]Network training:  80%|█████████████████████▌     | 4/5 [01:12<00:18, 18.19s/epoch(s), Training loss(es)=[0.20580615 0.18758631 0.18253382 0.17621233 0.15923259]]Network training:  80%|█████████████████████▌     | 4/5 [01:30<00:22, 22.73s/epoch(s), Training loss(es)=[0.16650227 0.15979725 0.17369343 0.18393022 0.16153106]]Network training: 100%|███████████████████████████| 5/5 [01:30<00:00, 18.18s/epoch(s), Training loss(es)=[0.16650227 0.15979725 0.17369343 0.18393022 0.16153106]]
####################################################################
Starting training iteration 59.
Average action selection time:  0.32165851283073427
Rollout length:  1000
Rewards obtained: [2954.7725447995235]
model train lenght 60000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.20446552 0.17941093 0.19276516 0.17942773 0.16182154]]Network training:  20%|█████▍                     | 1/5 [00:18<01:13, 18.49s/epoch(s), Training loss(es)=[0.20446552 0.17941093 0.19276516 0.17942773 0.16182154]]Network training:  20%|█████▍                     | 1/5 [00:36<02:27, 36.88s/epoch(s), Training loss(es)=[0.1718014  0.18252985 0.17977576 0.18911326 0.2881615 ]]Network training:  40%|██████████▊                | 2/5 [00:36<00:55, 18.44s/epoch(s), Training loss(es)=[0.1718014  0.18252985 0.17977576 0.18911326 0.2881615 ]]Network training:  40%|██████████▊                | 2/5 [00:55<01:22, 27.61s/epoch(s), Training loss(es)=[0.17756312 0.16799998 0.19670875 0.18051454 0.19220525]]Network training:  60%|████████████████▏          | 3/5 [00:55<00:36, 18.41s/epoch(s), Training loss(es)=[0.17756312 0.16799998 0.19670875 0.18051454 0.19220525]]Network training:  60%|████████████████▏          | 3/5 [01:13<00:49, 24.59s/epoch(s), Training loss(es)=[0.16693048 0.17216799 0.2537994  0.17256938 0.17947382]]Network training:  80%|█████████████████████▌     | 4/5 [01:13<00:18, 18.44s/epoch(s), Training loss(es)=[0.16693048 0.17216799 0.2537994  0.17256938 0.17947382]]Network training:  80%|█████████████████████▌     | 4/5 [01:30<00:22, 22.64s/epoch(s), Training loss(es)=[0.22812188 0.18372272 0.18566751 0.17127873 0.17416118]]Network training: 100%|███████████████████████████| 5/5 [01:30<00:00, 18.11s/epoch(s), Training loss(es)=[0.22812188 0.18372272 0.18566751 0.17127873 0.17416118]]
####################################################################
Starting training iteration 60.
Average action selection time:  0.32220389747619627
Rollout length:  1000
Rewards obtained: [2165.4961402322797]
model train lenght 61000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.18249336 0.1780541  0.24017854 0.18543315 0.19540203]]Network training:  20%|█████▍                     | 1/5 [00:18<01:15, 18.82s/epoch(s), Training loss(es)=[0.18249336 0.1780541  0.24017854 0.18543315 0.19540203]]Network training:  20%|█████▍                     | 1/5 [00:37<02:30, 37.66s/epoch(s), Training loss(es)=[0.1833487  0.18243203 0.18665914 0.17569873 0.17162725]]Network training:  40%|██████████▊                | 2/5 [00:37<00:56, 18.83s/epoch(s), Training loss(es)=[0.1833487  0.18243203 0.18665914 0.17569873 0.17162725]]Network training:  40%|██████████▊                | 2/5 [00:56<01:24, 28.25s/epoch(s), Training loss(es)=[0.16173844 0.18931928 0.17700152 0.17016205 0.18526894]]Network training:  60%|████████████████▏          | 3/5 [00:56<00:37, 18.83s/epoch(s), Training loss(es)=[0.16173844 0.18931928 0.17700152 0.17016205 0.18526894]]Network training:  60%|████████████████▏          | 3/5 [01:14<00:49, 24.88s/epoch(s), Training loss(es)=[0.29416266 0.18096697 0.17644572 0.17889109 0.17237082]]Network training:  80%|█████████████████████▌     | 4/5 [01:14<00:18, 18.66s/epoch(s), Training loss(es)=[0.29416266 0.18096697 0.17644572 0.17889109 0.17237082]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.50s/epoch(s), Training loss(es)=[0.4693117  0.20597343 0.19914524 0.25967655 0.16713667]]Network training: 100%|███████████████████████████| 5/5 [01:21<00:00, 16.40s/epoch(s), Training loss(es)=[0.4693117  0.20597343 0.19914524 0.25967655 0.16713667]]
####################################################################
Starting training iteration 61.
Average action selection time:  0.33229138040542605
Rollout length:  1000
Rewards obtained: [6327.739450084227]
model train lenght 62000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.25937203 0.2425456  0.28753373 0.19668391 0.2002525 ]]Network training:  20%|█████▍                     | 1/5 [00:18<01:15, 18.92s/epoch(s), Training loss(es)=[0.25937203 0.2425456  0.28753373 0.19668391 0.2002525 ]]Network training:  20%|█████▍                     | 1/5 [00:37<02:31, 37.85s/epoch(s), Training loss(es)=[0.16258405 0.19529966 0.19591781 0.18262209 0.17728533]]Network training:  40%|██████████▊                | 2/5 [00:37<00:56, 18.93s/epoch(s), Training loss(es)=[0.16258405 0.19529966 0.19591781 0.18262209 0.17728533]]Network training:  40%|██████████▊                | 2/5 [00:56<01:25, 28.44s/epoch(s), Training loss(es)=[0.15774608 0.1769861  0.18855399 0.1805353  0.19674282]]Network training:  60%|████████████████▏          | 3/5 [00:56<00:37, 18.96s/epoch(s), Training loss(es)=[0.15774608 0.1769861  0.18855399 0.1805353  0.19674282]]Network training:  60%|████████████████▏          | 3/5 [01:07<00:45, 22.62s/epoch(s), Training loss(es)=[0.16792277 0.1983734  0.19220261 0.17206703 0.21019436]]Network training:  80%|█████████████████████▌     | 4/5 [01:07<00:16, 16.97s/epoch(s), Training loss(es)=[0.16792277 0.1983734  0.19220261 0.17206703 0.21019436]]Network training:  80%|█████████████████████▌     | 4/5 [01:15<00:18, 18.98s/epoch(s), Training loss(es)=[0.17779432 0.18250503 0.17689805 0.16906491 0.17381391]]Network training: 100%|███████████████████████████| 5/5 [01:15<00:00, 15.18s/epoch(s), Training loss(es)=[0.17779432 0.18250503 0.17689805 0.16906491 0.17381391]]
####################################################################
Starting training iteration 62.
Average action selection time:  0.34511148834228517
Rollout length:  1000
Rewards obtained: [5991.422357524894]
model train lenght 63000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:19<?, ?epoch(s)/s, Training loss(es)=[0.20896147 0.17175345 0.20357147 0.18414465 0.21351728]]Network training:  20%|█████▍                     | 1/5 [00:19<01:17, 19.45s/epoch(s), Training loss(es)=[0.20896147 0.17175345 0.20357147 0.18414465 0.21351728]]Network training:  20%|█████▍                     | 1/5 [00:38<02:35, 38.84s/epoch(s), Training loss(es)=[0.17361395 0.16129908 0.17760316 0.17337134 0.17962387]]Network training:  40%|██████████▊                | 2/5 [00:38<00:58, 19.42s/epoch(s), Training loss(es)=[0.17361395 0.16129908 0.17760316 0.17337134 0.17962387]]Network training:  40%|██████████▊                | 2/5 [00:51<01:16, 25.61s/epoch(s), Training loss(es)=[0.1624328  0.20192337 0.18814489 0.16365835 0.17580666]]Network training:  60%|████████████████▏          | 3/5 [00:51<00:34, 17.07s/epoch(s), Training loss(es)=[0.1624328  0.20192337 0.18814489 0.16365835 0.17580666]]Network training:  60%|████████████████▏          | 3/5 [00:59<00:39, 19.94s/epoch(s), Training loss(es)=[0.16654254 0.16439497 0.18756573 0.1611506  0.1763209 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:59<00:14, 14.96s/epoch(s), Training loss(es)=[0.16654254 0.16439497 0.18756573 0.1611506  0.1763209 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:08<00:17, 17.09s/epoch(s), Training loss(es)=[0.16860555 0.1796717  0.19610618 0.17321712 0.1761238 ]]Network training: 100%|███████████████████████████| 5/5 [01:08<00:00, 13.67s/epoch(s), Training loss(es)=[0.16860555 0.1796717  0.19610618 0.17321712 0.1761238 ]]
####################################################################
Starting training iteration 63.
Average action selection time:  0.3614482431411743
Rollout length:  1000
Rewards obtained: [3038.340334338157]
model train lenght 64000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:19<?, ?epoch(s)/s, Training loss(es)=[0.16560537 0.1902697  0.25384384 0.16837882 0.19240461]]Network training:  20%|█████▍                     | 1/5 [00:19<01:18, 19.63s/epoch(s), Training loss(es)=[0.16560537 0.1902697  0.25384384 0.16837882 0.19240461]]Network training:  20%|█████▍                     | 1/5 [00:30<02:01, 30.35s/epoch(s), Training loss(es)=[0.22946319 0.20159285 0.16691741 0.19885682 0.18383995]]Network training:  40%|██████████▊                | 2/5 [00:30<00:45, 15.18s/epoch(s), Training loss(es)=[0.22946319 0.20159285 0.16691741 0.19885682 0.18383995]]Network training:  40%|██████████▊                | 2/5 [00:38<00:58, 19.48s/epoch(s), Training loss(es)=[0.15992206 0.17297184 0.17774697 0.18923011 0.16426674]]Network training:  60%|████████████████▏          | 3/5 [00:38<00:25, 12.99s/epoch(s), Training loss(es)=[0.15992206 0.17297184 0.17774697 0.18923011 0.16426674]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.80s/epoch(s), Training loss(es)=[0.1699555  0.18310513 0.18091175 0.18213913 0.17044473]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.85s/epoch(s), Training loss(es)=[0.1699555  0.18310513 0.18091175 0.18213913 0.17044473]]Network training:  80%|█████████████████████▌     | 4/5 [00:56<00:14, 14.07s/epoch(s), Training loss(es)=[0.1932468  0.17268415 0.19132142 0.18419784 0.18705451]]Network training: 100%|███████████████████████████| 5/5 [00:56<00:00, 11.25s/epoch(s), Training loss(es)=[0.1932468  0.17268415 0.19132142 0.18419784 0.18705451]]
####################################################################
Starting training iteration 64.
Average action selection time:  0.3764383373260498
Rollout length:  1000
Rewards obtained: [5919.131771640879]
model train lenght 65000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.1888324  0.18976866 0.19515924 0.19256206 0.18836407]]Network training:  20%|█████▍                     | 1/5 [00:11<00:46, 11.68s/epoch(s), Training loss(es)=[0.1888324  0.18976866 0.19515924 0.19256206 0.18836407]]Network training:  20%|█████▍                     | 1/5 [00:20<01:23, 20.91s/epoch(s), Training loss(es)=[0.2067366  0.16650288 0.23390645 0.1866941  0.17153224]]Network training:  40%|██████████▊                | 2/5 [00:20<00:31, 10.45s/epoch(s), Training loss(es)=[0.2067366  0.16650288 0.23390645 0.1866941  0.17153224]]Network training:  40%|██████████▊                | 2/5 [00:29<00:44, 14.83s/epoch(s), Training loss(es)=[0.17728086 0.18205443 0.18683179 0.17637134 0.1724397 ]]Network training:  60%|████████████████▏          | 3/5 [00:29<00:19,  9.88s/epoch(s), Training loss(es)=[0.17728086 0.18205443 0.18683179 0.17637134 0.1724397 ]]Network training:  60%|████████████████▏          | 3/5 [00:38<00:25, 12.85s/epoch(s), Training loss(es)=[0.18388794 0.18530425 0.17352284 0.18736331 0.17981102]]Network training:  80%|█████████████████████▌     | 4/5 [00:38<00:09,  9.64s/epoch(s), Training loss(es)=[0.18388794 0.18530425 0.17352284 0.18736331 0.17981102]]Network training:  80%|█████████████████████▌     | 4/5 [00:49<00:12, 12.46s/epoch(s), Training loss(es)=[0.16260931 0.27827558 0.18706235 0.17322476 0.17459892]]Network training: 100%|███████████████████████████| 5/5 [00:49<00:00,  9.97s/epoch(s), Training loss(es)=[0.16260931 0.27827558 0.18706235 0.17322476 0.17459892]]
####################################################################
Starting training iteration 65.
Average action selection time:  0.3768490195274353
Rollout length:  1000
Rewards obtained: [4231.982202493091]
model train lenght 66000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.17706986 0.19576854 0.20177463 0.19012147 0.1868626 ]]Network training:  20%|█████▍                     | 1/5 [00:08<00:33,  8.27s/epoch(s), Training loss(es)=[0.17706986 0.19576854 0.20177463 0.19012147 0.1868626 ]]Network training:  20%|█████▍                     | 1/5 [00:16<01:06, 16.71s/epoch(s), Training loss(es)=[0.17425054 0.15783823 0.20957243 0.20342284 0.21121557]]Network training:  40%|██████████▊                | 2/5 [00:16<00:25,  8.35s/epoch(s), Training loss(es)=[0.17425054 0.15783823 0.20957243 0.20342284 0.21121557]]Network training:  40%|██████████▊                | 2/5 [00:25<00:37, 12.57s/epoch(s), Training loss(es)=[0.3745533  0.18073569 0.18699853 0.19027372 0.20140538]]Network training:  60%|████████████████▏          | 3/5 [00:25<00:16,  8.38s/epoch(s), Training loss(es)=[0.3745533  0.18073569 0.18699853 0.19027372 0.20140538]]Network training:  60%|████████████████▏          | 3/5 [00:33<00:22, 11.12s/epoch(s), Training loss(es)=[0.16759284 0.17494558 0.18340103 0.19819774 0.17438604]]Network training:  80%|█████████████████████▌     | 4/5 [00:33<00:08,  8.34s/epoch(s), Training loss(es)=[0.16759284 0.17494558 0.18340103 0.19819774 0.17438604]]Network training:  80%|█████████████████████▌     | 4/5 [00:52<00:13, 13.11s/epoch(s), Training loss(es)=[0.17253238 0.18004468 0.18610534 0.18365964 0.18011343]]Network training: 100%|███████████████████████████| 5/5 [00:52<00:00, 10.49s/epoch(s), Training loss(es)=[0.17253238 0.18004468 0.18610534 0.18365964 0.18011343]]
####################################################################
Starting training iteration 66.
Average action selection time:  0.36607307076454165
Rollout length:  1000
Rewards obtained: [5945.150829122045]
model train lenght 67000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.17748249 0.17877808 0.18049698 0.20915644 0.1863457 ]]Network training:  20%|█████▍                     | 1/5 [00:08<00:35,  8.88s/epoch(s), Training loss(es)=[0.17748249 0.17877808 0.18049698 0.20915644 0.1863457 ]]Network training:  20%|█████▍                     | 1/5 [00:17<01:10, 17.55s/epoch(s), Training loss(es)=[0.25507066 0.16525751 0.18455786 0.19229639 0.20184472]]Network training:  40%|██████████▊                | 2/5 [00:17<00:26,  8.77s/epoch(s), Training loss(es)=[0.25507066 0.16525751 0.18455786 0.19229639 0.20184472]]Network training:  40%|██████████▊                | 2/5 [00:26<00:39, 13.04s/epoch(s), Training loss(es)=[0.19472608 0.18268944 0.2092949  0.16986436 0.17543511]]Network training:  60%|████████████████▏          | 3/5 [00:26<00:17,  8.69s/epoch(s), Training loss(es)=[0.19472608 0.18268944 0.2092949  0.16986436 0.17543511]]Network training:  60%|████████████████▏          | 3/5 [00:41<00:27, 13.78s/epoch(s), Training loss(es)=[0.20538265 0.16889736 0.18333463 0.1730056  0.16672014]]Network training:  80%|█████████████████████▌     | 4/5 [00:41<00:10, 10.33s/epoch(s), Training loss(es)=[0.20538265 0.16889736 0.18333463 0.1730056  0.16672014]]Network training:  80%|█████████████████████▌     | 4/5 [01:01<00:15, 15.47s/epoch(s), Training loss(es)=[0.178609   0.17867307 0.17735708 0.18691985 0.1518847 ]]Network training: 100%|███████████████████████████| 5/5 [01:01<00:00, 12.37s/epoch(s), Training loss(es)=[0.178609   0.17867307 0.17735708 0.18691985 0.1518847 ]]
####################################################################
Starting training iteration 67.
Average action selection time:  0.3550840015411377
Rollout length:  1000
Rewards obtained: [5081.786162581154]
model train lenght 68000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.17384566 0.17536846 0.1840459  0.20034303 0.16249388]]Network training:  20%|█████▍                     | 1/5 [00:08<00:34,  8.60s/epoch(s), Training loss(es)=[0.17384566 0.17536846 0.1840459  0.20034303 0.16249388]]Network training:  20%|█████▍                     | 1/5 [00:17<01:08, 17.23s/epoch(s), Training loss(es)=[0.15610872 0.20817842 0.17669651 0.180075   0.167627  ]]Network training:  40%|██████████▊                | 2/5 [00:17<00:25,  8.61s/epoch(s), Training loss(es)=[0.15610872 0.20817842 0.17669651 0.180075   0.167627  ]]Network training:  40%|██████████▊                | 2/5 [00:28<00:42, 14.06s/epoch(s), Training loss(es)=[0.18665527 0.20297208 0.20016146 0.17333    0.1867638 ]]Network training:  60%|████████████████▏          | 3/5 [00:28<00:18,  9.38s/epoch(s), Training loss(es)=[0.18665527 0.20297208 0.20016146 0.17333    0.1867638 ]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.29s/epoch(s), Training loss(es)=[0.16490877 0.18235935 0.18444763 0.19920266 0.18403308]]Network training:  80%|█████████████████████▌     | 4/5 [00:48<00:12, 12.21s/epoch(s), Training loss(es)=[0.16490877 0.18235935 0.18444763 0.19920266 0.18403308]]Network training:  80%|█████████████████████▌     | 4/5 [01:09<00:17, 17.39s/epoch(s), Training loss(es)=[0.17157851 0.18180594 0.18490224 0.17383504 0.19244081]]Network training: 100%|███████████████████████████| 5/5 [01:09<00:00, 13.91s/epoch(s), Training loss(es)=[0.17157851 0.18180594 0.18490224 0.17383504 0.19244081]]
####################################################################
Starting training iteration 68.
Average action selection time:  0.34485948586463927
Rollout length:  1000
Rewards obtained: [4040.975727974947]
model train lenght 69000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:08<?, ?epoch(s)/s, Training loss(es)=[0.18058267 0.17219381 0.19380149 0.19693749 0.1935852 ]]Network training:  20%|█████▍                     | 1/5 [00:08<00:35,  8.88s/epoch(s), Training loss(es)=[0.18058267 0.17219381 0.19380149 0.19693749 0.1935852 ]]Network training:  20%|█████▍                     | 1/5 [00:17<01:11, 17.76s/epoch(s), Training loss(es)=[0.1856634  0.18375656 0.18795994 0.2683585  0.18263777]]Network training:  40%|██████████▊                | 2/5 [00:17<00:26,  8.88s/epoch(s), Training loss(es)=[0.1856634  0.18375656 0.18795994 0.2683585  0.18263777]]Network training:  40%|██████████▊                | 2/5 [00:37<00:56, 18.70s/epoch(s), Training loss(es)=[0.18194845 0.19540462 0.20461743 0.17298849 0.21034768]]Network training:  60%|████████████████▏          | 3/5 [00:37<00:24, 12.47s/epoch(s), Training loss(es)=[0.18194845 0.19540462 0.20461743 0.17298849 0.21034768]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.47s/epoch(s), Training loss(es)=[0.23752733 0.17764974 0.19485465 0.16692622 0.18221582]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.60s/epoch(s), Training loss(es)=[0.23752733 0.17764974 0.19485465 0.16692622 0.18221582]]Network training:  80%|█████████████████████▌     | 4/5 [01:19<00:19, 19.89s/epoch(s), Training loss(es)=[0.17175524 0.17252393 0.15843548 0.33576682 0.16740791]]Network training: 100%|███████████████████████████| 5/5 [01:19<00:00, 15.91s/epoch(s), Training loss(es)=[0.17175524 0.17252393 0.15843548 0.33576682 0.16740791]]
####################################################################
Starting training iteration 69.
Average action selection time:  0.33293264055252075
Rollout length:  1000
Rewards obtained: [6501.274812616375]
model train lenght 70000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:09<?, ?epoch(s)/s, Training loss(es)=[0.19441855 0.19726907 0.19612485 0.22893648 0.19410823]]Network training:  20%|█████▍                     | 1/5 [00:09<00:38,  9.67s/epoch(s), Training loss(es)=[0.19441855 0.19726907 0.19612485 0.22893648 0.19410823]]Network training:  20%|█████▍                     | 1/5 [00:26<01:47, 26.76s/epoch(s), Training loss(es)=[0.18287495 0.17464651 0.18802702 0.217953   0.20175046]]Network training:  40%|██████████▊                | 2/5 [00:26<00:40, 13.38s/epoch(s), Training loss(es)=[0.18287495 0.17464651 0.18802702 0.217953   0.20175046]]Network training:  40%|██████████▊                | 2/5 [00:48<01:12, 24.11s/epoch(s), Training loss(es)=[0.16727668 0.15919356 0.16761033 0.18592682 0.17124307]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.07s/epoch(s), Training loss(es)=[0.16727668 0.15919356 0.16761033 0.18592682 0.17124307]]Network training:  60%|████████████████▏          | 3/5 [01:09<00:46, 23.20s/epoch(s), Training loss(es)=[0.15522607 0.17651707 0.3206074  0.18396294 0.16685408]]Network training:  80%|█████████████████████▌     | 4/5 [01:09<00:17, 17.40s/epoch(s), Training loss(es)=[0.15522607 0.17651707 0.3206074  0.18396294 0.16685408]]Network training:  80%|█████████████████████▌     | 4/5 [01:31<00:22, 22.78s/epoch(s), Training loss(es)=[0.16972919 0.1747342  0.19959994 0.17541763 0.16582528]]Network training: 100%|███████████████████████████| 5/5 [01:31<00:00, 18.22s/epoch(s), Training loss(es)=[0.16972919 0.1747342  0.19959994 0.17541763 0.16582528]]
####################################################################
Starting training iteration 70.
Average action selection time:  0.3195460653305054
Rollout length:  1000
Rewards obtained: [4045.188692500576]
model train lenght 71000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.15733638 0.1806631  0.1837542  0.19226097 0.1806853 ]]Network training:  20%|█████▍                     | 1/5 [00:13<00:55, 13.78s/epoch(s), Training loss(es)=[0.15733638 0.1806631  0.1837542  0.19226097 0.1806853 ]]Network training:  20%|█████▍                     | 1/5 [00:35<02:21, 35.50s/epoch(s), Training loss(es)=[0.22143213 0.17272268 0.36134705 0.1950936  0.17176162]]Network training:  40%|██████████▊                | 2/5 [00:35<00:53, 17.75s/epoch(s), Training loss(es)=[0.22143213 0.17272268 0.36134705 0.1950936  0.17176162]]Network training:  40%|██████████▊                | 2/5 [00:57<01:25, 28.59s/epoch(s), Training loss(es)=[0.19857575 0.18454099 0.181848   0.1893326  0.16986202]]Network training:  60%|████████████████▏          | 3/5 [00:57<00:38, 19.06s/epoch(s), Training loss(es)=[0.19857575 0.18454099 0.181848   0.1893326  0.16986202]]Network training:  60%|████████████████▏          | 3/5 [01:18<00:52, 26.30s/epoch(s), Training loss(es)=[0.16696091 0.1794212  0.19447793 0.18615137 0.16621487]]Network training:  80%|█████████████████████▌     | 4/5 [01:18<00:19, 19.73s/epoch(s), Training loss(es)=[0.16696091 0.1794212  0.19447793 0.18615137 0.16621487]]Network training:  80%|█████████████████████▌     | 4/5 [01:40<00:25, 25.15s/epoch(s), Training loss(es)=[0.18591927 0.16779907 0.23627134 0.16688348 0.1757313 ]]Network training: 100%|███████████████████████████| 5/5 [01:40<00:00, 20.12s/epoch(s), Training loss(es)=[0.18591927 0.16779907 0.23627134 0.16688348 0.1757313 ]]
####################################################################
Starting training iteration 71.
Average action selection time:  0.30702071356773375
Rollout length:  1000
Rewards obtained: [6323.23127304849]
model train lenght 72000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.18953758 0.19073333 0.23554231 0.20108728 0.17855933]]Network training:  20%|█████▍                     | 1/5 [00:21<01:26, 21.73s/epoch(s), Training loss(es)=[0.18953758 0.19073333 0.23554231 0.20108728 0.17855933]]Network training:  20%|█████▍                     | 1/5 [00:43<02:55, 43.95s/epoch(s), Training loss(es)=[0.17497173 0.18271123 0.16774866 0.18051516 0.2876189 ]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.98s/epoch(s), Training loss(es)=[0.17497173 0.18271123 0.16774866 0.18051516 0.2876189 ]]Network training:  40%|██████████▊                | 2/5 [01:06<01:39, 33.09s/epoch(s), Training loss(es)=[0.20699902 0.18583599 0.17417516 0.16547403 0.20041032]]Network training:  60%|████████████████▏          | 3/5 [01:06<00:44, 22.06s/epoch(s), Training loss(es)=[0.20699902 0.18583599 0.17417516 0.16547403 0.20041032]]Network training:  60%|████████████████▏          | 3/5 [01:28<00:58, 29.47s/epoch(s), Training loss(es)=[0.19074188 0.17083053 0.17919569 0.17887484 0.1869754 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:28<00:22, 22.11s/epoch(s), Training loss(es)=[0.19074188 0.17083053 0.17919569 0.17887484 0.1869754 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:50<00:27, 27.66s/epoch(s), Training loss(es)=[0.17172381 0.16988008 0.19176716 0.19809091 0.17768103]]Network training: 100%|███████████████████████████| 5/5 [01:50<00:00, 22.13s/epoch(s), Training loss(es)=[0.17172381 0.16988008 0.19176716 0.19809091 0.17768103]]
####################################################################
Starting training iteration 72.
Average action selection time:  0.3042901058197022
Rollout length:  1000
Rewards obtained: [1836.091618936801]
model train lenght 73000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.17405528 0.17513484 0.16719137 0.17560703 0.2048829 ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:29, 22.46s/epoch(s), Training loss(es)=[0.17405528 0.17513484 0.16719137 0.17560703 0.2048829 ]]Network training:  20%|█████▍                     | 1/5 [00:45<03:00, 45.01s/epoch(s), Training loss(es)=[0.19737065 0.17259504 0.18253273 0.1836091  0.16739315]]Network training:  40%|██████████▊                | 2/5 [00:45<01:07, 22.51s/epoch(s), Training loss(es)=[0.19737065 0.17259504 0.18253273 0.1836091  0.16739315]]Network training:  40%|██████████▊                | 2/5 [01:07<01:41, 33.76s/epoch(s), Training loss(es)=[0.18353848 0.19335759 0.19680841 0.18391961 0.18078434]]Network training:  60%|████████████████▏          | 3/5 [01:07<00:45, 22.51s/epoch(s), Training loss(es)=[0.18353848 0.19335759 0.19680841 0.18391961 0.18078434]]Network training:  60%|████████████████▏          | 3/5 [01:29<00:59, 30.00s/epoch(s), Training loss(es)=[0.18961136 0.17854218 0.18217573 0.16218542 0.27034327]]Network training:  80%|█████████████████████▌     | 4/5 [01:29<00:22, 22.50s/epoch(s), Training loss(es)=[0.18961136 0.17854218 0.18217573 0.16218542 0.27034327]]Network training:  80%|█████████████████████▌     | 4/5 [01:52<00:28, 28.13s/epoch(s), Training loss(es)=[0.17110094 0.17093718 0.22628742 0.22190279 0.18403749]]Network training: 100%|███████████████████████████| 5/5 [01:52<00:00, 22.50s/epoch(s), Training loss(es)=[0.17110094 0.17093718 0.22628742 0.22190279 0.18403749]]
####################################################################
Starting training iteration 73.
Average action selection time:  0.3037563729286194
Rollout length:  1000
Rewards obtained: [6069.401131550876]
model train lenght 74000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.2024256  0.18246211 0.19664286 0.18908817 0.20335752]]Network training:  20%|█████▍                     | 1/5 [00:22<01:30, 22.65s/epoch(s), Training loss(es)=[0.2024256  0.18246211 0.19664286 0.18908817 0.20335752]]Network training:  20%|█████▍                     | 1/5 [00:45<03:00, 45.24s/epoch(s), Training loss(es)=[0.19701962 0.16938736 0.18806443 0.18085906 0.16713701]]Network training:  40%|██████████▊                | 2/5 [00:45<01:07, 22.62s/epoch(s), Training loss(es)=[0.19701962 0.16938736 0.18806443 0.18085906 0.16713701]]Network training:  40%|██████████▊                | 2/5 [01:07<01:41, 33.97s/epoch(s), Training loss(es)=[0.16432233 0.1911871  0.28036124 0.16899933 0.16987206]]Network training:  60%|████████████████▏          | 3/5 [01:07<00:45, 22.65s/epoch(s), Training loss(es)=[0.16432233 0.1911871  0.28036124 0.16899933 0.16987206]]Network training:  60%|████████████████▏          | 3/5 [01:30<01:00, 30.24s/epoch(s), Training loss(es)=[0.20550919 0.31179535 0.17977458 0.17079376 0.17857859]]Network training:  80%|█████████████████████▌     | 4/5 [01:30<00:22, 22.68s/epoch(s), Training loss(es)=[0.20550919 0.31179535 0.17977458 0.17079376 0.17857859]]Network training:  80%|█████████████████████▌     | 4/5 [01:53<00:28, 28.38s/epoch(s), Training loss(es)=[0.19485371 0.16208054 0.15252487 0.17670667 0.16955732]]Network training: 100%|███████████████████████████| 5/5 [01:53<00:00, 22.70s/epoch(s), Training loss(es)=[0.19485371 0.16208054 0.15252487 0.17670667 0.16955732]]
####################################################################
Starting training iteration 74.
Average action selection time:  0.30327999305725095
Rollout length:  1000
Rewards obtained: [3667.9138351201186]
model train lenght 75000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.1938691  0.16814911 0.1901782  0.18203148 0.17894621]]Network training:  20%|█████▍                     | 1/5 [00:23<01:32, 23.06s/epoch(s), Training loss(es)=[0.1938691  0.16814911 0.1901782  0.18203148 0.17894621]]Network training:  20%|█████▍                     | 1/5 [00:46<03:04, 46.03s/epoch(s), Training loss(es)=[0.16312572 0.1922364  0.19065832 0.18167925 0.15813902]]Network training:  40%|██████████▊                | 2/5 [00:46<01:09, 23.02s/epoch(s), Training loss(es)=[0.16312572 0.1922364  0.19065832 0.18167925 0.15813902]]Network training:  40%|██████████▊                | 2/5 [01:09<01:43, 34.54s/epoch(s), Training loss(es)=[0.1832601  0.1715689  0.16518776 0.21808776 0.16608807]]Network training:  60%|████████████████▏          | 3/5 [01:09<00:46, 23.03s/epoch(s), Training loss(es)=[0.1832601  0.1715689  0.16518776 0.21808776 0.16608807]]Network training:  60%|████████████████▏          | 3/5 [01:32<01:01, 30.73s/epoch(s), Training loss(es)=[0.16037339 0.1837456  0.19489913 0.19873755 0.18895636]]Network training:  80%|█████████████████████▌     | 4/5 [01:32<00:23, 23.05s/epoch(s), Training loss(es)=[0.16037339 0.1837456  0.19489913 0.19873755 0.18895636]]Network training:  80%|█████████████████████▌     | 4/5 [01:55<00:28, 28.82s/epoch(s), Training loss(es)=[0.18275394 0.16612628 0.19832219 0.17913085 0.16588272]]Network training: 100%|███████████████████████████| 5/5 [01:55<00:00, 23.06s/epoch(s), Training loss(es)=[0.18275394 0.16612628 0.19832219 0.17913085 0.16588272]]
####################################################################
Starting training iteration 75.
Average action selection time:  0.30175985765457153
Rollout length:  1000
Rewards obtained: [4736.782517993116]
model train lenght 76000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.20547278 0.16802175 0.17920037 0.19085552 0.17064512]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.45s/epoch(s), Training loss(es)=[0.20547278 0.16802175 0.17920037 0.19085552 0.17064512]]Network training:  20%|█████▍                     | 1/5 [00:46<03:07, 46.86s/epoch(s), Training loss(es)=[0.23641053 0.17942607 0.18459098 0.17455828 0.16557647]]Network training:  40%|██████████▊                | 2/5 [00:46<01:10, 23.43s/epoch(s), Training loss(es)=[0.23641053 0.17942607 0.18459098 0.17455828 0.16557647]]Network training:  40%|██████████▊                | 2/5 [01:10<01:45, 35.18s/epoch(s), Training loss(es)=[0.18318662 0.18267651 0.18380786 0.20767517 0.2564876 ]]Network training:  60%|████████████████▏          | 3/5 [01:10<00:46, 23.45s/epoch(s), Training loss(es)=[0.18318662 0.18267651 0.18380786 0.20767517 0.2564876 ]]Network training:  60%|████████████████▏          | 3/5 [01:33<01:02, 31.25s/epoch(s), Training loss(es)=[0.15769985 0.18583949 0.17145589 0.200621   0.17056194]]Network training:  80%|█████████████████████▌     | 4/5 [01:33<00:23, 23.44s/epoch(s), Training loss(es)=[0.15769985 0.18583949 0.17145589 0.200621   0.17056194]]Network training:  80%|█████████████████████▌     | 4/5 [01:57<00:29, 29.27s/epoch(s), Training loss(es)=[0.17556232 0.15803558 0.1726336  0.16480209 0.16676389]]Network training: 100%|███████████████████████████| 5/5 [01:57<00:00, 23.42s/epoch(s), Training loss(es)=[0.17556232 0.15803558 0.1726336  0.16480209 0.16676389]]
####################################################################
Starting training iteration 76.
Average action selection time:  0.30066156554222107
Rollout length:  1000
Rewards obtained: [1778.5750454314882]
model train lenght 77000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.17214659 0.19820441 0.20180771 0.18414985 0.17662089]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 23.79s/epoch(s), Training loss(es)=[0.17214659 0.19820441 0.20180771 0.18414985 0.17662089]]Network training:  20%|█████▍                     | 1/5 [00:47<03:09, 47.36s/epoch(s), Training loss(es)=[0.15867604 0.1794681  0.18799363 0.18970518 0.16950004]]Network training:  40%|██████████▊                | 2/5 [00:47<01:11, 23.68s/epoch(s), Training loss(es)=[0.15867604 0.1794681  0.18799363 0.18970518 0.16950004]]Network training:  40%|██████████▊                | 2/5 [01:11<01:46, 35.50s/epoch(s), Training loss(es)=[0.17692693 0.18965879 0.16206081 0.20937115 0.15689953]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.67s/epoch(s), Training loss(es)=[0.17692693 0.18965879 0.16206081 0.20937115 0.15689953]]Network training:  60%|████████████████▏          | 3/5 [01:34<01:03, 31.55s/epoch(s), Training loss(es)=[0.16921024 0.17590141 0.1717755  0.16684902 0.18550903]]Network training:  80%|█████████████████████▌     | 4/5 [01:34<00:23, 23.66s/epoch(s), Training loss(es)=[0.16921024 0.17590141 0.1717755  0.16684902 0.18550903]]Network training:  80%|█████████████████████▌     | 4/5 [01:58<00:29, 29.59s/epoch(s), Training loss(es)=[0.2075219  0.18268797 0.17846164 0.19268818 0.17038994]]Network training: 100%|███████████████████████████| 5/5 [01:58<00:00, 23.67s/epoch(s), Training loss(es)=[0.2075219  0.18268797 0.17846164 0.19268818 0.17038994]]
####################################################################
Starting training iteration 77.
Average action selection time:  0.2989359471797943
Rollout length:  1000
Rewards obtained: [4706.260399214807]
model train lenght 78000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.1733481  0.20556118 0.18380964 0.19421677 0.17300421]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.03s/epoch(s), Training loss(es)=[0.1733481  0.20556118 0.18380964 0.19421677 0.17300421]]Network training:  20%|█████▍                     | 1/5 [00:47<03:11, 48.00s/epoch(s), Training loss(es)=[0.16214114 0.19612019 0.19372642 0.17557618 0.20791577]]Network training:  40%|██████████▊                | 2/5 [00:47<01:11, 24.00s/epoch(s), Training loss(es)=[0.16214114 0.19612019 0.19372642 0.17557618 0.20791577]]Network training:  40%|██████████▊                | 2/5 [01:11<01:47, 35.95s/epoch(s), Training loss(es)=[0.18058471 0.19207275 0.17138813 0.17999591 0.17427406]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.96s/epoch(s), Training loss(es)=[0.18058471 0.19207275 0.17138813 0.17999591 0.17427406]]Network training:  60%|████████████████▏          | 3/5 [01:35<01:03, 31.95s/epoch(s), Training loss(es)=[0.21704422 0.24074605 0.19203846 0.17164402 0.14934315]]Network training:  80%|█████████████████████▌     | 4/5 [01:35<00:23, 23.96s/epoch(s), Training loss(es)=[0.21704422 0.24074605 0.19203846 0.17164402 0.14934315]]Network training:  80%|█████████████████████▌     | 4/5 [01:59<00:29, 29.96s/epoch(s), Training loss(es)=[0.16887903 0.16523172 0.18707132 0.3055258  0.14709516]]Network training: 100%|███████████████████████████| 5/5 [01:59<00:00, 23.97s/epoch(s), Training loss(es)=[0.16887903 0.16523172 0.18707132 0.3055258  0.14709516]]
####################################################################
Starting training iteration 78.
Average action selection time:  0.29828617906570437
Rollout length:  1000
Rewards obtained: [4525.548581288614]
model train lenght 79000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.2079468  0.1793406  0.18116926 0.17386913 0.17627989]]Network training:  20%|█████▍                     | 1/5 [00:24<01:37, 24.30s/epoch(s), Training loss(es)=[0.2079468  0.1793406  0.18116926 0.17386913 0.17627989]]Network training:  20%|█████▍                     | 1/5 [00:48<03:14, 48.65s/epoch(s), Training loss(es)=[0.22892195 0.16652122 0.17090826 0.17497243 0.17870228]]Network training:  40%|██████████▊                | 2/5 [00:48<01:12, 24.32s/epoch(s), Training loss(es)=[0.22892195 0.16652122 0.17090826 0.17497243 0.17870228]]Network training:  40%|██████████▊                | 2/5 [01:12<01:49, 36.47s/epoch(s), Training loss(es)=[0.17797856 0.18841997 0.17165273 0.18050358 0.18027763]]Network training:  60%|████████████████▏          | 3/5 [01:12<00:48, 24.31s/epoch(s), Training loss(es)=[0.17797856 0.18841997 0.17165273 0.18050358 0.18027763]]Network training:  60%|████████████████▏          | 3/5 [01:37<01:04, 32.40s/epoch(s), Training loss(es)=[0.17239    0.19321562 0.17444216 0.17601025 0.177484  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:37<00:24, 24.30s/epoch(s), Training loss(es)=[0.17239    0.19321562 0.17444216 0.17601025 0.177484  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:54<00:28, 28.51s/epoch(s), Training loss(es)=[0.23435615 0.18126585 0.17589095 0.17460446 0.16126294]]Network training: 100%|███████████████████████████| 5/5 [01:54<00:00, 22.80s/epoch(s), Training loss(es)=[0.23435615 0.18126585 0.17589095 0.17460446 0.16126294]]
####################################################################
Starting training iteration 79.
Average action selection time:  0.30679539585113524
Rollout length:  1000
Rewards obtained: [4828.6552282485345]
model train lenght 80000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.15454009 0.19099765 0.19294333 0.17201154 0.2427831 ]]Network training:  20%|█████▍                     | 1/5 [00:24<01:38, 24.53s/epoch(s), Training loss(es)=[0.15454009 0.19099765 0.19294333 0.17201154 0.2427831 ]]Network training:  20%|█████▍                     | 1/5 [00:49<03:16, 49.00s/epoch(s), Training loss(es)=[0.18699443 0.28466803 0.18349846 0.17048676 0.16444251]]Network training:  40%|██████████▊                | 2/5 [00:49<01:13, 24.50s/epoch(s), Training loss(es)=[0.18699443 0.28466803 0.18349846 0.17048676 0.16444251]]Network training:  40%|██████████▊                | 2/5 [01:13<01:50, 36.76s/epoch(s), Training loss(es)=[0.19816989 0.21109739 0.17131539 0.18694809 0.17175071]]Network training:  60%|████████████████▏          | 3/5 [01:13<00:49, 24.51s/epoch(s), Training loss(es)=[0.19816989 0.21109739 0.17131539 0.18694809 0.17175071]]Network training:  60%|████████████████▏          | 3/5 [01:35<01:03, 31.88s/epoch(s), Training loss(es)=[0.18651931 0.17473271 0.18310857 0.19343887 0.17407317]]Network training:  80%|█████████████████████▌     | 4/5 [01:35<00:23, 23.91s/epoch(s), Training loss(es)=[0.18651931 0.17473271 0.18310857 0.19343887 0.17407317]]Network training:  80%|█████████████████████▌     | 4/5 [01:45<00:26, 26.45s/epoch(s), Training loss(es)=[0.16407186 0.18735442 0.16994761 0.18629472 0.14745806]]Network training: 100%|███████████████████████████| 5/5 [01:45<00:00, 21.16s/epoch(s), Training loss(es)=[0.16407186 0.18735442 0.16994761 0.18629472 0.14745806]]
####################################################################
Starting training iteration 80.
Average action selection time:  0.3169339168071747
Rollout length:  1000
Rewards obtained: [5242.542409227128]
model train lenght 81000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.1706542  0.17715465 0.35772672 0.2000134  0.20877676]]Network training:  20%|█████▍                     | 1/5 [00:24<01:38, 24.74s/epoch(s), Training loss(es)=[0.1706542  0.17715465 0.35772672 0.2000134  0.20877676]]Network training:  20%|█████▍                     | 1/5 [00:49<03:18, 49.55s/epoch(s), Training loss(es)=[0.18514039 0.17851882 0.21282114 0.18874085 0.15699558]]Network training:  40%|██████████▊                | 2/5 [00:49<01:14, 24.77s/epoch(s), Training loss(es)=[0.18514039 0.17851882 0.21282114 0.18874085 0.15699558]]Network training:  40%|██████████▊                | 2/5 [01:14<01:51, 37.23s/epoch(s), Training loss(es)=[0.17460771 0.18283242 0.23798832 0.22723114 0.17514567]]Network training:  60%|████████████████▏          | 3/5 [01:14<00:49, 24.82s/epoch(s), Training loss(es)=[0.17460771 0.18283242 0.23798832 0.22723114 0.17514567]]Network training:  60%|████████████████▏          | 3/5 [01:28<00:59, 29.61s/epoch(s), Training loss(es)=[0.1536393  0.16965619 0.17998561 0.17327869 0.17272548]]Network training:  80%|█████████████████████▌     | 4/5 [01:28<00:22, 22.21s/epoch(s), Training loss(es)=[0.1536393  0.16965619 0.17998561 0.17327869 0.17272548]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.87s/epoch(s), Training loss(es)=[0.15513225 0.16805278 0.18500023 0.18311973 0.17231104]]Network training: 100%|███████████████████████████| 5/5 [01:39<00:00, 19.89s/epoch(s), Training loss(es)=[0.15513225 0.16805278 0.18500023 0.18311973 0.17231104]]
####################################################################
Starting training iteration 81.
Average action selection time:  0.3281299338340759
Rollout length:  1000
Rewards obtained: [6497.5347789589005]
model train lenght 82000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:25<?, ?epoch(s)/s, Training loss(es)=[0.17297198 0.1750619  0.18740779 0.21540159 0.16746394]]Network training:  20%|█████▍                     | 1/5 [00:25<01:40, 25.23s/epoch(s), Training loss(es)=[0.17297198 0.1750619  0.18740779 0.21540159 0.16746394]]Network training:  20%|█████▍                     | 1/5 [00:50<03:21, 50.50s/epoch(s), Training loss(es)=[0.21832494 0.1758258  0.19091702 0.20478778 0.16286527]]Network training:  40%|██████████▊                | 2/5 [00:50<01:15, 25.25s/epoch(s), Training loss(es)=[0.21832494 0.1758258  0.19091702 0.20478778 0.16286527]]Network training:  40%|██████████▊                | 2/5 [01:10<01:45, 35.29s/epoch(s), Training loss(es)=[0.37430355 0.22215283 0.22715081 0.20631875 0.18944745]]Network training:  60%|████████████████▏          | 3/5 [01:10<00:47, 23.53s/epoch(s), Training loss(es)=[0.37430355 0.22215283 0.22715081 0.20631875 0.18944745]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.12s/epoch(s), Training loss(es)=[0.24418657 0.17211062 0.21079014 0.21379079 0.1713538 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.34s/epoch(s), Training loss(es)=[0.24418657 0.17211062 0.21079014 0.21379079 0.1713538 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:32<00:23, 23.09s/epoch(s), Training loss(es)=[0.18792927 0.15591045 0.17197762 0.16639706 0.18024428]]Network training: 100%|███████████████████████████| 5/5 [01:32<00:00, 18.47s/epoch(s), Training loss(es)=[0.18792927 0.15591045 0.17197762 0.16639706 0.18024428]]
####################################################################
Starting training iteration 82.
Average action selection time:  0.3421541278362274
Rollout length:  1000
Rewards obtained: [3105.8830994380037]
model train lenght 83000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:25<?, ?epoch(s)/s, Training loss(es)=[0.20294417 0.19900478 0.1689549  0.19948298 0.19819553]]Network training:  20%|█████▍                     | 1/5 [00:25<01:41, 25.49s/epoch(s), Training loss(es)=[0.20294417 0.19900478 0.1689549  0.19948298 0.19819553]]Network training:  20%|█████▍                     | 1/5 [00:49<03:19, 49.83s/epoch(s), Training loss(es)=[0.1707625  0.19799556 0.31418326 0.19901043 0.18423949]]Network training:  40%|██████████▊                | 2/5 [00:49<01:14, 24.92s/epoch(s), Training loss(es)=[0.1707625  0.19799556 0.31418326 0.19901043 0.18423949]]Network training:  40%|██████████▊                | 2/5 [01:01<01:31, 30.52s/epoch(s), Training loss(es)=[0.23084861 0.21003504 0.197006   0.1933354  0.18428345]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:40, 20.35s/epoch(s), Training loss(es)=[0.23084861 0.21003504 0.197006   0.1933354  0.18428345]]Network training:  60%|████████████████▏          | 3/5 [01:12<00:48, 24.02s/epoch(s), Training loss(es)=[0.17439081 0.1713104  0.1588811  0.18643518 0.16107038]]Network training:  80%|█████████████████████▌     | 4/5 [01:12<00:18, 18.02s/epoch(s), Training loss(es)=[0.17439081 0.1713104  0.1588811  0.18643518 0.16107038]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.80s/epoch(s), Training loss(es)=[0.17543377 0.170005   0.17223428 0.1718555  0.1878342 ]]Network training: 100%|███████████████████████████| 5/5 [01:23<00:00, 16.64s/epoch(s), Training loss(es)=[0.17543377 0.170005   0.17223428 0.1718555  0.1878342 ]]
####################################################################
Starting training iteration 83.
Average action selection time:  0.36032643604278564
Rollout length:  1000
Rewards obtained: [5418.203415794731]
model train lenght 84000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:25<?, ?epoch(s)/s, Training loss(es)=[0.17774525 0.1787537  0.20340566 0.19265784 0.19445045]]Network training:  20%|█████▍                     | 1/5 [00:25<01:42, 25.67s/epoch(s), Training loss(es)=[0.17774525 0.1787537  0.20340566 0.19265784 0.19445045]]Network training:  20%|█████▍                     | 1/5 [00:36<02:25, 36.35s/epoch(s), Training loss(es)=[0.19155307 0.17024036 0.21695173 0.19119701 0.1802068 ]]Network training:  40%|██████████▊                | 2/5 [00:36<00:54, 18.18s/epoch(s), Training loss(es)=[0.19155307 0.17024036 0.21695173 0.19119701 0.1802068 ]]Network training:  40%|██████████▊                | 2/5 [00:47<01:10, 23.60s/epoch(s), Training loss(es)=[0.18479475 0.1738136  0.17941199 0.18155791 0.17944169]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.74s/epoch(s), Training loss(es)=[0.18479475 0.1738136  0.17941199 0.18155791 0.17944169]]Network training:  60%|████████████████▏          | 3/5 [00:57<00:38, 19.17s/epoch(s), Training loss(es)=[0.18050922 0.16999136 0.17716794 0.1734079  0.16566798]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.38s/epoch(s), Training loss(es)=[0.18050922 0.16999136 0.17716794 0.1734079  0.16566798]]Network training:  80%|█████████████████████▌     | 4/5 [01:07<00:16, 16.95s/epoch(s), Training loss(es)=[0.15444112 0.18529166 0.16346721 0.20990598 0.21321155]]Network training: 100%|███████████████████████████| 5/5 [01:07<00:00, 13.56s/epoch(s), Training loss(es)=[0.15444112 0.18529166 0.16346721 0.20990598 0.21321155]]
####################################################################
Starting training iteration 84.
Average action selection time:  0.36991466021537783
Rollout length:  1000
Rewards obtained: [6755.0489452461525]
model train lenght 85000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.24771528 0.2663837  0.18955424 0.17999196 0.22949877]]Network training:  20%|█████▍                     | 1/5 [00:18<01:15, 18.81s/epoch(s), Training loss(es)=[0.24771528 0.2663837  0.18955424 0.17999196 0.22949877]]Network training:  20%|█████▍                     | 1/5 [00:30<02:01, 30.33s/epoch(s), Training loss(es)=[0.18996798 0.21231419 0.18748356 0.21111219 0.15049885]]Network training:  40%|██████████▊                | 2/5 [00:30<00:45, 15.17s/epoch(s), Training loss(es)=[0.18996798 0.21231419 0.18748356 0.21111219 0.15049885]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.72s/epoch(s), Training loss(es)=[0.17446592 0.17850958 0.18686117 0.21037254 0.18630764]]Network training:  60%|████████████████▏          | 3/5 [00:41<00:27, 13.82s/epoch(s), Training loss(es)=[0.17446592 0.17850958 0.18686117 0.21037254 0.18630764]]Network training:  60%|████████████████▏          | 3/5 [00:52<00:35, 17.62s/epoch(s), Training loss(es)=[0.20195152 0.17993718 0.17288813 0.18045044 0.18997537]]Network training:  80%|█████████████████████▌     | 4/5 [00:52<00:13, 13.21s/epoch(s), Training loss(es)=[0.20195152 0.17993718 0.17288813 0.18045044 0.18997537]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 16.00s/epoch(s), Training loss(es)=[0.17397214 0.18392436 0.17460671 0.19242619 0.17498192]]Network training: 100%|███████████████████████████| 5/5 [01:03<00:00, 12.80s/epoch(s), Training loss(es)=[0.17397214 0.18392436 0.17460671 0.19242619 0.17498192]]
####################################################################
Starting training iteration 85.
Average action selection time:  0.3802294943332672
Rollout length:  1000
Rewards obtained: [6939.48558809154]
model train lenght 86000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:10<?, ?epoch(s)/s, Training loss(es)=[0.1854234  0.20180728 0.18050721 0.22433056 0.36094213]]Network training:  20%|█████▍                     | 1/5 [00:10<00:43, 10.84s/epoch(s), Training loss(es)=[0.1854234  0.20180728 0.18050721 0.22433056 0.36094213]]Network training:  20%|█████▍                     | 1/5 [00:22<01:28, 22.00s/epoch(s), Training loss(es)=[0.17572726 0.181507   0.19145854 0.19121861 0.20529428]]Network training:  40%|██████████▊                | 2/5 [00:22<00:33, 11.00s/epoch(s), Training loss(es)=[0.17572726 0.181507   0.19145854 0.19121861 0.20529428]]Network training:  40%|██████████▊                | 2/5 [00:32<00:49, 16.48s/epoch(s), Training loss(es)=[0.18930683 0.15537003 0.20066488 0.21176365 0.18138069]]Network training:  60%|████████████████▏          | 3/5 [00:32<00:21, 10.99s/epoch(s), Training loss(es)=[0.18930683 0.15537003 0.20066488 0.21176365 0.18138069]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.68s/epoch(s), Training loss(es)=[0.19387203 0.17616455 0.25896025 0.18310513 0.16639729]]Network training:  80%|█████████████████████▌     | 4/5 [00:44<00:11, 11.01s/epoch(s), Training loss(es)=[0.19387203 0.17616455 0.25896025 0.18310513 0.16639729]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.38s/epoch(s), Training loss(es)=[0.19218633 0.16945253 0.169251   0.19695824 0.16247971]]Network training: 100%|███████████████████████████| 5/5 [00:57<00:00, 11.51s/epoch(s), Training loss(es)=[0.19218633 0.16945253 0.169251   0.19695824 0.16247971]]
####################################################################
Starting training iteration 86.
Average action selection time:  0.3769255154132843
Rollout length:  1000
Rewards obtained: [5827.510481336232]
model train lenght 87000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.27797645 0.21038274 0.18932313 0.20283164 0.16497812]]Network training:  20%|█████▍                     | 1/5 [00:11<00:47, 11.96s/epoch(s), Training loss(es)=[0.27797645 0.21038274 0.18932313 0.20283164 0.16497812]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.03s/epoch(s), Training loss(es)=[0.18598649 0.18648382 0.21425723 0.20433831 0.16940369]]Network training:  40%|██████████▊                | 2/5 [00:24<00:36, 12.01s/epoch(s), Training loss(es)=[0.18598649 0.18648382 0.21425723 0.20433831 0.16940369]]Network training:  40%|██████████▊                | 2/5 [00:35<00:53, 17.86s/epoch(s), Training loss(es)=[0.19396356 0.17546    0.17348976 0.19322422 0.19653021]]Network training:  60%|████████████████▏          | 3/5 [00:35<00:23, 11.91s/epoch(s), Training loss(es)=[0.19396356 0.17546    0.17348976 0.19322422 0.19653021]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.91s/epoch(s), Training loss(es)=[0.21848352 0.16210751 0.17035301 0.16649562 0.15897849]]Network training:  80%|█████████████████████▌     | 4/5 [00:47<00:11, 11.93s/epoch(s), Training loss(es)=[0.21848352 0.16210751 0.17035301 0.16649562 0.15897849]]Network training:  80%|█████████████████████▌     | 4/5 [01:14<00:18, 18.53s/epoch(s), Training loss(es)=[0.17930427 0.16376378 0.16116443 0.1946469  0.14762807]]Network training: 100%|███████████████████████████| 5/5 [01:14<00:00, 14.82s/epoch(s), Training loss(es)=[0.17930427 0.16376378 0.16116443 0.1946469  0.14762807]]
####################################################################
Starting training iteration 87.
Average action selection time:  0.3586897521018982
Rollout length:  1000
Rewards obtained: [5960.390366168183]
model train lenght 88000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.19193707 0.19729362 0.17499499 0.18950877 0.17811571]]Network training:  20%|█████▍                     | 1/5 [00:11<00:46, 11.64s/epoch(s), Training loss(es)=[0.19193707 0.19729362 0.17499499 0.18950877 0.17811571]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.43s/epoch(s), Training loss(es)=[0.18212718 0.1854003  0.17257923 0.23253137 0.18030222]]Network training:  40%|██████████▊                | 2/5 [00:23<00:35, 11.71s/epoch(s), Training loss(es)=[0.18212718 0.1854003  0.17257923 0.23253137 0.18030222]]Network training:  40%|██████████▊                | 2/5 [00:35<00:52, 17.53s/epoch(s), Training loss(es)=[0.1913927  0.17984712 0.16894582 0.1799123  0.19389905]]Network training:  60%|████████████████▏          | 3/5 [00:35<00:23, 11.69s/epoch(s), Training loss(es)=[0.1913927  0.17984712 0.16894582 0.1799123  0.19389905]]Network training:  60%|████████████████▏          | 3/5 [00:59<00:39, 19.69s/epoch(s), Training loss(es)=[0.18293029 0.17757596 0.1722685  0.19767179 0.18185464]]Network training:  80%|█████████████████████▌     | 4/5 [00:59<00:14, 14.77s/epoch(s), Training loss(es)=[0.18293029 0.17757596 0.1722685  0.19767179 0.18185464]]Network training:  80%|█████████████████████▌     | 4/5 [01:26<00:21, 21.56s/epoch(s), Training loss(es)=[0.16700442 0.16857593 0.20010054 0.17330775 0.1563321 ]]Network training: 100%|███████████████████████████| 5/5 [01:26<00:00, 17.25s/epoch(s), Training loss(es)=[0.16700442 0.16857593 0.20010054 0.17330775 0.1563321 ]]
####################################################################
Starting training iteration 88.
Average action selection time:  0.34240506052970887
Rollout length:  1000
Rewards obtained: [6036.269052090732]
model train lenght 89000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.22765455 0.19505975 0.22771518 0.25266758 0.1821356 ]]Network training:  20%|█████▍                     | 1/5 [00:12<00:48, 12.18s/epoch(s), Training loss(es)=[0.22765455 0.19505975 0.22771518 0.25266758 0.1821356 ]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 23.99s/epoch(s), Training loss(es)=[0.185835   0.16806798 0.2026107  0.21886174 0.15140037]]Network training:  40%|██████████▊                | 2/5 [00:23<00:35, 12.00s/epoch(s), Training loss(es)=[0.185835   0.16806798 0.2026107  0.21886174 0.15140037]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.15s/epoch(s), Training loss(es)=[0.18377328 0.18957502 0.21478559 0.20257282 0.17751089]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.77s/epoch(s), Training loss(es)=[0.18377328 0.18957502 0.21478559 0.20257282 0.17751089]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.93s/epoch(s), Training loss(es)=[0.17048196 0.16302797 0.18210314 0.19404319 0.18620045]]Network training:  80%|█████████████████████▌     | 4/5 [01:11<00:17, 17.95s/epoch(s), Training loss(es)=[0.17048196 0.16302797 0.18210314 0.19404319 0.18620045]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.78s/epoch(s), Training loss(es)=[0.17358693 0.19685711 0.16966128 0.18960117 0.16782197]]Network training: 100%|███████████████████████████| 5/5 [01:39<00:00, 19.83s/epoch(s), Training loss(es)=[0.17358693 0.19685711 0.16966128 0.18960117 0.16782197]]
####################################################################
Starting training iteration 89.
Average action selection time:  0.32607624340057373
Rollout length:  1000
Rewards obtained: [5681.294440313949]
model train lenght 90000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:12<?, ?epoch(s)/s, Training loss(es)=[0.1914352  0.18783812 0.20481941 0.19310254 0.3013542 ]]Network training:  20%|█████▍                     | 1/5 [00:12<00:49, 12.33s/epoch(s), Training loss(es)=[0.1914352  0.18783812 0.20481941 0.19310254 0.3013542 ]]Network training:  20%|█████▍                     | 1/5 [00:27<01:51, 27.98s/epoch(s), Training loss(es)=[0.18024968 0.19912188 0.1687933  0.1781352  0.21175686]]Network training:  40%|██████████▊                | 2/5 [00:27<00:41, 13.99s/epoch(s), Training loss(es)=[0.18024968 0.19912188 0.1687933  0.1781352  0.21175686]]Network training:  40%|██████████▊                | 2/5 [00:55<01:23, 27.69s/epoch(s), Training loss(es)=[0.1824913  0.19071269 0.18746877 0.17622882 0.19200425]]Network training:  60%|████████████████▏          | 3/5 [00:55<00:36, 18.46s/epoch(s), Training loss(es)=[0.1824913  0.19071269 0.18746877 0.17622882 0.19200425]]Network training:  60%|████████████████▏          | 3/5 [01:24<00:56, 28.11s/epoch(s), Training loss(es)=[0.20243262 0.18949863 0.17553379 0.21584582 0.21647476]]Network training:  80%|█████████████████████▌     | 4/5 [01:24<00:21, 21.08s/epoch(s), Training loss(es)=[0.20243262 0.18949863 0.17553379 0.21584582 0.21647476]]Network training:  80%|█████████████████████▌     | 4/5 [01:52<00:28, 28.01s/epoch(s), Training loss(es)=[0.26126632 0.18406816 0.22139722 0.19857252 0.17588356]]Network training: 100%|███████████████████████████| 5/5 [01:52<00:00, 22.41s/epoch(s), Training loss(es)=[0.26126632 0.18406816 0.22139722 0.19857252 0.17588356]]
####################################################################
Starting training iteration 90.
Average action selection time:  0.31092952728271483
Rollout length:  1000
Rewards obtained: [4974.151151777832]
model train lenght 91000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:11<?, ?epoch(s)/s, Training loss(es)=[0.23433135 0.18412864 0.17563462 0.20742208 0.21881093]]Network training:  20%|█████▍                     | 1/5 [00:11<00:46, 11.60s/epoch(s), Training loss(es)=[0.23433135 0.18412864 0.17563462 0.20742208 0.21881093]]Network training:  20%|█████▍                     | 1/5 [00:34<02:16, 34.12s/epoch(s), Training loss(es)=[0.19796868 0.19915101 0.17535633 0.1877733  0.16707547]]Network training:  40%|██████████▊                | 2/5 [00:34<00:51, 17.06s/epoch(s), Training loss(es)=[0.19796868 0.19915101 0.17535633 0.1877733  0.16707547]]Network training:  40%|██████████▊                | 2/5 [01:01<01:32, 30.97s/epoch(s), Training loss(es)=[0.17024775 0.18207322 0.1682774  0.18336535 0.17703755]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:41, 20.65s/epoch(s), Training loss(es)=[0.17024775 0.18207322 0.1682774  0.18336535 0.17703755]]Network training:  60%|████████████████▏          | 3/5 [01:29<00:59, 29.95s/epoch(s), Training loss(es)=[0.18209736 0.18371853 0.16081774 0.17815362 0.22370154]]Network training:  80%|█████████████████████▌     | 4/5 [01:29<00:22, 22.46s/epoch(s), Training loss(es)=[0.18209736 0.18371853 0.16081774 0.17815362 0.22370154]]Network training:  80%|█████████████████████▌     | 4/5 [01:57<00:29, 29.46s/epoch(s), Training loss(es)=[0.21959753 0.18912432 0.18792328 0.27528688 0.1738251 ]]Network training: 100%|███████████████████████████| 5/5 [01:57<00:00, 23.57s/epoch(s), Training loss(es)=[0.21959753 0.18912432 0.18792328 0.27528688 0.1738251 ]]
####################################################################
Starting training iteration 91.
Average action selection time:  0.30053593349456786
Rollout length:  1000
Rewards obtained: [5624.904574144244]
model train lenght 92000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.18190509 0.1782954  0.18003976 0.20735884 0.17997888]]Network training:  20%|█████▍                     | 1/5 [00:14<00:59, 14.81s/epoch(s), Training loss(es)=[0.18190509 0.1782954  0.18003976 0.20735884 0.17997888]]Network training:  20%|█████▍                     | 1/5 [00:42<02:51, 42.95s/epoch(s), Training loss(es)=[0.18406622 0.17066135 0.17897178 0.18107024 0.17531839]]Network training:  40%|██████████▊                | 2/5 [00:42<01:04, 21.47s/epoch(s), Training loss(es)=[0.18406622 0.17066135 0.17897178 0.18107024 0.17531839]]Network training:  40%|██████████▊                | 2/5 [01:11<01:46, 35.59s/epoch(s), Training loss(es)=[0.1672993  0.1956097  0.17966835 0.17489491 0.18828857]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.73s/epoch(s), Training loss(es)=[0.1672993  0.1956097  0.17966835 0.17489491 0.18828857]]Network training:  60%|████████████████▏          | 3/5 [01:39<01:06, 33.11s/epoch(s), Training loss(es)=[0.20741425 0.18430623 0.17139901 0.23594473 0.18426143]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.84s/epoch(s), Training loss(es)=[0.20741425 0.18430623 0.17139901 0.23594473 0.18426143]]Network training:  80%|█████████████████████▌     | 4/5 [02:07<00:31, 31.94s/epoch(s), Training loss(es)=[0.15867051 0.17838944 0.18174261 0.18072838 0.22095732]]Network training: 100%|███████████████████████████| 5/5 [02:07<00:00, 25.55s/epoch(s), Training loss(es)=[0.15867051 0.17838944 0.18174261 0.18072838 0.22095732]]
####################################################################
Starting training iteration 92.
Average action selection time:  0.2880093367099762
Rollout length:  1000
Rewards obtained: [1836.3946834162014]
model train lenght 93000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.18825212 0.21935132 0.18128477 0.20724033 0.18679252]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.37s/epoch(s), Training loss(es)=[0.18825212 0.21935132 0.18128477 0.20724033 0.18679252]]Network training:  20%|█████▍                     | 1/5 [00:51<03:27, 51.96s/epoch(s), Training loss(es)=[0.17043915 0.1986719  0.18003307 0.18657668 0.18697138]]Network training:  40%|██████████▊                | 2/5 [00:51<01:17, 25.98s/epoch(s), Training loss(es)=[0.17043915 0.1986719  0.18003307 0.18657668 0.18697138]]Network training:  40%|██████████▊                | 2/5 [01:20<02:00, 40.28s/epoch(s), Training loss(es)=[0.25355566 0.18195733 0.16084324 0.18512729 0.20518672]]Network training:  60%|████████████████▏          | 3/5 [01:20<00:53, 26.85s/epoch(s), Training loss(es)=[0.25355566 0.18195733 0.16084324 0.18512729 0.20518672]]Network training:  60%|████████████████▏          | 3/5 [01:48<01:12, 36.32s/epoch(s), Training loss(es)=[0.1530581  0.24259338 0.17111836 0.19699878 0.26143566]]Network training:  80%|█████████████████████▌     | 4/5 [01:48<00:27, 27.24s/epoch(s), Training loss(es)=[0.1530581  0.24259338 0.17111836 0.19699878 0.26143566]]Network training:  80%|█████████████████████▌     | 4/5 [02:17<00:34, 34.38s/epoch(s), Training loss(es)=[0.16282266 0.20478965 0.15758237 0.17687288 0.17422557]]Network training: 100%|███████████████████████████| 5/5 [02:17<00:00, 27.50s/epoch(s), Training loss(es)=[0.16282266 0.20478965 0.15758237 0.17687288 0.17422557]]
####################################################################
Starting training iteration 93.
Average action selection time:  0.2791863408088684
Rollout length:  1000
Rewards obtained: [6215.375189604057]
model train lenght 94000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:28<?, ?epoch(s)/s, Training loss(es)=[0.19768862 0.18170945 0.19587843 0.21166328 0.18367986]]Network training:  20%|█████▍                     | 1/5 [00:28<01:55, 28.81s/epoch(s), Training loss(es)=[0.19768862 0.18170945 0.19587843 0.21166328 0.18367986]]Network training:  20%|█████▍                     | 1/5 [00:57<03:50, 57.68s/epoch(s), Training loss(es)=[0.18189597 0.18446122 0.18301038 0.19575968 0.16914839]]Network training:  40%|██████████▊                | 2/5 [00:57<01:26, 28.84s/epoch(s), Training loss(es)=[0.18189597 0.18446122 0.18301038 0.19575968 0.16914839]]Network training:  40%|██████████▊                | 2/5 [01:26<02:09, 43.20s/epoch(s), Training loss(es)=[0.1936139  0.17196031 0.17838077 0.18448606 0.17122546]]Network training:  60%|████████████████▏          | 3/5 [01:26<00:57, 28.80s/epoch(s), Training loss(es)=[0.1936139  0.17196031 0.17838077 0.18448606 0.17122546]]Network training:  60%|████████████████▏          | 3/5 [01:55<01:16, 38.43s/epoch(s), Training loss(es)=[0.3069087  0.17714141 0.18694377 0.17967759 0.3994558 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:55<00:28, 28.82s/epoch(s), Training loss(es)=[0.3069087  0.17714141 0.18694377 0.17967759 0.3994558 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:24<00:36, 36.04s/epoch(s), Training loss(es)=[0.17709872 0.17200865 0.19217233 0.17287154 0.20210437]]Network training: 100%|███████████████████████████| 5/5 [02:24<00:00, 28.83s/epoch(s), Training loss(es)=[0.17709872 0.17200865 0.19217233 0.17287154 0.20210437]]
####################################################################
Starting training iteration 94.
Average action selection time:  0.278831750869751
Rollout length:  1000
Rewards obtained: [6560.068881890955]
model train lenght 95000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:28<?, ?epoch(s)/s, Training loss(es)=[0.20105001 0.20626551 0.21230972 0.20406057 0.233974  ]]Network training:  20%|█████▍                     | 1/5 [00:28<01:55, 28.99s/epoch(s), Training loss(es)=[0.20105001 0.20626551 0.21230972 0.20406057 0.233974  ]]Network training:  20%|█████▍                     | 1/5 [00:57<03:51, 57.95s/epoch(s), Training loss(es)=[0.20266964 0.17431009 0.18491822 0.18379594 0.17951995]]Network training:  40%|██████████▊                | 2/5 [00:57<01:26, 28.97s/epoch(s), Training loss(es)=[0.20266964 0.17431009 0.18491822 0.18379594 0.17951995]]Network training:  40%|██████████▊                | 2/5 [01:26<02:10, 43.49s/epoch(s), Training loss(es)=[0.18433745 0.17774846 0.19660006 0.17205082 0.18526497]]Network training:  60%|████████████████▏          | 3/5 [01:26<00:57, 28.99s/epoch(s), Training loss(es)=[0.18433745 0.17774846 0.19660006 0.17205082 0.18526497]]Network training:  60%|████████████████▏          | 3/5 [01:56<01:17, 38.69s/epoch(s), Training loss(es)=[0.18155967 0.2572153  0.17619124 0.19507988 0.18022679]]Network training:  80%|█████████████████████▌     | 4/5 [01:56<00:29, 29.02s/epoch(s), Training loss(es)=[0.18155967 0.2572153  0.17619124 0.19507988 0.18022679]]Network training:  80%|█████████████████████▌     | 4/5 [02:25<00:36, 36.30s/epoch(s), Training loss(es)=[0.20444702 0.17875935 0.1889503  0.16393068 0.20371038]]Network training: 100%|███████████████████████████| 5/5 [02:25<00:00, 29.04s/epoch(s), Training loss(es)=[0.20444702 0.17875935 0.1889503  0.16393068 0.20371038]]
####################################################################
Starting training iteration 95.
Average action selection time:  0.2770122671127319
Rollout length:  1000
Rewards obtained: [6179.7163060208495]
model train lenght 96000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:29<?, ?epoch(s)/s, Training loss(es)=[0.21255362 0.18652643 0.18972357 0.15725921 0.17361276]]Network training:  20%|█████▍                     | 1/5 [00:29<01:56, 29.22s/epoch(s), Training loss(es)=[0.21255362 0.18652643 0.18972357 0.15725921 0.17361276]]Network training:  20%|█████▍                     | 1/5 [00:58<03:54, 58.54s/epoch(s), Training loss(es)=[0.18267494 0.18412997 0.18389249 0.27117744 0.18539034]]Network training:  40%|██████████▊                | 2/5 [00:58<01:27, 29.27s/epoch(s), Training loss(es)=[0.18267494 0.18412997 0.18389249 0.27117744 0.18539034]]Network training:  40%|██████████▊                | 2/5 [01:28<02:12, 44.03s/epoch(s), Training loss(es)=[0.18759002 0.1852202  0.21224439 0.17867544 0.16117126]]Network training:  60%|████████████████▏          | 3/5 [01:28<00:58, 29.36s/epoch(s), Training loss(es)=[0.18759002 0.1852202  0.21224439 0.17867544 0.16117126]]Network training:  60%|████████████████▏          | 3/5 [01:57<01:18, 39.14s/epoch(s), Training loss(es)=[0.17205015 0.18497501 0.19593707 0.18752722 0.16898239]]Network training:  80%|█████████████████████▌     | 4/5 [01:57<00:29, 29.35s/epoch(s), Training loss(es)=[0.17205015 0.18497501 0.19593707 0.18752722 0.16898239]]Network training:  80%|█████████████████████▌     | 4/5 [02:26<00:36, 36.70s/epoch(s), Training loss(es)=[0.223352   0.18708147 0.2060979  0.19945608 0.15749331]]Network training: 100%|███████████████████████████| 5/5 [02:26<00:00, 29.36s/epoch(s), Training loss(es)=[0.223352   0.18708147 0.2060979  0.19945608 0.15749331]]
####################################################################
Starting training iteration 96.
Average action selection time:  0.27647981214523315
Rollout length:  1000
Rewards obtained: [6662.306050203769]
model train lenght 97000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:29<?, ?epoch(s)/s, Training loss(es)=[0.20829314 0.18991335 0.1777471  0.20287544 0.18343478]]Network training:  20%|█████▍                     | 1/5 [00:29<01:58, 29.72s/epoch(s), Training loss(es)=[0.20829314 0.18991335 0.1777471  0.20287544 0.18343478]]Network training:  20%|█████▍                     | 1/5 [00:59<03:58, 59.55s/epoch(s), Training loss(es)=[0.18214096 0.16788529 0.1814166  0.19246969 0.17586373]]Network training:  40%|██████████▊                | 2/5 [00:59<01:29, 29.78s/epoch(s), Training loss(es)=[0.18214096 0.16788529 0.1814166  0.19246969 0.17586373]]Network training:  40%|████████████▊                   | 2/5 [01:29<02:14, 44.67s/epoch(s), Training loss(es)=[0.182495  0.1775292 0.1965236 0.2074414 0.1767733]]Network training:  60%|███████████████████▏            | 3/5 [01:29<00:59, 29.78s/epoch(s), Training loss(es)=[0.182495  0.1775292 0.1965236 0.2074414 0.1767733]]Network training:  60%|████████████████▏          | 3/5 [01:59<01:19, 39.70s/epoch(s), Training loss(es)=[0.18350281 0.17081381 0.17941561 0.23100364 0.17598005]]Network training:  80%|█████████████████████▌     | 4/5 [01:59<00:29, 29.78s/epoch(s), Training loss(es)=[0.18350281 0.17081381 0.17941561 0.23100364 0.17598005]]Network training:  80%|█████████████████████▌     | 4/5 [02:28<00:37, 37.21s/epoch(s), Training loss(es)=[0.20643592 0.16496162 0.18935078 0.18200108 0.16510296]]Network training: 100%|███████████████████████████| 5/5 [02:28<00:00, 29.77s/epoch(s), Training loss(es)=[0.20643592 0.16496162 0.18935078 0.18200108 0.16510296]]
####################################################################
Starting training iteration 97.
Average action selection time:  0.2744323325157165
Rollout length:  1000
Rewards obtained: [6017.390452576143]
model train lenght 98000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:30<?, ?epoch(s)/s, Training loss(es)=[0.37630153 0.19104408 0.18484902 0.17820774 0.17559792]]Network training:  20%|█████▍                     | 1/5 [00:30<02:00, 30.05s/epoch(s), Training loss(es)=[0.37630153 0.19104408 0.18484902 0.17820774 0.17559792]]Network training:  20%|█████▍                     | 1/5 [01:00<04:00, 60.21s/epoch(s), Training loss(es)=[0.17309113 0.18246828 0.18346462 0.16110204 0.16748759]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.10s/epoch(s), Training loss(es)=[0.17309113 0.18246828 0.18346462 0.16110204 0.16748759]]Network training:  40%|██████████▊                | 2/5 [01:30<02:15, 45.20s/epoch(s), Training loss(es)=[0.26978037 0.17636593 0.21335298 0.16551735 0.18952897]]Network training:  60%|████████████████▏          | 3/5 [01:30<01:00, 30.14s/epoch(s), Training loss(es)=[0.26978037 0.17636593 0.21335298 0.16551735 0.18952897]]Network training:  60%|████████████████▏          | 3/5 [02:00<01:20, 40.19s/epoch(s), Training loss(es)=[0.17794564 0.17678015 0.19370738 0.18652998 0.17097023]]Network training:  80%|█████████████████████▌     | 4/5 [02:00<00:30, 30.14s/epoch(s), Training loss(es)=[0.17794564 0.17678015 0.19370738 0.18652998 0.17097023]]Network training:  80%|█████████████████████▌     | 4/5 [02:30<00:37, 37.59s/epoch(s), Training loss(es)=[0.18522227 0.19176778 0.17779091 0.20401184 0.16712242]]Network training: 100%|███████████████████████████| 5/5 [02:30<00:00, 30.07s/epoch(s), Training loss(es)=[0.18522227 0.19176778 0.17779091 0.20401184 0.16712242]]
####################################################################
Starting training iteration 98.
Average action selection time:  0.27403158497810365
Rollout length:  1000
Rewards obtained: [6391.693203756771]
model train lenght 99000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:30<?, ?epoch(s)/s, Training loss(es)=[0.19468388 0.19198312 0.18310425 0.19427954 0.17219585]]Network training:  20%|█████▍                     | 1/5 [00:30<02:01, 30.43s/epoch(s), Training loss(es)=[0.19468388 0.19198312 0.18310425 0.19427954 0.17219585]]Network training:  20%|█████▍                     | 1/5 [01:00<04:02, 60.61s/epoch(s), Training loss(es)=[0.27713203 0.19194007 0.2067206  0.22716984 0.17280093]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.31s/epoch(s), Training loss(es)=[0.27713203 0.19194007 0.2067206  0.22716984 0.17280093]]Network training:  40%|██████████▊                | 2/5 [01:30<02:16, 45.46s/epoch(s), Training loss(es)=[0.18747532 0.17208296 0.3402253  0.20464057 0.18471453]]Network training:  60%|████████████████▏          | 3/5 [01:30<01:00, 30.31s/epoch(s), Training loss(es)=[0.18747532 0.17208296 0.3402253  0.20464057 0.18471453]]Network training:  60%|████████████████▏          | 3/5 [02:01<01:20, 40.43s/epoch(s), Training loss(es)=[0.19073112 0.18330233 0.25437677 0.2032008  0.18302765]]Network training:  80%|█████████████████████▌     | 4/5 [02:01<00:30, 30.32s/epoch(s), Training loss(es)=[0.19073112 0.18330233 0.25437677 0.2032008  0.18302765]]Network training:  80%|█████████████████████▌     | 4/5 [02:23<00:35, 35.77s/epoch(s), Training loss(es)=[0.18664138 0.20567288 0.20443965 0.17539634 0.16619675]]Network training: 100%|███████████████████████████| 5/5 [02:23<00:00, 28.61s/epoch(s), Training loss(es)=[0.18664138 0.20567288 0.20443965 0.17539634 0.16619675]]
####################################################################
Starting training iteration 99.
Average action selection time:  0.2843776891231537
Rollout length:  1000
Rewards obtained: [6187.327117027219]
model train lenght 100000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:30<?, ?epoch(s)/s, Training loss(es)=[0.18842225 0.19464432 0.24309443 0.21140853 0.20720744]]Network training:  20%|█████▍                     | 1/5 [00:30<02:02, 30.68s/epoch(s), Training loss(es)=[0.18842225 0.19464432 0.24309443 0.21140853 0.20720744]]Network training:  20%|█████▍                     | 1/5 [01:01<04:04, 61.24s/epoch(s), Training loss(es)=[0.19472156 0.21876238 0.19590701 0.23882097 0.18505016]]Network training:  40%|██████████▊                | 2/5 [01:01<01:31, 30.62s/epoch(s), Training loss(es)=[0.19472156 0.21876238 0.19590701 0.23882097 0.18505016]]Network training:  40%|██████████▊                | 2/5 [01:31<02:17, 45.91s/epoch(s), Training loss(es)=[0.17387536 0.18077838 0.19995537 0.18641661 0.1921109 ]]Network training:  60%|████████████████▏          | 3/5 [01:31<01:01, 30.60s/epoch(s), Training loss(es)=[0.17387536 0.18077838 0.19995537 0.18641661 0.1921109 ]]Network training:  60%|████████████████▏          | 3/5 [02:02<01:21, 40.81s/epoch(s), Training loss(es)=[0.17407995 0.1929221  0.19190994 0.18954678 0.21455708]]Network training:  80%|█████████████████████▌     | 4/5 [02:02<00:30, 30.61s/epoch(s), Training loss(es)=[0.17407995 0.1929221  0.19190994 0.18954678 0.21455708]]Network training:  80%|█████████████████████▌     | 4/5 [02:15<00:33, 33.83s/epoch(s), Training loss(es)=[0.18289576 0.17437722 0.17976311 0.18516497 0.18401758]]Network training: 100%|███████████████████████████| 5/5 [02:15<00:00, 27.06s/epoch(s), Training loss(es)=[0.18289576 0.17437722 0.17976311 0.18516497 0.18401758]]
####################################################################
Starting training iteration 100.
Average action selection time:  0.2947206928730011
Rollout length:  1000
Rewards obtained: [5022.990907043908]
model train lenght 101000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:30<?, ?epoch(s)/s, Training loss(es)=[0.20478845 0.18010552 0.19237414 0.18588954 0.1828573 ]]Network training:  20%|█████▍                     | 1/5 [00:30<02:03, 30.98s/epoch(s), Training loss(es)=[0.20478845 0.18010552 0.19237414 0.18588954 0.1828573 ]]Network training:  20%|█████▍                     | 1/5 [01:01<04:06, 61.74s/epoch(s), Training loss(es)=[0.1729913  0.18963271 0.18657608 0.21146682 0.18674327]]Network training:  40%|██████████▊                | 2/5 [01:01<01:32, 30.87s/epoch(s), Training loss(es)=[0.1729913  0.18963271 0.18657608 0.21146682 0.18674327]]Network training:  40%|██████████▊                | 2/5 [01:32<02:18, 46.33s/epoch(s), Training loss(es)=[0.17126782 0.1767936  0.17397925 0.19614309 0.17742309]]Network training:  60%|████████████████▏          | 3/5 [01:32<01:01, 30.89s/epoch(s), Training loss(es)=[0.17126782 0.1767936  0.17397925 0.19614309 0.17742309]]Network training:  60%|████████████████▏          | 3/5 [01:55<01:17, 38.56s/epoch(s), Training loss(es)=[0.18435857 0.17236222 0.18832052 0.20126961 0.19110575]]Network training:  80%|█████████████████████▌     | 4/5 [01:55<00:28, 28.92s/epoch(s), Training loss(es)=[0.18435857 0.17236222 0.18832052 0.20126961 0.19110575]]Network training:  80%|█████████████████████▌     | 4/5 [02:08<00:32, 32.15s/epoch(s), Training loss(es)=[0.17158578 0.16924728 0.18491955 0.18071957 0.19194235]]Network training: 100%|███████████████████████████| 5/5 [02:08<00:00, 25.72s/epoch(s), Training loss(es)=[0.17158578 0.16924728 0.18491955 0.18071957 0.19194235]]
####################################################################
Starting training iteration 101.
Average action selection time:  0.3042228422164917
Rollout length:  1000
Rewards obtained: [5943.75452451679]
model train lenght 102000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:31<?, ?epoch(s)/s, Training loss(es)=[0.1904167  0.5297447  0.17553978 0.18515986 0.1742222 ]]Network training:  20%|█████▍                     | 1/5 [00:31<02:05, 31.34s/epoch(s), Training loss(es)=[0.1904167  0.5297447  0.17553978 0.18515986 0.1742222 ]]Network training:  20%|█████▍                     | 1/5 [01:02<04:09, 62.46s/epoch(s), Training loss(es)=[0.2169446  0.17484011 0.20148937 0.16594267 0.17681676]]Network training:  40%|██████████▊                | 2/5 [01:02<01:33, 31.23s/epoch(s), Training loss(es)=[0.2169446  0.17484011 0.20148937 0.16594267 0.17681676]]Network training:  40%|██████████▊                | 2/5 [01:33<02:20, 46.87s/epoch(s), Training loss(es)=[0.1987788  0.1876078  0.17154403 0.19311641 0.17188175]]Network training:  60%|████████████████▏          | 3/5 [01:33<01:02, 31.24s/epoch(s), Training loss(es)=[0.1987788  0.1876078  0.17154403 0.19311641 0.17188175]]Network training:  60%|████████████████▏          | 3/5 [01:49<01:12, 36.47s/epoch(s), Training loss(es)=[0.17617336 0.183071   0.2533854  0.18793222 0.17613415]]Network training:  80%|█████████████████████▌     | 4/5 [01:49<00:27, 27.35s/epoch(s), Training loss(es)=[0.17617336 0.183071   0.2533854  0.18793222 0.17613415]]Network training:  80%|█████████████████████▌     | 4/5 [02:02<00:30, 30.61s/epoch(s), Training loss(es)=[0.16406822 0.17675139 0.17001069 0.21193288 0.18571764]]Network training: 100%|███████████████████████████| 5/5 [02:02<00:00, 24.49s/epoch(s), Training loss(es)=[0.16406822 0.17675139 0.17001069 0.21193288 0.18571764]]
####################################################################
Starting training iteration 102.
Average action selection time:  0.31574778294563294
Rollout length:  1000
Rewards obtained: [5906.197867796975]
model train lenght 103000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:31<?, ?epoch(s)/s, Training loss(es)=[0.18683806 0.184952   0.1945375  0.23443574 0.185745  ]]Network training:  20%|█████▍                     | 1/5 [00:31<02:06, 31.61s/epoch(s), Training loss(es)=[0.18683806 0.184952   0.1945375  0.23443574 0.185745  ]]Network training:  20%|█████▍                     | 1/5 [01:03<04:13, 63.34s/epoch(s), Training loss(es)=[0.16575971 0.18936059 0.189705   0.19851568 0.21028882]]Network training:  40%|██████████▊                | 2/5 [01:03<01:35, 31.67s/epoch(s), Training loss(es)=[0.16575971 0.18936059 0.189705   0.19851568 0.21028882]]Network training:  40%|██████████▊                | 2/5 [01:27<02:11, 43.88s/epoch(s), Training loss(es)=[0.19604619 0.18190634 0.18827535 0.1952769  0.16903447]]Network training:  60%|████████████████▏          | 3/5 [01:27<00:58, 29.25s/epoch(s), Training loss(es)=[0.19604619 0.18190634 0.18827535 0.1952769  0.16903447]]Network training:  60%|████████████████▏          | 3/5 [01:41<01:07, 33.77s/epoch(s), Training loss(es)=[0.20637383 0.19219056 0.20184425 0.19094571 0.46828505]]Network training:  80%|█████████████████████▌     | 4/5 [01:41<00:25, 25.33s/epoch(s), Training loss(es)=[0.20637383 0.19219056 0.20184425 0.19094571 0.46828505]]Network training:  80%|█████████████████████▌     | 4/5 [01:54<00:28, 28.65s/epoch(s), Training loss(es)=[0.17304544 0.19548167 0.16727078 0.17884398 0.21007942]]Network training: 100%|███████████████████████████| 5/5 [01:54<00:00, 22.92s/epoch(s), Training loss(es)=[0.17304544 0.19548167 0.16727078 0.17884398 0.21007942]]
####################################################################
Starting training iteration 103.
Average action selection time:  0.32819321608543395
Rollout length:  1000
Rewards obtained: [6557.596557935536]
model train lenght 104000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:31<?, ?epoch(s)/s, Training loss(es)=[0.17842582 0.17749088 0.17287914 0.1929542  0.19554412]]Network training:  20%|█████▍                     | 1/5 [00:31<02:07, 31.91s/epoch(s), Training loss(es)=[0.17842582 0.17749088 0.17287914 0.1929542  0.19554412]]Network training:  20%|█████▍                     | 1/5 [01:03<04:15, 63.87s/epoch(s), Training loss(es)=[0.20353076 0.20020725 0.17555586 0.22523023 0.16308743]]Network training:  40%|██████████▊                | 2/5 [01:03<01:35, 31.94s/epoch(s), Training loss(es)=[0.20353076 0.20020725 0.17555586 0.22523023 0.16308743]]Network training:  40%|██████████▊                | 2/5 [01:18<01:58, 39.35s/epoch(s), Training loss(es)=[0.20740709 0.1688145  0.5640622  0.28692114 0.16717568]]Network training:  60%|████████████████▏          | 3/5 [01:18<00:52, 26.24s/epoch(s), Training loss(es)=[0.20740709 0.1688145  0.5640622  0.28692114 0.16717568]]Network training:  60%|████████████████▏          | 3/5 [01:32<01:01, 30.71s/epoch(s), Training loss(es)=[0.18063547 0.19001648 0.17611936 0.25477985 0.19838853]]Network training:  80%|█████████████████████▌     | 4/5 [01:32<00:23, 23.03s/epoch(s), Training loss(es)=[0.18063547 0.19001648 0.17611936 0.25477985 0.19838853]]Network training:  80%|█████████████████████▌     | 4/5 [01:45<00:26, 26.32s/epoch(s), Training loss(es)=[0.17581452 0.17613663 0.1832789  0.18936533 0.20242605]]Network training: 100%|███████████████████████████| 5/5 [01:45<00:00, 21.05s/epoch(s), Training loss(es)=[0.17581452 0.17613663 0.1832789  0.18936533 0.20242605]]
####################################################################
Starting training iteration 104.
Average action selection time:  0.3392940375804901
Rollout length:  1000
Rewards obtained: [5500.957978855596]
model train lenght 105000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:32<?, ?epoch(s)/s, Training loss(es)=[0.19305587 0.20402034 0.26570845 0.21616343 0.17165346]]Network training:  20%|█████▍                     | 1/5 [00:32<02:08, 32.19s/epoch(s), Training loss(es)=[0.19305587 0.20402034 0.26570845 0.21616343 0.17165346]]Network training:  20%|█████▍                     | 1/5 [00:57<03:50, 57.71s/epoch(s), Training loss(es)=[0.18624504 0.17452277 0.19065455 0.18964924 0.18410634]]Network training:  40%|██████████▊                | 2/5 [00:57<01:26, 28.85s/epoch(s), Training loss(es)=[0.18624504 0.17452277 0.19065455 0.18964924 0.18410634]]Network training:  40%|██████████▊                | 2/5 [01:11<01:47, 35.77s/epoch(s), Training loss(es)=[0.1929054  0.17479514 0.19998598 0.17649537 0.5809081 ]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.84s/epoch(s), Training loss(es)=[0.1929054  0.17479514 0.19998598 0.17649537 0.5809081 ]]Network training:  60%|████████████████▏          | 3/5 [01:25<00:56, 28.45s/epoch(s), Training loss(es)=[0.18715328 0.16820577 0.17348477 0.18272328 0.22920337]]Network training:  80%|█████████████████████▌     | 4/5 [01:25<00:21, 21.34s/epoch(s), Training loss(es)=[0.18715328 0.16820577 0.17348477 0.18272328 0.22920337]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.80s/epoch(s), Training loss(es)=[0.23422578 0.6032227  0.20562246 0.2127598  0.21005578]]Network training: 100%|███████████████████████████| 5/5 [01:39<00:00, 19.84s/epoch(s), Training loss(es)=[0.23422578 0.6032227  0.20562246 0.2127598  0.21005578]]
####################################################################
Starting training iteration 105.
Average action selection time:  0.355726912021637
Rollout length:  1000
Rewards obtained: [2331.9994831308345]
model train lenght 106000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:31<?, ?epoch(s)/s, Training loss(es)=[0.20547344 0.19808865 0.18907344 0.21378879 0.17531891]]Network training:  20%|█████▍                     | 1/5 [00:31<02:07, 31.78s/epoch(s), Training loss(es)=[0.20547344 0.19808865 0.18907344 0.21378879 0.17531891]]Network training:  20%|█████▍                     | 1/5 [00:46<03:04, 46.00s/epoch(s), Training loss(es)=[0.17004885 0.1816537  0.19350548 0.20539722 0.19463919]]Network training:  40%|██████████▊                | 2/5 [00:46<01:09, 23.00s/epoch(s), Training loss(es)=[0.17004885 0.1816537  0.19350548 0.20539722 0.19463919]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.09s/epoch(s), Training loss(es)=[0.19244419 0.18837303 0.18841569 0.26580575 0.19230595]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.06s/epoch(s), Training loss(es)=[0.19244419 0.18837303 0.18841569 0.26580575 0.19230595]]Network training:  60%|████████████████▏          | 3/5 [01:14<00:49, 24.73s/epoch(s), Training loss(es)=[0.17523849 0.18817742 0.17278855 0.20165727 0.22726957]]Network training:  80%|█████████████████████▌     | 4/5 [01:14<00:18, 18.55s/epoch(s), Training loss(es)=[0.17523849 0.18817742 0.17278855 0.20165727 0.22726957]]Network training:  80%|█████████████████████▌     | 4/5 [01:27<00:21, 21.93s/epoch(s), Training loss(es)=[0.1730837  0.17083888 0.27523622 0.18404847 0.19433774]]Network training: 100%|███████████████████████████| 5/5 [01:27<00:00, 17.54s/epoch(s), Training loss(es)=[0.1730837  0.17083888 0.27523622 0.18404847 0.19433774]]
####################################################################
Starting training iteration 106.
Average action selection time:  0.36173079180717466
Rollout length:  1000
Rewards obtained: [6449.525730795436]
model train lenght 107000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:27<?, ?epoch(s)/s, Training loss(es)=[0.17393951 0.17319733 0.2144865  0.1832094  0.19667456]]Network training:  20%|█████▍                     | 1/5 [00:27<01:49, 27.33s/epoch(s), Training loss(es)=[0.17393951 0.17319733 0.2144865  0.1832094  0.19667456]]Network training:  20%|█████▍                     | 1/5 [00:41<02:45, 41.31s/epoch(s), Training loss(es)=[0.18169299 0.18257293 0.17703693 0.23864497 0.18934776]]Network training:  40%|██████████▊                | 2/5 [00:41<01:01, 20.65s/epoch(s), Training loss(es)=[0.18169299 0.18257293 0.17703693 0.23864497 0.18934776]]Network training:  40%|██████████▊                | 2/5 [00:55<01:23, 27.68s/epoch(s), Training loss(es)=[0.19761294 0.1633925  0.1717146  0.17568535 0.16810134]]Network training:  60%|████████████████▏          | 3/5 [00:55<00:36, 18.46s/epoch(s), Training loss(es)=[0.19761294 0.1633925  0.1717146  0.17568535 0.16810134]]Network training:  60%|████████████████▏          | 3/5 [01:09<00:46, 23.07s/epoch(s), Training loss(es)=[0.19725032 0.23618992 0.17386763 0.1941039  0.16554406]]Network training:  80%|█████████████████████▌     | 4/5 [01:09<00:17, 17.30s/epoch(s), Training loss(es)=[0.19725032 0.23618992 0.17386763 0.1941039  0.16554406]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.83s/epoch(s), Training loss(es)=[0.18006144 0.17014655 0.17278077 0.22428194 0.17826015]]Network training: 100%|███████████████████████████| 5/5 [01:23<00:00, 16.66s/epoch(s), Training loss(es)=[0.18006144 0.17014655 0.17278077 0.22428194 0.17826015]]
####################################################################
Starting training iteration 107.
Average action selection time:  0.3562187917232513
Rollout length:  1000
Rewards obtained: [6282.973527995051]
model train lenght 108000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:31<?, ?epoch(s)/s, Training loss(es)=[0.18382914 0.18572295 0.18441324 0.1847137  0.17686716]]Network training:  20%|█████▍                     | 1/5 [00:31<02:05, 31.27s/epoch(s), Training loss(es)=[0.18382914 0.18572295 0.18441324 0.1847137  0.17686716]]Network training:  20%|█████▍                     | 1/5 [00:45<03:00, 45.01s/epoch(s), Training loss(es)=[0.15638989 0.19061978 0.18302293 0.2532886  0.17628945]]Network training:  40%|██████████▊                | 2/5 [00:45<01:07, 22.50s/epoch(s), Training loss(es)=[0.15638989 0.19061978 0.18302293 0.2532886  0.17628945]]Network training:  40%|██████████▊                | 2/5 [00:58<01:27, 29.10s/epoch(s), Training loss(es)=[0.16020577 0.21180229 0.17536971 0.17518118 0.21149951]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.40s/epoch(s), Training loss(es)=[0.16020577 0.21180229 0.17536971 0.17518118 0.21149951]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.72s/epoch(s), Training loss(es)=[0.17949194 0.17490438 0.17377017 0.19967663 0.17638731]]Network training:  80%|█████████████████████▌     | 4/5 [01:11<00:17, 17.79s/epoch(s), Training loss(es)=[0.17949194 0.17490438 0.17377017 0.19967663 0.17638731]]Network training:  80%|█████████████████████▌     | 4/5 [01:24<00:21, 21.08s/epoch(s), Training loss(es)=[0.19601746 0.19706254 0.19667831 0.19398475 0.17107949]]Network training: 100%|███████████████████████████| 5/5 [01:24<00:00, 16.86s/epoch(s), Training loss(es)=[0.19601746 0.19706254 0.19667831 0.19398475 0.17107949]]
####################################################################
Starting training iteration 108.
Average action selection time:  0.3452882709503174
Rollout length:  1000
Rewards obtained: [7295.9506546271905]
model train lenght 109000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:32<?, ?epoch(s)/s, Training loss(es)=[0.18441968 0.19782503 0.18693252 0.18505253 0.20246129]]Network training:  20%|█████▍                     | 1/5 [00:32<02:11, 32.87s/epoch(s), Training loss(es)=[0.18441968 0.19782503 0.18693252 0.18505253 0.20246129]]Network training:  20%|█████▍                     | 1/5 [00:52<03:29, 52.30s/epoch(s), Training loss(es)=[0.1889118  0.16834408 0.17487346 0.1980407  0.18683203]]Network training:  40%|██████████▊                | 2/5 [00:52<01:18, 26.15s/epoch(s), Training loss(es)=[0.1889118  0.16834408 0.17487346 0.1980407  0.18683203]]Network training:  40%|██████████▊                | 2/5 [01:04<01:36, 32.09s/epoch(s), Training loss(es)=[0.19863398 0.20306045 0.2313151  0.19064528 0.15996292]]Network training:  60%|████████████████▏          | 3/5 [01:04<00:42, 21.39s/epoch(s), Training loss(es)=[0.19863398 0.20306045 0.2313151  0.19064528 0.15996292]]Network training:  60%|████████████████▏          | 3/5 [01:16<00:51, 25.61s/epoch(s), Training loss(es)=[0.20463061 0.18069069 0.20272425 0.20297892 0.19171228]]Network training:  80%|█████████████████████▌     | 4/5 [01:16<00:19, 19.21s/epoch(s), Training loss(es)=[0.20463061 0.18069069 0.20272425 0.20297892 0.19171228]]Network training:  80%|█████████████████████▌     | 4/5 [01:29<00:22, 22.33s/epoch(s), Training loss(es)=[0.19923854 0.17718942 0.23964395 0.211529   0.19051088]]Network training: 100%|███████████████████████████| 5/5 [01:29<00:00, 17.87s/epoch(s), Training loss(es)=[0.19923854 0.17718942 0.23964395 0.211529   0.19051088]]
####################################################################
Starting training iteration 109.
Average action selection time:  0.6140194845199585
Rollout length:  1000
Rewards obtained: [7071.818784671995]
model train lenght 110000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:33<?, ?epoch(s)/s, Training loss(es)=[0.18691993 0.179057   0.1870301  0.19812676 0.37098736]]Network training:  20%|█████▍                     | 1/5 [00:33<02:13, 33.42s/epoch(s), Training loss(es)=[0.18691993 0.179057   0.1870301  0.19812676 0.37098736]]Network training:  20%|█████▍                     | 1/5 [01:04<04:17, 64.26s/epoch(s), Training loss(es)=[0.20290014 0.1945814  0.17414646 0.2071836  0.18667324]]Network training:  40%|██████████▊                | 2/5 [01:04<01:36, 32.13s/epoch(s), Training loss(es)=[0.20290014 0.1945814  0.17414646 0.2071836  0.18667324]]Network training:  40%|██████████▊                | 2/5 [01:18<01:57, 39.06s/epoch(s), Training loss(es)=[0.18015908 0.19555393 0.17411311 0.18767813 0.27111617]]Network training:  60%|████████████████▏          | 3/5 [01:18<00:52, 26.04s/epoch(s), Training loss(es)=[0.18015908 0.19555393 0.17411311 0.18767813 0.27111617]]Network training:  60%|████████████████▏          | 3/5 [01:32<01:01, 30.70s/epoch(s), Training loss(es)=[0.20007418 0.1599512  0.17280811 0.20364162 0.21278025]]Network training:  80%|█████████████████████▌     | 4/5 [01:32<00:23, 23.03s/epoch(s), Training loss(es)=[0.20007418 0.1599512  0.17280811 0.20364162 0.21278025]]Network training:  80%|█████████████████████▌     | 4/5 [01:46<00:26, 26.61s/epoch(s), Training loss(es)=[0.18045372 0.19455104 0.18845917 0.1761383  0.20118035]]Network training: 100%|███████████████████████████| 5/5 [01:46<00:00, 21.28s/epoch(s), Training loss(es)=[0.18045372 0.19455104 0.18845917 0.1761383  0.20118035]]
####################################################################
Starting training iteration 110.
Average action selection time:  0.33920267009735106
Rollout length:  1000
Rewards obtained: [5515.713355509291]
model train lenght 111000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:52<?, ?epoch(s)/s, Training loss(es)=[0.20858613 0.19139166 0.19102578 0.29149806 0.17589548]]Network training:  20%|█████▏                    | 1/5 [01:52<07:28, 112.02s/epoch(s), Training loss(es)=[0.20858613 0.19139166 0.19102578 0.29149806 0.17589548]]Network training:  20%|█████▏                    | 1/5 [02:20<09:21, 140.28s/epoch(s), Training loss(es)=[0.20767426 0.19783601 0.2650056  0.1876223  0.19058338]]Network training:  40%|██████████▊                | 2/5 [02:20<03:30, 70.14s/epoch(s), Training loss(es)=[0.20767426 0.19783601 0.2650056  0.1876223  0.19058338]]Network training:  40%|██████████▊                | 2/5 [02:37<03:55, 78.65s/epoch(s), Training loss(es)=[0.2254303  0.19955994 0.18712686 0.17619368 0.17468345]]Network training:  60%|████████████████▏          | 3/5 [02:37<01:44, 52.43s/epoch(s), Training loss(es)=[0.2254303  0.19955994 0.18712686 0.17619368 0.17468345]]Network training:  60%|████████████████▏          | 3/5 [02:54<01:56, 58.11s/epoch(s), Training loss(es)=[0.17626625 0.1966741  0.18310907 0.20632629 0.18856534]]Network training:  80%|█████████████████████▌     | 4/5 [02:54<00:43, 43.58s/epoch(s), Training loss(es)=[0.17626625 0.1966741  0.18310907 0.20632629 0.18856534]]Network training:  80%|█████████████████████▌     | 4/5 [03:11<00:47, 47.79s/epoch(s), Training loss(es)=[0.17093256 0.19635063 0.20184125 0.18865268 0.18529932]]Network training: 100%|███████████████████████████| 5/5 [03:11<00:00, 38.24s/epoch(s), Training loss(es)=[0.17093256 0.19635063 0.20184125 0.18865268 0.18529932]]
####################################################################
Starting training iteration 111.
Average action selection time:  0.3436392636299133
Rollout length:  1000
Rewards obtained: [5994.91769110541]
model train lenght 112000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:34<?, ?epoch(s)/s, Training loss(es)=[0.18203533 0.17755616 0.19050907 0.19102426 0.17431784]]Network training:  20%|█████▍                     | 1/5 [00:34<02:19, 34.80s/epoch(s), Training loss(es)=[0.18203533 0.17755616 0.19050907 0.19102426 0.17431784]]Network training:  20%|█████▍                     | 1/5 [00:48<03:15, 48.93s/epoch(s), Training loss(es)=[0.19970816 0.22265247 0.20777717 0.20830303 0.1745359 ]]Network training:  40%|██████████▊                | 2/5 [00:48<01:13, 24.47s/epoch(s), Training loss(es)=[0.19970816 0.22265247 0.20777717 0.20830303 0.1745359 ]]Network training:  40%|██████████▊                | 2/5 [01:00<01:31, 30.47s/epoch(s), Training loss(es)=[0.18814847 0.19092892 0.170823   0.2386075  0.18132044]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.31s/epoch(s), Training loss(es)=[0.18814847 0.19092892 0.170823   0.2386075  0.18132044]]Network training:  60%|████████████████▏          | 3/5 [01:12<00:48, 24.01s/epoch(s), Training loss(es)=[0.18681285 0.18061744 0.20796977 0.20649107 0.18234682]]Network training:  80%|█████████████████████▌     | 4/5 [01:12<00:18, 18.01s/epoch(s), Training loss(es)=[0.18681285 0.18061744 0.20796977 0.20649107 0.18234682]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.90s/epoch(s), Training loss(es)=[0.21090671 0.20770268 0.1855524  0.17354067 0.23845652]]Network training: 100%|███████████████████████████| 5/5 [01:23<00:00, 16.72s/epoch(s), Training loss(es)=[0.21090671 0.20770268 0.1855524  0.17354067 0.23845652]]
####################################################################
Starting training iteration 112.
Average action selection time:  0.44893905568122866
Rollout length:  1000
Rewards obtained: [5227.8993146423145]
model train lenght 113000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:28<?, ?epoch(s)/s, Training loss(es)=[0.21145737 0.19374044 0.18760131 0.23078956 0.17273492]]Network training:  20%|█████▍                     | 1/5 [00:28<01:53, 28.39s/epoch(s), Training loss(es)=[0.21145737 0.19374044 0.18760131 0.23078956 0.17273492]]Network training:  20%|█████▍                     | 1/5 [00:42<02:50, 42.58s/epoch(s), Training loss(es)=[0.18804504 0.19344178 0.26481596 0.2232129  0.21861562]]Network training:  40%|██████████▊                | 2/5 [00:42<01:03, 21.29s/epoch(s), Training loss(es)=[0.18804504 0.19344178 0.26481596 0.2232129  0.21861562]]Network training:  40%|██████████▊                | 2/5 [00:55<01:22, 27.58s/epoch(s), Training loss(es)=[0.19487393 0.17538272 0.21053852 0.20224373 0.18907736]]Network training:  60%|████████████████▏          | 3/5 [00:55<00:36, 18.38s/epoch(s), Training loss(es)=[0.19487393 0.17538272 0.21053852 0.20224373 0.18907736]]Network training:  60%|████████████████▏          | 3/5 [01:07<00:44, 22.44s/epoch(s), Training loss(es)=[0.19293398 0.16069363 0.17255013 0.19633622 0.18828815]]Network training:  80%|█████████████████████▌     | 4/5 [01:07<00:16, 16.83s/epoch(s), Training loss(es)=[0.19293398 0.16069363 0.17255013 0.19633622 0.18828815]]Network training:  80%|█████████████████████▌     | 4/5 [01:20<00:20, 20.02s/epoch(s), Training loss(es)=[0.21441008 0.3627867  0.18389298 0.23427053 0.18049046]]Network training: 100%|███████████████████████████| 5/5 [01:20<00:00, 16.01s/epoch(s), Training loss(es)=[0.21441008 0.3627867  0.18389298 0.23427053 0.18049046]]
####################################################################
Starting training iteration 113.
Average action selection time:  0.4286953375339508
Rollout length:  1000
Rewards obtained: [6754.961947220978]
model train lenght 114000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:26<?, ?epoch(s)/s, Training loss(es)=[0.18602616 0.23317263 0.19092378 0.20869814 0.19388932]]Network training:  20%|█████▍                     | 1/5 [00:26<01:44, 26.17s/epoch(s), Training loss(es)=[0.18602616 0.23317263 0.19092378 0.20869814 0.19388932]]Network training:  20%|█████▍                     | 1/5 [00:38<02:34, 38.61s/epoch(s), Training loss(es)=[0.1876485  0.18951061 0.21222979 0.19623835 0.20899673]]Network training:  40%|██████████▊                | 2/5 [00:38<00:57, 19.31s/epoch(s), Training loss(es)=[0.1876485  0.18951061 0.21222979 0.19623835 0.20899673]]Network training:  40%|██████████▊                | 2/5 [00:50<01:16, 25.46s/epoch(s), Training loss(es)=[0.18907075 0.19139642 0.21546248 0.20157383 0.18327497]]Network training:  60%|████████████████▏          | 3/5 [00:50<00:33, 16.97s/epoch(s), Training loss(es)=[0.18907075 0.19139642 0.21546248 0.20157383 0.18327497]]Network training:  60%|████████████████▏          | 3/5 [01:02<00:41, 20.70s/epoch(s), Training loss(es)=[0.24301219 0.1858178  0.20510772 0.20216933 0.16904116]]Network training:  80%|█████████████████████▌     | 4/5 [01:02<00:15, 15.53s/epoch(s), Training loss(es)=[0.24301219 0.1858178  0.20510772 0.20216933 0.16904116]]Network training:  80%|█████████████████████▌     | 4/5 [01:13<00:18, 18.44s/epoch(s), Training loss(es)=[0.186698   0.20244114 0.18067461 0.18219951 0.17849177]]Network training: 100%|███████████████████████████| 5/5 [01:13<00:00, 14.75s/epoch(s), Training loss(es)=[0.186698   0.20244114 0.18067461 0.18219951 0.17849177]]
####################################################################
Starting training iteration 114.
Average action selection time:  0.3990159771442413
Rollout length:  1000
Rewards obtained: [8667.485923720284]
model train lenght 115000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.20836267 0.24733189 0.21457376 0.21862468 0.20357263]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.33s/epoch(s), Training loss(es)=[0.20836267 0.24733189 0.21457376 0.21862468 0.20357263]]Network training:  20%|█████▍                     | 1/5 [00:35<02:22, 35.74s/epoch(s), Training loss(es)=[0.18092938 0.17905748 0.19943257 0.19017279 0.19319622]]Network training:  40%|██████████▊                | 2/5 [00:35<00:53, 17.87s/epoch(s), Training loss(es)=[0.18092938 0.17905748 0.19943257 0.19017279 0.19319622]]Network training:  40%|██████████▊                | 2/5 [00:47<01:11, 23.82s/epoch(s), Training loss(es)=[0.17485957 0.19953202 0.21507983 0.18065584 0.19152005]]Network training:  60%|████████████████▏          | 3/5 [00:47<00:31, 15.88s/epoch(s), Training loss(es)=[0.17485957 0.19953202 0.21507983 0.18065584 0.19152005]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:39, 19.64s/epoch(s), Training loss(es)=[0.20555964 0.17467885 0.17508543 0.193276   0.25062338]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.73s/epoch(s), Training loss(es)=[0.20555964 0.17467885 0.17508543 0.193276   0.25062338]]Network training:  80%|█████████████████████▌     | 4/5 [01:10<00:17, 17.71s/epoch(s), Training loss(es)=[0.20199278 0.18386392 0.20900156 0.18629202 0.19830585]]Network training: 100%|███████████████████████████| 5/5 [01:10<00:00, 14.17s/epoch(s), Training loss(es)=[0.20199278 0.18386392 0.20900156 0.18629202 0.19830585]]
####################################################################
Starting training iteration 115.
Average action selection time:  0.40200849318504334
Rollout length:  1000
Rewards obtained: [6262.451198835221]
model train lenght 116000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:19<?, ?epoch(s)/s, Training loss(es)=[0.22156882 0.21893445 0.18705979 0.24101594 0.20401181]]Network training:  20%|█████▍                     | 1/5 [00:19<01:19, 19.96s/epoch(s), Training loss(es)=[0.22156882 0.21893445 0.18705979 0.24101594 0.20401181]]Network training:  20%|█████▍                     | 1/5 [00:33<02:12, 33.22s/epoch(s), Training loss(es)=[0.21574013 0.19029166 0.18040232 0.19799742 0.22393344]]Network training:  40%|██████████▊                | 2/5 [00:33<00:49, 16.61s/epoch(s), Training loss(es)=[0.21574013 0.19029166 0.18040232 0.19799742 0.22393344]]Network training:  40%|██████████▊                | 2/5 [00:46<01:09, 23.07s/epoch(s), Training loss(es)=[0.21792851 0.21902071 0.1977751  0.17595811 0.2173914 ]]Network training:  60%|████████████████▏          | 3/5 [00:46<00:30, 15.38s/epoch(s), Training loss(es)=[0.21792851 0.21902071 0.1977751  0.17595811 0.2173914 ]]Network training:  60%|████████████████▏          | 3/5 [00:59<00:39, 19.68s/epoch(s), Training loss(es)=[0.222935   0.175161   0.19223757 0.23508076 0.18399362]]Network training:  80%|█████████████████████▌     | 4/5 [00:59<00:14, 14.76s/epoch(s), Training loss(es)=[0.222935   0.175161   0.19223757 0.23508076 0.18399362]]Network training:  80%|█████████████████████▌     | 4/5 [01:12<00:18, 18.08s/epoch(s), Training loss(es)=[0.19402066 0.19898899 0.19378038 0.19633004 0.20842844]]Network training: 100%|███████████████████████████| 5/5 [01:12<00:00, 14.46s/epoch(s), Training loss(es)=[0.19402066 0.19898899 0.19378038 0.19633004 0.20842844]]
####################################################################
Starting training iteration 116.
Average action selection time:  0.3787733154296875
Rollout length:  1000
Rewards obtained: [6783.325207956115]
model train lenght 117000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.21260487 0.2704512  0.19494995 0.1860019  0.1967352 ]]Network training:  20%|█████▍                     | 1/5 [00:15<01:00, 15.12s/epoch(s), Training loss(es)=[0.21260487 0.2704512  0.19494995 0.1860019  0.1967352 ]]Network training:  20%|█████▍                     | 1/5 [00:29<01:57, 29.49s/epoch(s), Training loss(es)=[0.18147263 0.17202659 0.20029967 0.22312364 0.19713165]]Network training:  40%|██████████▊                | 2/5 [00:29<00:44, 14.75s/epoch(s), Training loss(es)=[0.18147263 0.17202659 0.20029967 0.22312364 0.19713165]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.02s/epoch(s), Training loss(es)=[0.1879526  0.2065686  0.1796251  0.21105981 0.2014915 ]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.68s/epoch(s), Training loss(es)=[0.1879526  0.2065686  0.1796251  0.21105981 0.2014915 ]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.47s/epoch(s), Training loss(es)=[0.20361204 0.17443809 0.20627715 0.18229182 0.2002673 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.60s/epoch(s), Training loss(es)=[0.20361204 0.17443809 0.20627715 0.18229182 0.2002673 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:12<00:18, 18.18s/epoch(s), Training loss(es)=[0.19120102 0.18109594 0.17423894 0.21119155 0.17971131]]Network training: 100%|███████████████████████████| 5/5 [01:12<00:00, 14.55s/epoch(s), Training loss(es)=[0.19120102 0.18109594 0.17423894 0.21119155 0.17971131]]
####################################################################
Starting training iteration 117.
Average action selection time:  0.3801006374359131
Rollout length:  1000
Rewards obtained: [5252.74210562155]
model train lenght 118000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:14<?, ?epoch(s)/s, Training loss(es)=[0.26107582 0.19695368 0.17911823 0.18769926 0.19910009]]Network training:  20%|█████▍                     | 1/5 [00:14<00:56, 14.06s/epoch(s), Training loss(es)=[0.26107582 0.19695368 0.17911823 0.18769926 0.19910009]]Network training:  20%|█████▍                     | 1/5 [00:28<01:54, 28.50s/epoch(s), Training loss(es)=[0.17627703 0.19053371 0.22248603 0.2512617  0.21155065]]Network training:  40%|██████████▊                | 2/5 [00:28<00:42, 14.25s/epoch(s), Training loss(es)=[0.17627703 0.19053371 0.22248603 0.2512617  0.21155065]]Network training:  40%|██████████▊                | 2/5 [00:42<01:04, 21.38s/epoch(s), Training loss(es)=[0.18107285 0.2053981  0.20191735 0.20613141 0.21259639]]Network training:  60%|████████████████▏          | 3/5 [00:42<00:28, 14.25s/epoch(s), Training loss(es)=[0.18107285 0.2053981  0.20191735 0.20613141 0.21259639]]Network training:  60%|████████████████▏          | 3/5 [00:57<00:38, 19.27s/epoch(s), Training loss(es)=[0.17900145 0.1797712  0.19328174 0.19406697 0.1939184 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.46s/epoch(s), Training loss(es)=[0.17900145 0.1797712  0.19328174 0.19406697 0.1939184 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:13<00:18, 18.30s/epoch(s), Training loss(es)=[0.49236763 0.19672877 0.18290721 0.18648255 0.17492916]]Network training: 100%|███████████████████████████| 5/5 [01:13<00:00, 14.64s/epoch(s), Training loss(es)=[0.49236763 0.19672877 0.18290721 0.18648255 0.17492916]]
####################################################################
Starting training iteration 118.
Average action selection time:  0.4725772635936737
Rollout length:  1000
Rewards obtained: [9603.824209639006]
model train lenght 119000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.22948614 0.196255   0.20407966 0.19489802 0.21030053]]Network training:  20%|█████▍                     | 1/5 [00:13<00:52, 13.09s/epoch(s), Training loss(es)=[0.22948614 0.196255   0.20407966 0.19489802 0.21030053]]Network training:  20%|█████▍                     | 1/5 [00:26<01:44, 26.18s/epoch(s), Training loss(es)=[0.1902777  0.19043036 0.18669435 0.19819055 0.20929383]]Network training:  40%|██████████▊                | 2/5 [00:26<00:39, 13.09s/epoch(s), Training loss(es)=[0.1902777  0.19043036 0.18669435 0.19819055 0.20929383]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.98s/epoch(s), Training loss(es)=[0.18820964 0.22496489 0.17378287 0.22944434 0.1935289 ]]Network training:  60%|████████████████▏          | 3/5 [00:39<00:26, 13.32s/epoch(s), Training loss(es)=[0.18820964 0.22496489 0.17378287 0.22944434 0.1935289 ]]Network training:  60%|████████████████▏          | 3/5 [00:53<00:35, 17.74s/epoch(s), Training loss(es)=[0.18820803 0.1927903  0.18910162 0.19084945 0.1942976 ]]Network training:  80%|█████████████████████▌     | 4/5 [00:53<00:13, 13.30s/epoch(s), Training loss(es)=[0.18820803 0.1927903  0.18910162 0.19084945 0.1942976 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:06<00:16, 16.53s/epoch(s), Training loss(es)=[0.20148735 0.18461585 0.1924502  0.20441191 0.1846701 ]]Network training: 100%|███████████████████████████| 5/5 [01:06<00:00, 13.22s/epoch(s), Training loss(es)=[0.20148735 0.18461585 0.1924502  0.20441191 0.1846701 ]]
####################################################################
Starting training iteration 119.
Average action selection time:  1.0363911941051482
Rollout length:  1000
Rewards obtained: [7008.535636437506]
model train lenght 120000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.21587719 0.1976752  0.19990596 0.19874905 0.20795435]]Network training:  20%|█████▍                     | 1/5 [00:13<00:54, 13.66s/epoch(s), Training loss(es)=[0.21587719 0.1976752  0.19990596 0.19874905 0.20795435]]Network training:  20%|█████▍                     | 1/5 [00:26<01:46, 26.65s/epoch(s), Training loss(es)=[0.21501258 0.19655229 0.21065032 0.25410137 0.20358518]]Network training:  40%|██████████▊                | 2/5 [00:26<00:39, 13.33s/epoch(s), Training loss(es)=[0.21501258 0.19655229 0.21065032 0.25410137 0.20358518]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.87s/epoch(s), Training loss(es)=[0.20745751 0.18973646 0.35180703 0.16834725 0.20197491]]Network training:  60%|████████████████▏          | 3/5 [00:39<00:26, 13.24s/epoch(s), Training loss(es)=[0.20745751 0.18973646 0.35180703 0.16834725 0.20197491]]Network training:  60%|████████████████▏          | 3/5 [00:52<00:35, 17.55s/epoch(s), Training loss(es)=[0.19126903 0.18974523 0.17935006 0.18789369 0.19401582]]Network training:  80%|█████████████████████▌     | 4/5 [00:52<00:13, 13.16s/epoch(s), Training loss(es)=[0.19126903 0.18974523 0.17935006 0.18789369 0.19401582]]Network training:  80%|█████████████████████▌     | 4/5 [01:05<00:16, 16.29s/epoch(s), Training loss(es)=[0.21936166 0.20336466 0.21844128 0.20220676 0.25043526]]Network training: 100%|███████████████████████████| 5/5 [01:05<00:00, 13.04s/epoch(s), Training loss(es)=[0.21936166 0.20336466 0.21844128 0.20220676 0.25043526]]
####################################################################
Starting training iteration 120.
Average action selection time:  0.5354020941257477
Rollout length:  1000
Rewards obtained: [7463.652669572728]
model train lenght 121000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:13<?, ?epoch(s)/s, Training loss(es)=[0.1860023  0.19695398 0.18971607 0.18170744 0.22234862]]Network training:  20%|█████▍                     | 1/5 [00:13<00:54, 13.65s/epoch(s), Training loss(es)=[0.1860023  0.19695398 0.18971607 0.18170744 0.22234862]]Network training:  20%|█████▍                     | 1/5 [00:27<01:48, 27.05s/epoch(s), Training loss(es)=[0.17856313 0.22344439 0.2094436  0.2671475  0.20702793]]Network training:  40%|██████████▊                | 2/5 [00:27<00:40, 13.52s/epoch(s), Training loss(es)=[0.17856313 0.22344439 0.2094436  0.2671475  0.20702793]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.91s/epoch(s), Training loss(es)=[0.20097259 0.22362678 0.19504954 0.20634599 0.21946472]]Network training:  60%|████████████████▏          | 3/5 [00:39<00:26, 13.27s/epoch(s), Training loss(es)=[0.20097259 0.22362678 0.19504954 0.20634599 0.21946472]]Network training:  60%|████████████████▏          | 3/5 [00:52<00:35, 17.53s/epoch(s), Training loss(es)=[0.22626814 0.17693204 0.19491792 0.22246407 0.20351614]]Network training:  80%|█████████████████████▌     | 4/5 [00:52<00:13, 13.15s/epoch(s), Training loss(es)=[0.22626814 0.17693204 0.19491792 0.22246407 0.20351614]]Network training:  80%|█████████████████████▌     | 4/5 [01:11<00:17, 17.87s/epoch(s), Training loss(es)=[0.23403946 0.18233022 0.17466003 0.20180793 0.20839131]]Network training: 100%|███████████████████████████| 5/5 [01:11<00:00, 14.30s/epoch(s), Training loss(es)=[0.23403946 0.18233022 0.17466003 0.20180793 0.20839131]]
####################################################################
Starting training iteration 121.
Average action selection time:  0.4002784152030945
Rollout length:  1000
Rewards obtained: [7329.27024197682]
model train lenght 122000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.2198663  0.20102483 0.20513183 0.22441143 0.192987  ]]Network training:  20%|█████▍                     | 1/5 [00:16<01:05, 16.25s/epoch(s), Training loss(es)=[0.2198663  0.20102483 0.20513183 0.22441143 0.192987  ]]Network training:  20%|█████▍                     | 1/5 [01:10<04:42, 70.63s/epoch(s), Training loss(es)=[0.19342588 0.25553077 0.24093589 0.18210465 0.2442884 ]]Network training:  40%|██████████▊                | 2/5 [01:10<01:45, 35.32s/epoch(s), Training loss(es)=[0.19342588 0.25553077 0.24093589 0.18210465 0.2442884 ]]Network training:  40%|██████████▊                | 2/5 [01:23<02:05, 41.83s/epoch(s), Training loss(es)=[0.16562623 0.28793555 0.19386832 0.20668225 0.21784504]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.89s/epoch(s), Training loss(es)=[0.16562623 0.28793555 0.19386832 0.20668225 0.21784504]]Network training:  60%|████████████████▏          | 3/5 [01:36<01:04, 32.12s/epoch(s), Training loss(es)=[0.19055949 0.20378359 0.18520772 0.23008272 0.25834015]]Network training:  80%|█████████████████████▌     | 4/5 [01:36<00:24, 24.09s/epoch(s), Training loss(es)=[0.19055949 0.20378359 0.18520772 0.23008272 0.25834015]]Network training:  80%|█████████████████████▌     | 4/5 [01:58<00:29, 29.55s/epoch(s), Training loss(es)=[0.18860285 0.23680604 0.21018672 0.22035193 0.17533597]]Network training: 100%|███████████████████████████| 5/5 [01:58<00:00, 23.64s/epoch(s), Training loss(es)=[0.18860285 0.23680604 0.21018672 0.22035193 0.17533597]]
####################################################################
Starting training iteration 122.
Average action selection time:  0.46862203311920164
Rollout length:  1000
Rewards obtained: [8125.4523183762585]
model train lenght 123000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.23404373 0.21456821 0.1997411  0.23738252 0.19238177]]Network training:  20%|█████▍                     | 1/5 [00:15<01:00, 15.18s/epoch(s), Training loss(es)=[0.23404373 0.21456821 0.1997411  0.23738252 0.19238177]]Network training:  20%|█████▍                     | 1/5 [00:29<01:57, 29.31s/epoch(s), Training loss(es)=[0.19243605 0.17911577 0.19416922 0.23852825 0.2250072 ]]Network training:  40%|██████████▊                | 2/5 [00:29<00:43, 14.66s/epoch(s), Training loss(es)=[0.19243605 0.17911577 0.19416922 0.23852825 0.2250072 ]]Network training:  40%|██████████▊                | 2/5 [00:42<01:03, 21.21s/epoch(s), Training loss(es)=[0.20388845 0.20950322 0.20426583 0.22415896 0.18896183]]Network training:  60%|████████████████▏          | 3/5 [00:42<00:28, 14.14s/epoch(s), Training loss(es)=[0.20388845 0.20950322 0.20426583 0.22415896 0.18896183]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.34s/epoch(s), Training loss(es)=[0.17297271 0.19996597 0.22051597 0.28864646 0.21062222]]Network training:  80%|█████████████████████▌     | 4/5 [00:58<00:14, 14.50s/epoch(s), Training loss(es)=[0.17297271 0.19996597 0.22051597 0.28864646 0.21062222]]Network training:  80%|█████████████████████▌     | 4/5 [01:31<00:22, 22.89s/epoch(s), Training loss(es)=[0.20532249 0.19505796 0.25017065 0.21174043 0.19051513]]Network training: 100%|███████████████████████████| 5/5 [01:31<00:00, 18.31s/epoch(s), Training loss(es)=[0.20532249 0.19505796 0.25017065 0.21174043 0.19051513]]
####################################################################
Starting training iteration 123.
Average action selection time:  0.48390315771102904
Rollout length:  1000
Rewards obtained: [5713.40536504008]
model train lenght 124000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [05:14<?, ?epoch(s)/s, Training loss(es)=[0.20201206 0.19036016 0.18860272 0.21899617 0.20117845]]Network training:  20%|█████▏                    | 1/5 [05:14<20:57, 314.46s/epoch(s), Training loss(es)=[0.20201206 0.19036016 0.18860272 0.21899617 0.20117845]]Network training:  20%|█████▏                    | 1/5 [05:31<22:06, 331.61s/epoch(s), Training loss(es)=[0.21064545 0.19087835 0.21137512 0.19377232 0.19287741]]Network training:  40%|██████████▍               | 2/5 [05:31<08:17, 165.80s/epoch(s), Training loss(es)=[0.21064545 0.19087835 0.21137512 0.19377232 0.19287741]]Network training:  40%|██████████▍               | 2/5 [05:45<08:38, 172.87s/epoch(s), Training loss(es)=[0.192406   0.18468069 0.25767553 0.23061131 0.22520564]]Network training:  60%|███████████████▌          | 3/5 [05:45<03:50, 115.25s/epoch(s), Training loss(es)=[0.192406   0.18468069 0.25767553 0.23061131 0.22520564]]Network training:  60%|███████████████▌          | 3/5 [05:59<03:59, 119.98s/epoch(s), Training loss(es)=[0.21757263 0.20080413 0.19197108 0.22895408 0.19708356]]Network training:  80%|█████████████████████▌     | 4/5 [05:59<01:29, 89.99s/epoch(s), Training loss(es)=[0.21757263 0.20080413 0.19197108 0.22895408 0.19708356]]Network training:  80%|█████████████████████▌     | 4/5 [06:37<01:39, 99.42s/epoch(s), Training loss(es)=[0.22680067 0.18318354 0.24605341 0.19152802 0.21517822]]Network training: 100%|███████████████████████████| 5/5 [06:37<00:00, 79.53s/epoch(s), Training loss(es)=[0.22680067 0.18318354 0.24605341 0.19152802 0.21517822]]
####################################################################
Starting training iteration 124.
Average action selection time:  0.3487335789203644
Rollout length:  1000
Rewards obtained: [6633.128375931004]
model train lenght 125000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.25053325 0.20437267 0.18930243 0.22735244 0.27789053]]Network training:  20%|█████▍                     | 1/5 [00:15<01:01, 15.48s/epoch(s), Training loss(es)=[0.25053325 0.20437267 0.18930243 0.22735244 0.27789053]]Network training:  20%|█████▍                     | 1/5 [00:30<02:02, 30.53s/epoch(s), Training loss(es)=[0.23544234 0.27250266 0.2128061  0.21118459 0.18871683]]Network training:  40%|██████████▊                | 2/5 [00:30<00:45, 15.27s/epoch(s), Training loss(es)=[0.23544234 0.27250266 0.2128061  0.21118459 0.18871683]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.18s/epoch(s), Training loss(es)=[0.21447514 0.22308205 0.1920707  0.21200909 0.18465215]]Network training:  60%|████████████████▏          | 3/5 [00:44<00:29, 14.79s/epoch(s), Training loss(es)=[0.21447514 0.22308205 0.1920707  0.21200909 0.18465215]]Network training:  60%|████████████████▏          | 3/5 [00:57<00:38, 19.30s/epoch(s), Training loss(es)=[0.18473414 0.22117051 0.1988315  0.22695816 0.21029323]]Network training:  80%|█████████████████████▌     | 4/5 [00:57<00:14, 14.48s/epoch(s), Training loss(es)=[0.18473414 0.22117051 0.1988315  0.22695816 0.21029323]]Network training:  80%|█████████████████████▌     | 4/5 [01:34<00:23, 23.72s/epoch(s), Training loss(es)=[0.19988514 0.18516754 0.21927561 0.21501467 0.19284736]]Network training: 100%|███████████████████████████| 5/5 [01:34<00:00, 18.97s/epoch(s), Training loss(es)=[0.19988514 0.18516754 0.21927561 0.21501467 0.19284736]]
####################################################################
Starting training iteration 125.
Average action selection time:  0.3503641636371613
Rollout length:  1000
Rewards obtained: [7400.8240639029145]
model train lenght 126000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.21402913 0.21053247 0.19879346 0.23351438 0.21326308]]Network training:  20%|█████▍                     | 1/5 [00:15<01:02, 15.58s/epoch(s), Training loss(es)=[0.21402913 0.21053247 0.19879346 0.23351438 0.21326308]]Network training:  20%|█████▍                     | 1/5 [00:30<02:02, 30.57s/epoch(s), Training loss(es)=[0.22758718 0.20739628 0.19812289 0.24112888 0.22201407]]Network training:  40%|██████████▊                | 2/5 [00:30<00:45, 15.28s/epoch(s), Training loss(es)=[0.22758718 0.20739628 0.19812289 0.24112888 0.22201407]]Network training:  40%|██████████▊                | 2/5 [00:45<01:08, 22.82s/epoch(s), Training loss(es)=[0.20943186 0.19750243 0.20166169 0.18690751 0.30961683]]Network training:  60%|████████████████▏          | 3/5 [00:45<00:30, 15.22s/epoch(s), Training loss(es)=[0.20943186 0.19750243 0.20166169 0.18690751 0.30961683]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.28s/epoch(s), Training loss(es)=[0.21986504 0.2022711  0.22300696 0.22437729 0.18150254]]Network training:  80%|█████████████████████▌     | 4/5 [01:03<00:15, 15.96s/epoch(s), Training loss(es)=[0.21986504 0.2022711  0.22300696 0.22437729 0.18150254]]Network training:  80%|█████████████████████▌     | 4/5 [01:42<00:25, 25.52s/epoch(s), Training loss(es)=[0.21034814 0.27163437 0.2060585  0.1971283  0.19817021]]Network training: 100%|███████████████████████████| 5/5 [01:42<00:00, 20.42s/epoch(s), Training loss(es)=[0.21034814 0.27163437 0.2060585  0.1971283  0.19817021]]
####################################################################
Starting training iteration 126.
Average action selection time:  0.3461763169765472
Rollout length:  1000
Rewards obtained: [7255.763407420056]
model train lenght 127000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.183637   0.22911985 0.19469798 0.19745469 0.20384432]]Network training:  20%|█████▍                     | 1/5 [00:16<01:05, 16.43s/epoch(s), Training loss(es)=[0.183637   0.22911985 0.19469798 0.19745469 0.20384432]]Network training:  20%|█████▍                     | 1/5 [00:32<02:09, 32.49s/epoch(s), Training loss(es)=[0.21421152 0.18703273 0.20543148 0.19687656 0.19423787]]Network training:  40%|██████████▊                | 2/5 [00:32<00:48, 16.25s/epoch(s), Training loss(es)=[0.21421152 0.18703273 0.20543148 0.19687656 0.19423787]]Network training:  40%|██████████▊                | 2/5 [00:48<01:13, 24.36s/epoch(s), Training loss(es)=[0.19292967 0.20126362 0.19310378 0.21243384 0.19468519]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.24s/epoch(s), Training loss(es)=[0.19292967 0.20126362 0.19310378 0.21243384 0.19468519]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.91s/epoch(s), Training loss(es)=[0.19171935 0.2017265  0.1983954  0.24489546 0.21739319]]Network training:  80%|█████████████████████▌     | 4/5 [01:11<00:17, 17.94s/epoch(s), Training loss(es)=[0.19171935 0.2017265  0.1983954  0.24489546 0.21739319]]Network training:  80%|█████████████████████▌     | 4/5 [01:50<00:27, 27.57s/epoch(s), Training loss(es)=[0.1777702  0.20304513 0.18067472 0.21113311 0.20491406]]Network training: 100%|███████████████████████████| 5/5 [01:50<00:00, 22.05s/epoch(s), Training loss(es)=[0.1777702  0.20304513 0.18067472 0.21113311 0.20491406]]
####################################################################
Starting training iteration 127.
Average action selection time:  0.34010000443458555
Rollout length:  1000
Rewards obtained: [6734.16168051607]
model train lenght 128000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.23515572 0.21717422 0.18951571 0.20023017 0.20599698]]Network training:  20%|█████▍                     | 1/5 [00:16<01:04, 16.15s/epoch(s), Training loss(es)=[0.23515572 0.21717422 0.18951571 0.20023017 0.20599698]]Network training:  20%|█████▍                     | 1/5 [00:32<02:08, 32.23s/epoch(s), Training loss(es)=[0.22982325 0.21054016 0.21451472 0.19175419 0.19733334]]Network training:  40%|██████████▊                | 2/5 [00:32<00:48, 16.12s/epoch(s), Training loss(es)=[0.22982325 0.21054016 0.21451472 0.19175419 0.19733334]]Network training:  40%|██████████▊                | 2/5 [00:48<01:12, 24.05s/epoch(s), Training loss(es)=[0.31643847 0.21134876 0.1996556  0.21261148 0.18980317]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.03s/epoch(s), Training loss(es)=[0.31643847 0.21134876 0.1996556  0.21261148 0.18980317]]Network training:  60%|████████████████▏          | 3/5 [01:08<00:45, 22.98s/epoch(s), Training loss(es)=[0.17904277 0.2097447  0.19787219 0.21483323 0.20266394]]Network training:  80%|█████████████████████▌     | 4/5 [01:08<00:17, 17.24s/epoch(s), Training loss(es)=[0.17904277 0.2097447  0.19787219 0.21483323 0.20266394]]Network training:  80%|█████████████████████▌     | 4/5 [01:47<00:26, 26.96s/epoch(s), Training loss(es)=[0.20141283 0.1928624  0.19097917 0.20294651 0.20055412]]Network training: 100%|███████████████████████████| 5/5 [01:47<00:00, 21.56s/epoch(s), Training loss(es)=[0.20141283 0.1928624  0.19097917 0.20294651 0.20055412]]
####################################################################
Starting training iteration 128.
Average action selection time:  0.3428881721496582
Rollout length:  1000
Rewards obtained: [9234.970850977505]
model train lenght 129000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.26569965 0.2122883  0.20835952 0.22772254 0.19583833]]Network training:  20%|█████▍                     | 1/5 [00:16<01:06, 16.66s/epoch(s), Training loss(es)=[0.26569965 0.2122883  0.20835952 0.22772254 0.19583833]]Network training:  20%|█████▍                     | 1/5 [00:34<02:16, 34.19s/epoch(s), Training loss(es)=[0.23215781 0.22055364 0.20088796 0.19823703 0.20848255]]Network training:  40%|██████████▊                | 2/5 [00:34<00:51, 17.10s/epoch(s), Training loss(es)=[0.23215781 0.22055364 0.20088796 0.19823703 0.20848255]]Network training:  40%|██████████▊                | 2/5 [00:51<01:17, 25.76s/epoch(s), Training loss(es)=[0.20846596 0.1967803  0.18634786 0.20268948 0.35577998]]Network training:  60%|████████████████▏          | 3/5 [00:51<00:34, 17.17s/epoch(s), Training loss(es)=[0.20846596 0.1967803  0.18634786 0.20268948 0.35577998]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.67s/epoch(s), Training loss(es)=[0.20583174 0.20554277 0.19787684 0.1945824  0.2141934 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.75s/epoch(s), Training loss(es)=[0.20583174 0.20554277 0.19787684 0.1945824  0.2141934 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:02<00:30, 30.55s/epoch(s), Training loss(es)=[0.23940901 0.18461648 0.1851996  0.2117731  0.22148614]]Network training: 100%|███████████████████████████| 5/5 [02:02<00:00, 24.44s/epoch(s), Training loss(es)=[0.23940901 0.18461648 0.1851996  0.2117731  0.22148614]]
####################################################################
Starting training iteration 129.
Average action selection time:  0.3294490218162537
Rollout length:  1000
Rewards obtained: [6562.433966246443]
model train lenght 130000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.22329031 0.21878648 0.18113124 0.21419129 0.21973823]]Network training:  20%|█████▍                     | 1/5 [00:15<01:03, 15.91s/epoch(s), Training loss(es)=[0.22329031 0.21878648 0.18113124 0.21419129 0.21973823]]Network training:  20%|█████▍                     | 1/5 [00:32<02:08, 32.11s/epoch(s), Training loss(es)=[0.18131645 0.17592748 0.21216215 0.21499152 0.22747803]]Network training:  40%|██████████▊                | 2/5 [00:32<00:48, 16.06s/epoch(s), Training loss(es)=[0.18131645 0.17592748 0.21216215 0.21499152 0.22747803]]Network training:  40%|██████████▊                | 2/5 [00:48<01:12, 24.17s/epoch(s), Training loss(es)=[0.18326321 0.19700947 0.20571929 0.22697315 0.20689851]]Network training:  60%|████████████████▏          | 3/5 [00:48<00:32, 16.11s/epoch(s), Training loss(es)=[0.18326321 0.19700947 0.20571929 0.22697315 0.20689851]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.33s/epoch(s), Training loss(es)=[0.20872866 0.25892776 0.19110881 0.2242781  0.2692624 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.49s/epoch(s), Training loss(es)=[0.20872866 0.25892776 0.19110881 0.2242781  0.2692624 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:01<00:30, 30.34s/epoch(s), Training loss(es)=[0.22515991 0.28004855 0.18624829 0.19182956 0.19889213]]Network training: 100%|███████████████████████████| 5/5 [02:01<00:00, 24.27s/epoch(s), Training loss(es)=[0.22515991 0.28004855 0.18624829 0.19182956 0.19889213]]
####################################################################
Starting training iteration 130.
Average action selection time:  0.3260157837867737
Rollout length:  1000
Rewards obtained: [7165.317610348783]
model train lenght 131000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.20966727 0.20022503 0.21576184 0.31944582 0.2160007 ]]Network training:  20%|█████▍                     | 1/5 [00:16<01:06, 16.57s/epoch(s), Training loss(es)=[0.20966727 0.20022503 0.21576184 0.31944582 0.2160007 ]]Network training:  20%|█████▍                     | 1/5 [00:32<02:11, 32.90s/epoch(s), Training loss(es)=[0.20613667 0.20602727 0.2013318  0.22359197 0.23869546]]Network training:  40%|██████████▊                | 2/5 [00:32<00:49, 16.45s/epoch(s), Training loss(es)=[0.20613667 0.20602727 0.2013318  0.22359197 0.23869546]]Network training:  40%|██████████▊                | 2/5 [00:50<01:15, 25.06s/epoch(s), Training loss(es)=[0.23214312 0.20426537 0.18220383 0.2194823  0.19596818]]Network training:  60%|████████████████▏          | 3/5 [00:50<00:33, 16.71s/epoch(s), Training loss(es)=[0.23214312 0.20426537 0.18220383 0.2194823  0.19596818]]Network training:  60%|████████████████▏          | 3/5 [01:28<00:58, 29.49s/epoch(s), Training loss(es)=[0.18770793 0.18495359 0.23187879 0.188472   0.18547177]]Network training:  80%|█████████████████████▌     | 4/5 [01:28<00:22, 22.12s/epoch(s), Training loss(es)=[0.18770793 0.18495359 0.23187879 0.188472   0.18547177]]Network training:  80%|█████████████████████▌     | 4/5 [02:08<00:32, 32.05s/epoch(s), Training loss(es)=[0.17143711 0.17070258 0.21348588 0.21200913 0.2115378 ]]Network training: 100%|███████████████████████████| 5/5 [02:08<00:00, 25.64s/epoch(s), Training loss(es)=[0.17143711 0.17070258 0.21348588 0.21200913 0.2115378 ]]
####################################################################
Starting training iteration 131.
Average action selection time:  0.31968987941741944
Rollout length:  1000
Rewards obtained: [11159.186054691509]
model train lenght 132000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:15<?, ?epoch(s)/s, Training loss(es)=[0.22319485 0.21334593 0.336276   0.21925628 0.20273462]]Network training:  20%|█████▍                     | 1/5 [00:15<01:03, 15.97s/epoch(s), Training loss(es)=[0.22319485 0.21334593 0.336276   0.21925628 0.20273462]]Network training:  20%|█████▍                     | 1/5 [00:31<02:06, 31.66s/epoch(s), Training loss(es)=[0.28097925 0.21674587 0.22332618 0.20175076 0.3246073 ]]Network training:  40%|██████████▊                | 2/5 [00:31<00:47, 15.83s/epoch(s), Training loss(es)=[0.28097925 0.21674587 0.22332618 0.20175076 0.3246073 ]]Network training:  40%|██████████▊                | 2/5 [00:51<01:16, 25.65s/epoch(s), Training loss(es)=[0.20312151 0.20966052 0.3038857  0.20856482 0.1909075 ]]Network training:  60%|████████████████▏          | 3/5 [00:51<00:34, 17.10s/epoch(s), Training loss(es)=[0.20312151 0.20966052 0.3038857  0.20856482 0.1909075 ]]Network training:  60%|████████████████▏          | 3/5 [01:31<01:00, 30.43s/epoch(s), Training loss(es)=[0.1953382  0.21019322 0.1929868  0.20048189 0.21831135]]Network training:  80%|█████████████████████▌     | 4/5 [01:31<00:22, 22.82s/epoch(s), Training loss(es)=[0.1953382  0.21019322 0.1929868  0.20048189 0.21831135]]Network training:  80%|█████████████████████▌     | 4/5 [02:11<00:32, 32.83s/epoch(s), Training loss(es)=[0.20945576 0.17822579 0.1757409  0.201166   0.19773784]]Network training: 100%|███████████████████████████| 5/5 [02:11<00:00, 26.27s/epoch(s), Training loss(es)=[0.20945576 0.17822579 0.1757409  0.201166   0.19773784]]
####################################################################
Starting training iteration 132.
Average action selection time:  0.3136129467487335
Rollout length:  1000
Rewards obtained: [8940.225134865574]
model train lenght 133000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:16<?, ?epoch(s)/s, Training loss(es)=[0.26581144 0.2196477  0.19057962 0.2546486  0.2215035 ]]Network training:  20%|█████▍                     | 1/5 [00:16<01:05, 16.41s/epoch(s), Training loss(es)=[0.26581144 0.2196477  0.19057962 0.2546486  0.2215035 ]]Network training:  20%|█████▍                     | 1/5 [00:33<02:12, 33.11s/epoch(s), Training loss(es)=[0.24894868 0.20299391 0.20650071 0.2233961  0.19695635]]Network training:  40%|██████████▊                | 2/5 [00:33<00:49, 16.56s/epoch(s), Training loss(es)=[0.24894868 0.20299391 0.20650071 0.2233961  0.19695635]]Network training:  40%|██████████▊                | 2/5 [00:53<01:19, 26.58s/epoch(s), Training loss(es)=[0.27877942 0.18833643 0.21484455 0.20896108 0.26260862]]Network training:  60%|████████████████▏          | 3/5 [00:53<00:35, 17.72s/epoch(s), Training loss(es)=[0.27877942 0.18833643 0.21484455 0.20896108 0.26260862]]Network training:  60%|████████████████▏          | 3/5 [01:33<01:02, 31.17s/epoch(s), Training loss(es)=[0.18799561 0.20048892 0.18467832 0.23068984 0.23209783]]Network training:  80%|█████████████████████▌     | 4/5 [01:33<00:23, 23.37s/epoch(s), Training loss(es)=[0.18799561 0.20048892 0.18467832 0.23068984 0.23209783]]Network training:  80%|█████████████████████▌     | 4/5 [02:13<00:33, 33.46s/epoch(s), Training loss(es)=[0.1966076  0.23581801 0.20203872 0.19320446 0.20449005]]Network training: 100%|███████████████████████████| 5/5 [02:13<00:00, 26.77s/epoch(s), Training loss(es)=[0.1966076  0.23581801 0.20203872 0.19320446 0.20449005]]
####################################################################
Starting training iteration 133.
Average action selection time:  0.31176478266716
Rollout length:  1000
Rewards obtained: [7127.1640038126825]
model train lenght 134000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.1994591  0.21730398 0.24527283 0.21274585 0.20889592]]Network training:  20%|█████▍                     | 1/5 [00:17<01:09, 17.47s/epoch(s), Training loss(es)=[0.1994591  0.21730398 0.24527283 0.21274585 0.20889592]]Network training:  20%|█████▍                     | 1/5 [00:34<02:19, 34.77s/epoch(s), Training loss(es)=[0.18659048 0.21939388 0.19854565 0.22184531 0.2037246 ]]Network training:  40%|██████████▊                | 2/5 [00:34<00:52, 17.38s/epoch(s), Training loss(es)=[0.18659048 0.21939388 0.19854565 0.22184531 0.2037246 ]]Network training:  40%|██████████▊                | 2/5 [01:01<01:31, 30.62s/epoch(s), Training loss(es)=[0.20863399 0.2001737  0.19555059 0.22878145 0.21834263]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:40, 20.41s/epoch(s), Training loss(es)=[0.20863399 0.2001737  0.19555059 0.22878145 0.21834263]]Network training:  60%|████████████████▏          | 3/5 [01:41<01:07, 33.96s/epoch(s), Training loss(es)=[0.20787652 0.20937823 0.25691834 0.20710911 0.21852769]]Network training:  80%|█████████████████████▌     | 4/5 [01:41<00:25, 25.47s/epoch(s), Training loss(es)=[0.20787652 0.20937823 0.25691834 0.20710911 0.21852769]]Network training:  80%|█████████████████████▌     | 4/5 [02:22<00:35, 35.63s/epoch(s), Training loss(es)=[0.19947389 0.22199301 0.18863007 0.19805697 0.1921957 ]]Network training: 100%|███████████████████████████| 5/5 [02:22<00:00, 28.50s/epoch(s), Training loss(es)=[0.19947389 0.22199301 0.18863007 0.19805697 0.1921957 ]]
####################################################################
Starting training iteration 134.
Average action selection time:  0.3032170219421387
Rollout length:  1000
Rewards obtained: [9904.611283519063]
model train lenght 135000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.20259982 0.20175469 0.21946709 0.23553303 0.23602246]]Network training:  20%|█████▍                     | 1/5 [00:17<01:10, 17.70s/epoch(s), Training loss(es)=[0.20259982 0.20175469 0.21946709 0.23553303 0.23602246]]Network training:  20%|█████▍                     | 1/5 [00:33<02:15, 33.89s/epoch(s), Training loss(es)=[0.23930733 0.21687791 0.19070761 0.22842343 0.20548445]]Network training:  40%|██████████▊                | 2/5 [00:33<00:50, 16.94s/epoch(s), Training loss(es)=[0.23930733 0.21687791 0.19070761 0.22842343 0.20548445]]Network training:  40%|██████████▊                | 2/5 [01:05<01:37, 32.51s/epoch(s), Training loss(es)=[0.20787393 0.23478033 0.21883596 0.22112142 0.22248963]]Network training:  60%|████████████████▏          | 3/5 [01:05<00:43, 21.68s/epoch(s), Training loss(es)=[0.20787393 0.23478033 0.21883596 0.22112142 0.22248963]]Network training:  60%|████████████████▏          | 3/5 [01:45<01:10, 35.33s/epoch(s), Training loss(es)=[0.20490886 0.21220107 0.20372148 0.19747402 0.19983976]]Network training:  80%|█████████████████████▌     | 4/5 [01:45<00:26, 26.49s/epoch(s), Training loss(es)=[0.20490886 0.21220107 0.20372148 0.19747402 0.19983976]]Network training:  80%|█████████████████████▌     | 4/5 [02:26<00:36, 36.73s/epoch(s), Training loss(es)=[0.22985622 0.20467669 0.20470588 0.27391964 0.26784813]]Network training: 100%|███████████████████████████| 5/5 [02:26<00:00, 29.39s/epoch(s), Training loss(es)=[0.22985622 0.20467669 0.20470588 0.27391964 0.26784813]]
####################################################################
Starting training iteration 135.
Average action selection time:  0.29677550530433655
Rollout length:  1000
Rewards obtained: [4317.385131356992]
model train lenght 136000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:18<?, ?epoch(s)/s, Training loss(es)=[0.27732965 0.21708809 0.21450432 0.25824648 0.23188758]]Network training:  20%|█████▍                     | 1/5 [00:18<01:13, 18.41s/epoch(s), Training loss(es)=[0.27732965 0.21708809 0.21450432 0.25824648 0.23188758]]Network training:  20%|█████▍                     | 1/5 [00:35<02:20, 35.17s/epoch(s), Training loss(es)=[0.348622   0.21251217 0.22982493 0.22862129 0.19919299]]Network training:  40%|██████████▊                | 2/5 [00:35<00:52, 17.59s/epoch(s), Training loss(es)=[0.348622   0.21251217 0.22982493 0.22862129 0.19919299]]Network training:  40%|██████████▊                | 2/5 [01:11<01:47, 35.99s/epoch(s), Training loss(es)=[0.2394021  0.21572945 0.19669111 0.20725024 0.2113958 ]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.99s/epoch(s), Training loss(es)=[0.2394021  0.21572945 0.19669111 0.20725024 0.2113958 ]]Network training:  60%|████████████████▏          | 3/5 [01:53<01:15, 37.77s/epoch(s), Training loss(es)=[0.20802203 0.20384379 0.20558468 0.21418232 0.20916663]]Network training:  80%|█████████████████████▌     | 4/5 [01:53<00:28, 28.32s/epoch(s), Training loss(es)=[0.20802203 0.20384379 0.20558468 0.21418232 0.20916663]]Network training:  80%|█████████████████████▌     | 4/5 [02:34<00:38, 38.64s/epoch(s), Training loss(es)=[0.21176843 0.18356636 0.21913789 0.22727185 0.21004443]]Network training: 100%|███████████████████████████| 5/5 [02:34<00:00, 30.91s/epoch(s), Training loss(es)=[0.21176843 0.18356636 0.21913789 0.22727185 0.21004443]]
####################################################################
Starting training iteration 136.
Average action selection time:  0.2889109597206116
Rollout length:  1000
Rewards obtained: [9986.72038529775]
model train lenght 137000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.22175892 0.2218421  0.22817051 0.22164729 0.25868386]]Network training:  20%|█████▍                     | 1/5 [00:17<01:09, 17.31s/epoch(s), Training loss(es)=[0.22175892 0.2218421  0.22817051 0.22164729 0.25868386]]Network training:  20%|█████▍                     | 1/5 [00:33<02:13, 33.49s/epoch(s), Training loss(es)=[0.21181016 0.22239853 0.24944033 0.20836373 0.19023378]]Network training:  40%|██████████▊                | 2/5 [00:33<00:50, 16.75s/epoch(s), Training loss(es)=[0.21181016 0.22239853 0.24944033 0.20836373 0.19023378]]Network training:  40%|██████████▊                | 2/5 [01:13<01:50, 36.98s/epoch(s), Training loss(es)=[0.19874802 0.19968228 0.26096424 0.21483041 0.21578574]]Network training:  60%|████████████████▏          | 3/5 [01:13<00:49, 24.66s/epoch(s), Training loss(es)=[0.19874802 0.19968228 0.26096424 0.21483041 0.21578574]]Network training:  60%|████████████████▏          | 3/5 [01:55<01:17, 38.53s/epoch(s), Training loss(es)=[0.33050346 0.2124082  0.24282645 0.2104223  0.22030486]]Network training:  80%|█████████████████████▌     | 4/5 [01:55<00:28, 28.89s/epoch(s), Training loss(es)=[0.33050346 0.2124082  0.24282645 0.2104223  0.22030486]]Network training:  80%|█████████████████████▌     | 4/5 [02:37<00:39, 39.29s/epoch(s), Training loss(es)=[0.19656785 0.19845738 0.21120635 0.22292031 0.19208695]]Network training: 100%|███████████████████████████| 5/5 [02:37<00:00, 31.44s/epoch(s), Training loss(es)=[0.19656785 0.19845738 0.21120635 0.22292031 0.19208695]]
####################################################################
Starting training iteration 137.
Average action selection time:  0.2837206926345825
Rollout length:  1000
Rewards obtained: [9810.687468923285]
model train lenght 138000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.22343177 0.24041328 0.20829214 0.23682493 0.23795708]]Network training:  20%|█████▍                     | 1/5 [00:17<01:10, 17.65s/epoch(s), Training loss(es)=[0.22343177 0.24041328 0.20829214 0.23682493 0.23795708]]Network training:  20%|█████▍                     | 1/5 [00:39<02:36, 39.15s/epoch(s), Training loss(es)=[0.20449619 0.18300411 0.20969631 0.21139236 0.19544694]]Network training:  40%|██████████▊                | 2/5 [00:39<00:58, 19.57s/epoch(s), Training loss(es)=[0.20449619 0.18300411 0.20969631 0.21139236 0.19544694]]Network training:  40%|██████████▊                | 2/5 [01:21<02:01, 40.52s/epoch(s), Training loss(es)=[0.30084816 0.20236868 0.20443526 0.22334698 0.22773193]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.01s/epoch(s), Training loss(es)=[0.30084816 0.20236868 0.20443526 0.22334698 0.22773193]]Network training:  60%|████████████████▏          | 3/5 [02:02<01:21, 40.99s/epoch(s), Training loss(es)=[0.22489919 0.19911744 0.21058081 0.23369043 0.2223168 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:02<00:30, 30.74s/epoch(s), Training loss(es)=[0.22489919 0.19911744 0.21058081 0.23369043 0.2223168 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:44<00:41, 41.22s/epoch(s), Training loss(es)=[0.23188414 0.20303571 0.19782601 0.23328038 0.19953105]]Network training: 100%|███████████████████████████| 5/5 [02:44<00:00, 32.97s/epoch(s), Training loss(es)=[0.23188414 0.20303571 0.19782601 0.23328038 0.19953105]]
####################################################################
Starting training iteration 138.
Average action selection time:  0.27642007637023924
Rollout length:  1000
Rewards obtained: [8419.697815208277]
model train lenght 139000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:17<?, ?epoch(s)/s, Training loss(es)=[0.24692377 0.21689221 0.20244282 0.19987923 0.22386128]]Network training:  20%|█████▍                     | 1/5 [00:17<01:10, 17.51s/epoch(s), Training loss(es)=[0.24692377 0.21689221 0.20244282 0.19987923 0.22386128]]Network training:  20%|█████▍                     | 1/5 [00:42<02:49, 42.37s/epoch(s), Training loss(es)=[0.22573428 0.19312364 0.19371808 0.2250414  0.20667437]]Network training:  40%|██████████▊                | 2/5 [00:42<01:03, 21.18s/epoch(s), Training loss(es)=[0.22573428 0.19312364 0.19371808 0.2250414  0.20667437]]Network training:  40%|██████████▊                | 2/5 [01:25<02:07, 42.51s/epoch(s), Training loss(es)=[0.22991936 0.24029289 0.20545734 0.22846255 0.22940107]]Network training:  60%|████████████████▏          | 3/5 [01:25<00:56, 28.34s/epoch(s), Training loss(es)=[0.22991936 0.24029289 0.20545734 0.22846255 0.22940107]]Network training:  60%|████████████████▏          | 3/5 [02:08<01:25, 42.74s/epoch(s), Training loss(es)=[0.22075754 0.23294003 0.20046505 0.2177511  0.28078273]]Network training:  80%|█████████████████████▌     | 4/5 [02:08<00:32, 32.05s/epoch(s), Training loss(es)=[0.22075754 0.23294003 0.20046505 0.2177511  0.28078273]]Network training:  80%|█████████████████████▌     | 4/5 [02:51<00:42, 42.80s/epoch(s), Training loss(es)=[0.18681447 0.20241663 0.20489426 0.22267903 0.26249447]]Network training: 100%|███████████████████████████| 5/5 [02:51<00:00, 34.24s/epoch(s), Training loss(es)=[0.18681447 0.20241663 0.20489426 0.22267903 0.26249447]]
####################################################################
Starting training iteration 139.
Average action selection time:  0.28170467233657837
Rollout length:  1000
Rewards obtained: [11937.007179593464]
model train lenght 140000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.1973477  0.24831381 0.19686952 0.20995645 0.21523666]]Network training:  20%|█████▍                     | 1/5 [00:22<01:29, 22.41s/epoch(s), Training loss(es)=[0.1973477  0.24831381 0.19686952 0.20995645 0.21523666]]Network training:  20%|█████▍                     | 1/5 [01:05<04:23, 65.79s/epoch(s), Training loss(es)=[0.19997612 0.20179373 0.19201384 0.22362745 0.23799646]]Network training:  40%|██████████▊                | 2/5 [01:05<01:38, 32.89s/epoch(s), Training loss(es)=[0.19997612 0.20179373 0.19201384 0.22362745 0.23799646]]Network training:  40%|██████████▊                | 2/5 [01:49<02:43, 54.62s/epoch(s), Training loss(es)=[0.22130705 0.21602032 0.26221094 0.21075355 0.20390512]]Network training:  60%|████████████████▏          | 3/5 [01:49<01:12, 36.41s/epoch(s), Training loss(es)=[0.22130705 0.21602032 0.26221094 0.21075355 0.20390512]]Network training:  60%|████████████████▏          | 3/5 [02:32<01:41, 50.94s/epoch(s), Training loss(es)=[0.22013994 0.20339437 0.22150981 0.22302513 0.25220183]]Network training:  80%|█████████████████████▌     | 4/5 [02:32<00:38, 38.21s/epoch(s), Training loss(es)=[0.22013994 0.20339437 0.22150981 0.22302513 0.25220183]]Network training:  80%|█████████████████████▌     | 4/5 [03:16<00:49, 49.01s/epoch(s), Training loss(es)=[0.1987911  0.21671885 0.19944905 0.2265366  0.2148405 ]]Network training: 100%|███████████████████████████| 5/5 [03:16<00:00, 39.21s/epoch(s), Training loss(es)=[0.1987911  0.21671885 0.19944905 0.2265366  0.2148405 ]]
####################################################################
Starting training iteration 140.
Average action selection time:  0.27022812390327455
Rollout length:  1000
Rewards obtained: [9996.705820199446]
model train lenght 141000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:43<?, ?epoch(s)/s, Training loss(es)=[0.22274838 0.22586147 0.252671   0.24435535 0.20483899]]Network training:  20%|█████▍                     | 1/5 [00:43<02:54, 43.61s/epoch(s), Training loss(es)=[0.22274838 0.22586147 0.252671   0.24435535 0.20483899]]Network training:  20%|█████▍                     | 1/5 [01:27<05:48, 87.16s/epoch(s), Training loss(es)=[0.22180852 0.19693159 0.27358013 0.21542768 0.22417957]]Network training:  40%|██████████▊                | 2/5 [01:27<02:10, 43.58s/epoch(s), Training loss(es)=[0.22180852 0.19693159 0.27358013 0.21542768 0.22417957]]Network training:  40%|██████████▊                | 2/5 [02:10<03:16, 65.45s/epoch(s), Training loss(es)=[0.21691236 0.21203609 0.31418252 0.20405622 0.1958035 ]]Network training:  60%|████████████████▏          | 3/5 [02:10<01:27, 43.63s/epoch(s), Training loss(es)=[0.21691236 0.21203609 0.31418252 0.20405622 0.1958035 ]]Network training:  60%|████████████████▏          | 3/5 [02:54<01:56, 58.08s/epoch(s), Training loss(es)=[0.21856436 0.23404282 0.24105029 0.22106712 0.22586267]]Network training:  80%|█████████████████████▌     | 4/5 [02:54<00:43, 43.56s/epoch(s), Training loss(es)=[0.21856436 0.23404282 0.24105029 0.22106712 0.22586267]]Network training:  80%|█████████████████████▌     | 4/5 [03:30<00:52, 52.62s/epoch(s), Training loss(es)=[0.22263771 0.19797443 0.22589722 0.26994964 0.36741108]]Network training: 100%|███████████████████████████| 5/5 [03:30<00:00, 42.09s/epoch(s), Training loss(es)=[0.22263771 0.19797443 0.22589722 0.26994964 0.36741108]]
####################################################################
Starting training iteration 141.
Average action selection time:  0.27427205061912535
Rollout length:  1000
Rewards obtained: [8674.963896042556]
model train lenght 142000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.22460704 0.21977654 0.2091102  0.22684044 0.21113989]]Network training:  20%|█████▍                     | 1/5 [00:44<02:58, 44.63s/epoch(s), Training loss(es)=[0.22460704 0.21977654 0.2091102  0.22684044 0.21113989]]Network training:  20%|█████▍                     | 1/5 [01:29<05:56, 89.23s/epoch(s), Training loss(es)=[0.23523752 0.19955198 0.2754099  0.21490823 0.23891838]]Network training:  40%|██████████▊                | 2/5 [01:29<02:13, 44.62s/epoch(s), Training loss(es)=[0.23523752 0.19955198 0.2754099  0.21490823 0.23891838]]Network training:  40%|██████████▊                | 2/5 [02:13<03:20, 66.67s/epoch(s), Training loss(es)=[0.4229302  0.21909223 0.2244459  0.20044021 0.20823562]]Network training:  60%|████████████████▏          | 3/5 [02:13<01:28, 44.45s/epoch(s), Training loss(es)=[0.4229302  0.21909223 0.2244459  0.20044021 0.20823562]]Network training:  60%|████████████████▏          | 3/5 [02:48<01:52, 56.09s/epoch(s), Training loss(es)=[0.20691997 0.22572683 0.20635195 0.21031389 0.21972686]]Network training:  80%|█████████████████████▌     | 4/5 [02:48<00:42, 42.07s/epoch(s), Training loss(es)=[0.20691997 0.22572683 0.20635195 0.21031389 0.21972686]]Network training:  80%|█████████████████████▌     | 4/5 [03:11<00:47, 47.77s/epoch(s), Training loss(es)=[0.2145024  0.22899033 0.20007809 0.19313909 0.21275635]]Network training: 100%|███████████████████████████| 5/5 [03:11<00:00, 38.22s/epoch(s), Training loss(es)=[0.2145024  0.22899033 0.20007809 0.19313909 0.21275635]]
####################################################################
Starting training iteration 142.
Average action selection time:  0.3028160135746002
Rollout length:  1000
Rewards obtained: [5647.057603077747]
model train lenght 143000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.21104045 0.20179059 0.20298992 0.22289209 0.21198235]]Network training:  20%|█████▍                     | 1/5 [00:44<02:58, 44.57s/epoch(s), Training loss(es)=[0.21104045 0.20179059 0.20298992 0.22289209 0.21198235]]Network training:  20%|█████▍                     | 1/5 [01:28<05:55, 88.96s/epoch(s), Training loss(es)=[0.21027361 0.26530063 0.21477656 0.200842   0.25512093]]Network training:  40%|██████████▊                | 2/5 [01:28<02:13, 44.48s/epoch(s), Training loss(es)=[0.21027361 0.26530063 0.21477656 0.200842   0.25512093]]Network training:  40%|██████████▊                | 2/5 [02:06<03:09, 63.16s/epoch(s), Training loss(es)=[0.21697515 0.23663728 0.18350288 0.21719651 0.2128499 ]]Network training:  60%|████████████████▏          | 3/5 [02:06<01:24, 42.10s/epoch(s), Training loss(es)=[0.21697515 0.23663728 0.18350288 0.21719651 0.2128499 ]]Network training:  60%|████████████████▏          | 3/5 [02:29<01:39, 49.82s/epoch(s), Training loss(es)=[0.2205279  0.23917966 0.22093663 0.2218104  0.22227144]]Network training:  80%|█████████████████████▌     | 4/5 [02:29<00:37, 37.37s/epoch(s), Training loss(es)=[0.2205279  0.23917966 0.22093663 0.2218104  0.22227144]]Network training:  80%|█████████████████████▌     | 4/5 [02:51<00:42, 42.92s/epoch(s), Training loss(es)=[0.20286076 0.22647017 0.19176595 0.19793299 0.22831121]]Network training: 100%|███████████████████████████| 5/5 [02:51<00:00, 34.34s/epoch(s), Training loss(es)=[0.20286076 0.22647017 0.19176595 0.19793299 0.22831121]]
####################################################################
Starting training iteration 143.
Average action selection time:  0.317267459154129
Rollout length:  1000
Rewards obtained: [6092.268974693189]
model train lenght 144000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:45<?, ?epoch(s)/s, Training loss(es)=[0.24004841 0.20313868 0.24796553 0.25188375 0.21845855]]Network training:  20%|█████▍                     | 1/5 [00:45<03:00, 45.10s/epoch(s), Training loss(es)=[0.24004841 0.20313868 0.24796553 0.25188375 0.21845855]]Network training:  20%|█████▍                     | 1/5 [01:29<05:59, 89.95s/epoch(s), Training loss(es)=[0.21892881 0.20991795 0.2541728  0.2235581  0.23305066]]Network training:  40%|██████████▊                | 2/5 [01:29<02:14, 44.97s/epoch(s), Training loss(es)=[0.21892881 0.20991795 0.2541728  0.2235581  0.23305066]]Network training:  40%|██████████▊                | 2/5 [01:54<02:51, 57.24s/epoch(s), Training loss(es)=[0.22377232 0.2123989  0.22920269 0.2717173  0.26560196]]Network training:  60%|████████████████▏          | 3/5 [01:54<01:16, 38.16s/epoch(s), Training loss(es)=[0.22377232 0.2123989  0.22920269 0.2717173  0.26560196]]Network training:  60%|████████████████▏          | 3/5 [02:18<01:32, 46.08s/epoch(s), Training loss(es)=[0.22392705 0.21690655 0.2096581  0.24248266 0.21883799]]Network training:  80%|█████████████████████▌     | 4/5 [02:18<00:34, 34.56s/epoch(s), Training loss(es)=[0.22392705 0.21690655 0.2096581  0.24248266 0.21883799]]Network training:  80%|█████████████████████▌     | 4/5 [02:41<00:40, 40.47s/epoch(s), Training loss(es)=[0.24619094 0.22169809 0.20210634 0.20220883 0.20297441]]Network training: 100%|███████████████████████████| 5/5 [02:41<00:00, 32.38s/epoch(s), Training loss(es)=[0.24619094 0.22169809 0.20210634 0.20220883 0.20297441]]
####################################################################
Starting training iteration 144.
Average action selection time:  0.3349982373714447
Rollout length:  1000
Rewards obtained: [6550.329099229991]
model train lenght 145000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.24525467 0.2271948  0.2003378  0.24151026 0.21950878]]Network training:  20%|█████▍                     | 1/5 [00:44<02:56, 44.10s/epoch(s), Training loss(es)=[0.24525467 0.2271948  0.2003378  0.24151026 0.21950878]]Network training:  20%|█████▍                     | 1/5 [01:17<05:08, 77.02s/epoch(s), Training loss(es)=[0.2244808  0.21513714 0.24280117 0.22325273 0.22451854]]Network training:  40%|██████████▊                | 2/5 [01:17<01:55, 38.51s/epoch(s), Training loss(es)=[0.2244808  0.21513714 0.24280117 0.22325273 0.22451854]]Network training:  40%|██████████▊                | 2/5 [01:35<02:23, 47.71s/epoch(s), Training loss(es)=[0.2152095  0.19784054 0.22497432 0.2486254  0.2522894 ]]Network training:  60%|████████████████▏          | 3/5 [01:35<01:03, 31.81s/epoch(s), Training loss(es)=[0.2152095  0.19784054 0.22497432 0.2486254  0.2522894 ]]Network training:  60%|████████████████▏          | 3/5 [01:53<01:15, 37.98s/epoch(s), Training loss(es)=[0.1923071  0.21773738 0.21746448 0.21786024 0.22776885]]Network training:  80%|█████████████████████▌     | 4/5 [01:53<00:28, 28.49s/epoch(s), Training loss(es)=[0.1923071  0.21773738 0.21746448 0.21786024 0.22776885]]Network training:  80%|█████████████████████▌     | 4/5 [02:13<00:33, 33.35s/epoch(s), Training loss(es)=[0.21050303 0.22233896 0.21142636 0.2604589  0.22306685]]Network training: 100%|███████████████████████████| 5/5 [02:13<00:00, 26.68s/epoch(s), Training loss(es)=[0.21050303 0.22233896 0.21142636 0.2604589  0.22306685]]
####################################################################
Starting training iteration 145.
Average action selection time:  0.33303224921226504
Rollout length:  1000
Rewards obtained: [12744.891557003402]
model train lenght 146000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.2518966  0.2246752  0.2339884  0.24047488 0.2342961 ]]Network training:  20%|█████▍                     | 1/5 [00:44<02:57, 44.36s/epoch(s), Training loss(es)=[0.2518966  0.2246752  0.2339884  0.24047488 0.2342961 ]]Network training:  20%|█████▍                     | 1/5 [01:12<04:48, 72.24s/epoch(s), Training loss(es)=[0.19979326 0.23083393 0.22161005 0.1973832  0.24580972]]Network training:  40%|██████████▊                | 2/5 [01:12<01:48, 36.12s/epoch(s), Training loss(es)=[0.19979326 0.23083393 0.22161005 0.1973832  0.24580972]]Network training:  40%|██████████▊                | 2/5 [01:30<02:16, 45.48s/epoch(s), Training loss(es)=[0.24983467 0.2190114  0.23834607 0.23534583 0.23185994]]Network training:  60%|████████████████▏          | 3/5 [01:30<01:00, 30.32s/epoch(s), Training loss(es)=[0.24983467 0.2190114  0.23834607 0.23534583 0.23185994]]Network training:  60%|████████████████▏          | 3/5 [01:49<01:13, 36.50s/epoch(s), Training loss(es)=[0.21178584 0.22662154 0.21677522 0.21012916 0.21768142]]Network training:  80%|█████████████████████▌     | 4/5 [01:49<00:27, 27.38s/epoch(s), Training loss(es)=[0.21178584 0.22662154 0.21677522 0.21012916 0.21768142]]Network training:  80%|█████████████████████▌     | 4/5 [02:07<00:31, 31.94s/epoch(s), Training loss(es)=[0.24035718 0.21291316 0.21834433 0.2137549  0.18722886]]Network training: 100%|███████████████████████████| 5/5 [02:07<00:00, 25.55s/epoch(s), Training loss(es)=[0.24035718 0.21291316 0.21834433 0.2137549  0.18722886]]
####################################################################
Starting training iteration 146.
Average action selection time:  0.3342963252067566
Rollout length:  1000
Rewards obtained: [7757.621017455288]
model train lenght 147000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.24292766 0.22722548 0.22095051 0.2399709  0.2743939 ]]Network training:  20%|█████▍                     | 1/5 [00:44<02:58, 44.64s/epoch(s), Training loss(es)=[0.24292766 0.22722548 0.22095051 0.2399709  0.2743939 ]]Network training:  20%|█████▍                     | 1/5 [01:11<04:45, 71.33s/epoch(s), Training loss(es)=[0.22155765 0.18827009 0.21305954 0.2217679  0.2528843 ]]Network training:  40%|██████████▊                | 2/5 [01:11<01:46, 35.66s/epoch(s), Training loss(es)=[0.22155765 0.18827009 0.21305954 0.2217679  0.2528843 ]]Network training:  40%|██████████▊                | 2/5 [01:30<02:15, 45.16s/epoch(s), Training loss(es)=[0.24559537 0.21479309 0.26244238 0.21923128 0.21539009]]Network training:  60%|████████████████▏          | 3/5 [01:30<01:00, 30.11s/epoch(s), Training loss(es)=[0.24559537 0.21479309 0.26244238 0.21923128 0.21539009]]Network training:  60%|████████████████▏          | 3/5 [01:50<01:13, 36.69s/epoch(s), Training loss(es)=[0.21595527 0.1982701  0.20939016 0.23048577 0.20718677]]Network training:  80%|█████████████████████▌     | 4/5 [01:50<00:27, 27.52s/epoch(s), Training loss(es)=[0.21595527 0.1982701  0.20939016 0.23048577 0.20718677]]Network training:  80%|█████████████████████▌     | 4/5 [02:09<00:32, 32.32s/epoch(s), Training loss(es)=[0.21088833 0.23132129 0.198419   0.26056483 0.27774218]]Network training: 100%|███████████████████████████| 5/5 [02:09<00:00, 25.86s/epoch(s), Training loss(es)=[0.21088833 0.23132129 0.198419   0.26056483 0.27774218]]
####################################################################
Starting training iteration 147.
Average action selection time:  0.34589015030860903
Rollout length:  1000
Rewards obtained: [7113.324996997987]
model train lenght 148000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:43<?, ?epoch(s)/s, Training loss(es)=[0.24994993 0.23568168 0.20062435 0.27316898 0.25284937]]Network training:  20%|█████▍                     | 1/5 [00:43<02:55, 43.91s/epoch(s), Training loss(es)=[0.24994993 0.23568168 0.20062435 0.27316898 0.25284937]]Network training:  20%|█████▍                     | 1/5 [01:02<04:09, 62.44s/epoch(s), Training loss(es)=[0.23715779 0.2159155  0.2120621  0.23387246 0.23769078]]Network training:  40%|██████████▊                | 2/5 [01:02<01:33, 31.22s/epoch(s), Training loss(es)=[0.23715779 0.2159155  0.2120621  0.23387246 0.23769078]]Network training:  40%|██████████▊                | 2/5 [01:22<02:03, 41.08s/epoch(s), Training loss(es)=[0.21693721 0.2693434  0.26035982 0.21734129 0.2079797 ]]Network training:  60%|████████████████▏          | 3/5 [01:22<00:54, 27.39s/epoch(s), Training loss(es)=[0.21693721 0.2693434  0.26035982 0.21734129 0.2079797 ]]Network training:  60%|████████████████▏          | 3/5 [01:40<01:06, 33.49s/epoch(s), Training loss(es)=[0.27996615 0.23722844 0.23485582 0.20233993 0.22291191]]Network training:  80%|█████████████████████▌     | 4/5 [01:40<00:25, 25.12s/epoch(s), Training loss(es)=[0.27996615 0.23722844 0.23485582 0.20233993 0.22291191]]Network training:  80%|█████████████████████▌     | 4/5 [01:58<00:29, 29.58s/epoch(s), Training loss(es)=[0.22579348 0.23991284 0.19531538 0.38139567 0.21328369]]Network training: 100%|███████████████████████████| 5/5 [01:58<00:00, 23.66s/epoch(s), Training loss(es)=[0.22579348 0.23991284 0.19531538 0.38139567 0.21328369]]
####################################################################
Starting training iteration 148.
Average action selection time:  0.34516693258285525
Rollout length:  1000
Rewards obtained: [6051.520541496645]
model train lenght 149000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:44<?, ?epoch(s)/s, Training loss(es)=[0.230533   0.22207408 0.21355712 0.310398   0.22764236]]Network training:  20%|█████▍                     | 1/5 [00:44<02:57, 44.26s/epoch(s), Training loss(es)=[0.230533   0.22207408 0.21355712 0.310398   0.22764236]]Network training:  20%|█████▍                     | 1/5 [01:02<04:10, 62.73s/epoch(s), Training loss(es)=[0.23051143 0.22107017 0.2142854  0.22814101 0.22423819]]Network training:  40%|██████████▊                | 2/5 [01:02<01:34, 31.37s/epoch(s), Training loss(es)=[0.23051143 0.22107017 0.2142854  0.22814101 0.22423819]]Network training:  40%|██████████▊                | 2/5 [01:21<02:01, 40.63s/epoch(s), Training loss(es)=[0.28317374 0.24357812 0.22948852 0.21040279 0.21664214]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.09s/epoch(s), Training loss(es)=[0.28317374 0.24357812 0.22948852 0.21040279 0.21664214]]Network training:  60%|████████████████▏          | 3/5 [01:39<01:06, 33.05s/epoch(s), Training loss(es)=[0.25077724 0.22609973 0.24992037 0.23320466 0.22272934]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.79s/epoch(s), Training loss(es)=[0.25077724 0.22609973 0.24992037 0.23320466 0.22272934]]Network training:  80%|█████████████████████▌     | 4/5 [01:58<00:29, 29.55s/epoch(s), Training loss(es)=[0.23387629 0.55431056 0.30606958 0.23161756 0.25817364]]Network training: 100%|███████████████████████████| 5/5 [01:58<00:00, 23.64s/epoch(s), Training loss(es)=[0.23387629 0.55431056 0.30606958 0.23161756 0.25817364]]
####################################################################
Starting training iteration 149.
Average action selection time:  0.34683845019340515
Rollout length:  1000
Rewards obtained: [8243.445428586738]
model train lenght 150000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:43<?, ?epoch(s)/s, Training loss(es)=[0.21000059 0.19649407 0.24734165 0.22902915 0.20159364]]Network training:  20%|█████▍                     | 1/5 [00:43<02:53, 43.48s/epoch(s), Training loss(es)=[0.21000059 0.19649407 0.24734165 0.22902915 0.20159364]]Network training:  20%|█████▍                     | 1/5 [01:02<04:11, 62.89s/epoch(s), Training loss(es)=[0.25875443 0.20026448 0.23878647 0.2503006  0.23317261]]Network training:  40%|██████████▊                | 2/5 [01:02<01:34, 31.45s/epoch(s), Training loss(es)=[0.25875443 0.20026448 0.23878647 0.2503006  0.23317261]]Network training:  40%|██████████▊                | 2/5 [01:21<02:02, 40.94s/epoch(s), Training loss(es)=[0.20916358 0.21145296 0.2598887  0.2543142  0.21309671]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.30s/epoch(s), Training loss(es)=[0.20916358 0.21145296 0.2598887  0.2543142  0.21309671]]Network training:  60%|████████████████▏          | 3/5 [01:40<01:07, 33.66s/epoch(s), Training loss(es)=[0.19872579 0.23544343 0.19180383 0.25306368 0.20210567]]Network training:  80%|█████████████████████▌     | 4/5 [01:40<00:25, 25.25s/epoch(s), Training loss(es)=[0.19872579 0.23544343 0.19180383 0.25306368 0.20210567]]Network training:  80%|█████████████████████▌     | 4/5 [02:00<00:30, 30.09s/epoch(s), Training loss(es)=[0.21352434 0.2088906  0.22737718 0.23492038 0.20200774]]Network training: 100%|███████████████████████████| 5/5 [02:00<00:00, 24.07s/epoch(s), Training loss(es)=[0.21352434 0.2088906  0.22737718 0.23492038 0.20200774]]
####################################################################
Starting training iteration 150.
Average action selection time:  0.34979060196876527
Rollout length:  1000
Rewards obtained: [11141.880094844144]
model train lenght 151000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:41<?, ?epoch(s)/s, Training loss(es)=[0.2553286  0.22493234 0.22654456 0.23141131 0.24434374]]Network training:  20%|█████▍                     | 1/5 [00:41<02:44, 41.23s/epoch(s), Training loss(es)=[0.2553286  0.22493234 0.22654456 0.23141131 0.24434374]]Network training:  20%|█████▍                     | 1/5 [01:00<04:01, 60.49s/epoch(s), Training loss(es)=[0.28253114 0.22356467 0.21603721 0.21398818 0.20771629]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.24s/epoch(s), Training loss(es)=[0.28253114 0.22356467 0.21603721 0.21398818 0.20771629]]Network training:  40%|██████████▊                | 2/5 [01:20<02:00, 40.20s/epoch(s), Training loss(es)=[0.23050585 0.22504824 0.23795836 0.24171023 0.21810168]]Network training:  60%|████████████████▏          | 3/5 [01:20<00:53, 26.80s/epoch(s), Training loss(es)=[0.23050585 0.22504824 0.23795836 0.24171023 0.21810168]]Network training:  60%|████████████████▏          | 3/5 [01:39<01:06, 33.30s/epoch(s), Training loss(es)=[0.21147034 0.19604062 0.21920513 0.2794899  0.21697749]]Network training:  80%|█████████████████████▌     | 4/5 [01:39<00:24, 24.98s/epoch(s), Training loss(es)=[0.21147034 0.19604062 0.21920513 0.2794899  0.21697749]]Network training:  80%|█████████████████████▌     | 4/5 [01:59<00:29, 29.82s/epoch(s), Training loss(es)=[0.25418338 0.20952412 0.22282468 0.23932263 0.2046748 ]]Network training: 100%|███████████████████████████| 5/5 [01:59<00:00, 23.86s/epoch(s), Training loss(es)=[0.25418338 0.20952412 0.22282468 0.23932263 0.2046748 ]]
####################################################################
Starting training iteration 151.
Average action selection time:  0.35420877718925475
Rollout length:  1000
Rewards obtained: [9482.299540496342]
model train lenght 152000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:38<?, ?epoch(s)/s, Training loss(es)=[0.23013699 0.22757979 0.21077752 0.2853918  0.23514089]]Network training:  20%|█████▍                     | 1/5 [00:38<02:34, 38.50s/epoch(s), Training loss(es)=[0.23013699 0.22757979 0.21077752 0.2853918  0.23514089]]Network training:  20%|█████▍                     | 1/5 [00:59<03:57, 59.27s/epoch(s), Training loss(es)=[0.21906574 0.22970659 0.24074805 0.22845191 0.22121291]]Network training:  40%|██████████▊                | 2/5 [00:59<01:28, 29.64s/epoch(s), Training loss(es)=[0.21906574 0.22970659 0.24074805 0.22845191 0.22121291]]Network training:  40%|██████████▊                | 2/5 [01:18<01:58, 39.40s/epoch(s), Training loss(es)=[0.38215387 0.21823628 0.22311944 0.2551626  0.21628477]]Network training:  60%|████████████████▏          | 3/5 [01:18<00:52, 26.27s/epoch(s), Training loss(es)=[0.38215387 0.21823628 0.22311944 0.2551626  0.21628477]]Network training:  60%|████████████████▏          | 3/5 [01:38<01:05, 32.71s/epoch(s), Training loss(es)=[0.22265586 0.20659296 0.20467812 0.23309632 0.24572039]]Network training:  80%|█████████████████████▌     | 4/5 [01:38<00:24, 24.53s/epoch(s), Training loss(es)=[0.22265586 0.20659296 0.20467812 0.23309632 0.24572039]]Network training:  80%|█████████████████████▌     | 4/5 [01:56<00:29, 29.21s/epoch(s), Training loss(es)=[0.23797944 0.2468365  0.24074936 0.2746039  0.37086833]]Network training: 100%|███████████████████████████| 5/5 [01:56<00:00, 23.37s/epoch(s), Training loss(es)=[0.23797944 0.2468365  0.24074936 0.2746039  0.37086833]]
####################################################################
Starting training iteration 152.
Average action selection time:  0.36151149940490723
Rollout length:  1000
Rewards obtained: [9857.330103326953]
model train lenght 153000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:33<?, ?epoch(s)/s, Training loss(es)=[0.38180587 0.22124583 0.22217217 0.23344257 0.2255441 ]]Network training:  20%|█████▍                     | 1/5 [00:33<02:13, 33.45s/epoch(s), Training loss(es)=[0.38180587 0.22124583 0.22217217 0.23344257 0.2255441 ]]Network training:  20%|█████▍                     | 1/5 [00:53<03:35, 53.82s/epoch(s), Training loss(es)=[0.24232945 0.22253518 0.22935176 0.25479734 0.3423242 ]]Network training:  40%|██████████▊                | 2/5 [00:53<01:20, 26.91s/epoch(s), Training loss(es)=[0.24232945 0.22253518 0.22935176 0.25479734 0.3423242 ]]Network training:  40%|██████████▊                | 2/5 [01:13<01:50, 36.94s/epoch(s), Training loss(es)=[0.2424973  0.22569887 0.22806697 0.21074226 0.22770488]]Network training:  60%|████████████████▏          | 3/5 [01:13<00:49, 24.63s/epoch(s), Training loss(es)=[0.2424973  0.22569887 0.22806697 0.21074226 0.22770488]]Network training:  60%|████████████████▏          | 3/5 [01:32<01:01, 30.93s/epoch(s), Training loss(es)=[0.2333148  0.24094087 0.23640466 0.27378243 0.23896177]]Network training:  80%|█████████████████████▌     | 4/5 [01:32<00:23, 23.19s/epoch(s), Training loss(es)=[0.2333148  0.24094087 0.23640466 0.27378243 0.23896177]]Network training:  80%|█████████████████████▌     | 4/5 [01:50<00:27, 27.62s/epoch(s), Training loss(es)=[0.21048483 0.21802147 0.20189163 0.2643647  0.5271173 ]]Network training: 100%|███████████████████████████| 5/5 [01:50<00:00, 22.09s/epoch(s), Training loss(es)=[0.21048483 0.21802147 0.20189163 0.2643647  0.5271173 ]]
####################################################################
Starting training iteration 153.
Average action selection time:  0.36977598547935486
Rollout length:  1000
Rewards obtained: [6422.336362671665]
model train lenght 154000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:26<?, ?epoch(s)/s, Training loss(es)=[0.26680532 0.21044797 0.22509336 0.25798094 0.29183847]]Network training:  20%|█████▍                     | 1/5 [00:26<01:46, 26.51s/epoch(s), Training loss(es)=[0.26680532 0.21044797 0.22509336 0.25798094 0.29183847]]Network training:  20%|█████▍                     | 1/5 [00:46<03:05, 46.32s/epoch(s), Training loss(es)=[0.25486207 0.25223035 0.257546   0.25046787 0.20985425]]Network training:  40%|██████████▊                | 2/5 [00:46<01:09, 23.16s/epoch(s), Training loss(es)=[0.25486207 0.25223035 0.257546   0.25046787 0.20985425]]Network training:  40%|██████████▊                | 2/5 [01:05<01:38, 32.97s/epoch(s), Training loss(es)=[0.20603086 0.20078051 0.2567566  0.24707483 0.21799219]]Network training:  60%|████████████████▏          | 3/5 [01:05<00:43, 21.98s/epoch(s), Training loss(es)=[0.20603086 0.20078051 0.2567566  0.24707483 0.21799219]]Network training:  60%|████████████████▏          | 3/5 [01:25<00:57, 28.64s/epoch(s), Training loss(es)=[0.2616155  0.22206353 0.21853718 0.2422729  0.25173306]]Network training:  80%|█████████████████████▌     | 4/5 [01:25<00:21, 21.48s/epoch(s), Training loss(es)=[0.2616155  0.22206353 0.21853718 0.2422729  0.25173306]]Network training:  80%|█████████████████████▌     | 4/5 [01:45<00:26, 26.47s/epoch(s), Training loss(es)=[0.24137038 0.23390478 0.34963143 0.24411638 0.378534  ]]Network training: 100%|███████████████████████████| 5/5 [01:45<00:00, 21.18s/epoch(s), Training loss(es)=[0.24137038 0.23390478 0.34963143 0.24411638 0.378534  ]]
####################################################################
Starting training iteration 154.
Average action selection time:  0.3735154435634613
Rollout length:  1000
Rewards obtained: [12072.503301518711]
model train lenght 155000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.26800737 0.21296929 0.26602304 0.23169145 0.23763767]]Network training:  20%|█████▍                     | 1/5 [00:24<01:39, 24.80s/epoch(s), Training loss(es)=[0.26800737 0.21296929 0.26602304 0.23169145 0.23763767]]Network training:  20%|█████▍                     | 1/5 [00:44<02:56, 44.16s/epoch(s), Training loss(es)=[0.23488687 0.19506036 0.22847325 0.23627232 0.35471153]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.08s/epoch(s), Training loss(es)=[0.23488687 0.19506036 0.22847325 0.23627232 0.35471153]]Network training:  40%|██████████▊                | 2/5 [01:03<01:35, 31.83s/epoch(s), Training loss(es)=[0.22891618 0.2421742  0.2237853  0.36378378 0.24928916]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.22s/epoch(s), Training loss(es)=[0.22891618 0.2421742  0.2237853  0.36378378 0.24928916]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.99s/epoch(s), Training loss(es)=[0.24027114 0.21873386 0.2664815  0.26982114 0.24765947]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.99s/epoch(s), Training loss(es)=[0.24027114 0.21873386 0.2664815  0.26982114 0.24765947]]Network training:  80%|█████████████████████▌     | 4/5 [01:44<00:26, 26.22s/epoch(s), Training loss(es)=[0.2644176  0.21989521 0.21694747 0.23136635 0.24222109]]Network training: 100%|███████████████████████████| 5/5 [01:44<00:00, 20.98s/epoch(s), Training loss(es)=[0.2644176  0.21989521 0.21694747 0.23136635 0.24222109]]
####################################################################
Starting training iteration 155.
Average action selection time:  0.37683503818511965
Rollout length:  1000
Rewards obtained: [8568.664551446624]
model train lenght 156000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.24817729 0.20545493 0.26111832 0.23930322 0.22609207]]Network training:  20%|█████▍                     | 1/5 [00:21<01:26, 21.68s/epoch(s), Training loss(es)=[0.24817729 0.20545493 0.26111832 0.23930322 0.22609207]]Network training:  20%|█████▍                     | 1/5 [00:41<02:45, 41.49s/epoch(s), Training loss(es)=[0.2562889  0.2446377  0.23251887 0.28336123 0.3089599 ]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.74s/epoch(s), Training loss(es)=[0.2562889  0.2446377  0.23251887 0.28336123 0.3089599 ]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.13s/epoch(s), Training loss(es)=[0.2568992  0.3643287  0.21866955 0.2407926  0.23300566]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.09s/epoch(s), Training loss(es)=[0.2568992  0.3643287  0.21866955 0.2407926  0.23300566]]Network training:  60%|████████████████▏          | 3/5 [01:20<00:53, 26.97s/epoch(s), Training loss(es)=[0.24524368 0.23733139 0.21836917 0.4347541  0.3101995 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:20<00:20, 20.22s/epoch(s), Training loss(es)=[0.24524368 0.23733139 0.21836917 0.4347541  0.3101995 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:41<00:25, 25.41s/epoch(s), Training loss(es)=[0.2567245  0.21668467 0.2611007  0.22707671 0.23713979]]Network training: 100%|███████████████████████████| 5/5 [01:41<00:00, 20.33s/epoch(s), Training loss(es)=[0.2567245  0.21668467 0.2611007  0.22707671 0.23713979]]
####################################################################
Starting training iteration 156.
Average action selection time:  0.3780154538154602
Rollout length:  1000
Rewards obtained: [9999.212682671177]
model train lenght 157000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.31614423 0.24509443 0.26494396 0.27959633 0.44744653]]Network training:  20%|█████▍                     | 1/5 [00:20<01:23, 20.81s/epoch(s), Training loss(es)=[0.31614423 0.24509443 0.26494396 0.27959633 0.44744653]]Network training:  20%|█████▍                     | 1/5 [00:40<02:40, 40.18s/epoch(s), Training loss(es)=[0.21287778 0.23393004 0.22381116 0.4285417  0.24061821]]Network training:  40%|██████████▊                | 2/5 [00:40<01:00, 20.09s/epoch(s), Training loss(es)=[0.21287778 0.23393004 0.22381116 0.4285417  0.24061821]]Network training:  40%|██████████▊                | 2/5 [00:58<01:27, 29.31s/epoch(s), Training loss(es)=[0.3112377  0.2519876  0.21364304 0.23048064 0.24238208]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:39, 19.54s/epoch(s), Training loss(es)=[0.3112377  0.2519876  0.21364304 0.23048064 0.24238208]]Network training:  60%|████████████████▏          | 3/5 [01:16<00:51, 25.52s/epoch(s), Training loss(es)=[0.31072062 0.29093534 0.21627295 0.23811309 0.25122485]]Network training:  80%|█████████████████████▌     | 4/5 [01:16<00:19, 19.14s/epoch(s), Training loss(es)=[0.31072062 0.29093534 0.21627295 0.23811309 0.25122485]]Network training:  80%|█████████████████████▌     | 4/5 [01:34<00:23, 23.63s/epoch(s), Training loss(es)=[0.25299504 0.23652439 0.2479478  0.2276988  0.21452363]]Network training: 100%|███████████████████████████| 5/5 [01:34<00:00, 18.90s/epoch(s), Training loss(es)=[0.25299504 0.23652439 0.2479478  0.2276988  0.21452363]]
####################################################################
Starting training iteration 157.
Average action selection time:  0.38017809891700743
Rollout length:  1000
Rewards obtained: [11095.744763415281]
model train lenght 158000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.22628012 0.24422541 0.21216647 0.22249761 0.22308223]]Network training:  20%|█████▍                     | 1/5 [00:20<01:21, 20.48s/epoch(s), Training loss(es)=[0.22628012 0.24422541 0.21216647 0.22249761 0.22308223]]Network training:  20%|█████▍                     | 1/5 [00:41<02:45, 41.25s/epoch(s), Training loss(es)=[0.20767668 0.29726925 0.41010937 0.34081388 0.22743951]]Network training:  40%|██████████▊                | 2/5 [00:41<01:01, 20.63s/epoch(s), Training loss(es)=[0.20767668 0.29726925 0.41010937 0.34081388 0.22743951]]Network training:  40%|██████████▊                | 2/5 [01:01<01:32, 30.76s/epoch(s), Training loss(es)=[0.22800471 0.21420403 0.25655434 0.23524383 0.29934362]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:41, 20.51s/epoch(s), Training loss(es)=[0.22800471 0.21420403 0.25655434 0.23524383 0.29934362]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.01s/epoch(s), Training loss(es)=[0.21044509 0.24134512 0.23531455 0.32608688 0.22950427]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.26s/epoch(s), Training loss(es)=[0.21044509 0.24134512 0.23531455 0.32608688 0.22950427]]Network training:  80%|█████████████████████▌     | 4/5 [01:41<00:25, 25.31s/epoch(s), Training loss(es)=[0.3070813  0.23435359 0.27380058 0.3702812  0.25583848]]Network training: 100%|███████████████████████████| 5/5 [01:41<00:00, 20.25s/epoch(s), Training loss(es)=[0.3070813  0.23435359 0.27380058 0.3702812  0.25583848]]
####################################################################
Starting training iteration 158.
Average action selection time:  0.38000355768203736
Rollout length:  1000
Rewards obtained: [9245.347995652914]
model train lenght 159000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.250911   0.2396919  0.2265676  0.24965596 0.26615733]]Network training:  20%|█████▍                     | 1/5 [00:20<01:21, 20.48s/epoch(s), Training loss(es)=[0.250911   0.2396919  0.2265676  0.24965596 0.26615733]]Network training:  20%|█████▍                     | 1/5 [00:40<02:40, 40.18s/epoch(s), Training loss(es)=[0.22183865 0.2350683  0.21012174 0.24662012 0.22226594]]Network training:  40%|██████████▊                | 2/5 [00:40<01:00, 20.09s/epoch(s), Training loss(es)=[0.22183865 0.2350683  0.21012174 0.24662012 0.22226594]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.18s/epoch(s), Training loss(es)=[0.23520532 0.26931524 0.23279811 0.34895656 0.26874948]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.12s/epoch(s), Training loss(es)=[0.23520532 0.26931524 0.23279811 0.34895656 0.26874948]]Network training:  60%|████████████████▏          | 3/5 [01:20<00:53, 26.99s/epoch(s), Training loss(es)=[0.26999435 0.23331948 0.22925718 0.23090743 0.25203422]]Network training:  80%|█████████████████████▌     | 4/5 [01:20<00:20, 20.24s/epoch(s), Training loss(es)=[0.26999435 0.23331948 0.22925718 0.23090743 0.25203422]]Network training:  80%|█████████████████████▌     | 4/5 [01:44<00:26, 26.22s/epoch(s), Training loss(es)=[0.26375467 0.25488222 0.24785043 0.27971718 0.2457874 ]]Network training: 100%|███████████████████████████| 5/5 [01:44<00:00, 20.98s/epoch(s), Training loss(es)=[0.26375467 0.25488222 0.24785043 0.27971718 0.2457874 ]]
####################################################################
Starting training iteration 159.
Average action selection time:  0.3750128800868988
Rollout length:  1000
Rewards obtained: [10137.38091779577]
model train lenght 160000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.24889868 0.27199885 0.22220938 0.25391394 0.33369446]]Network training:  20%|█████▍                     | 1/5 [00:20<01:21, 20.32s/epoch(s), Training loss(es)=[0.24889868 0.27199885 0.22220938 0.25391394 0.33369446]]Network training:  20%|█████▍                     | 1/5 [00:39<02:39, 39.83s/epoch(s), Training loss(es)=[0.2345503  0.28587356 0.3276365  0.24695322 0.22766097]]Network training:  40%|██████████▊                | 2/5 [00:39<00:59, 19.91s/epoch(s), Training loss(es)=[0.2345503  0.28587356 0.3276365  0.24695322 0.22766097]]Network training:  40%|██████████▊                | 2/5 [00:58<01:27, 29.13s/epoch(s), Training loss(es)=[0.43505865 0.2260617  0.22463973 0.29151452 0.2235732 ]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.42s/epoch(s), Training loss(es)=[0.43505865 0.2260617  0.22463973 0.29151452 0.2235732 ]]Network training:  60%|████████████████▏          | 3/5 [01:18<00:52, 26.28s/epoch(s), Training loss(es)=[0.24378565 0.25243932 0.20236138 0.25749776 0.252368  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:18<00:19, 19.71s/epoch(s), Training loss(es)=[0.24378565 0.25243932 0.20236138 0.25749776 0.252368  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:47<00:26, 26.87s/epoch(s), Training loss(es)=[0.23540723 0.24424571 0.24735884 0.26186055 0.22686622]]Network training: 100%|███████████████████████████| 5/5 [01:47<00:00, 21.49s/epoch(s), Training loss(es)=[0.23540723 0.24424571 0.24735884 0.26186055 0.22686622]]
####################################################################
Starting training iteration 160.
Average action selection time:  0.3694494781494141
Rollout length:  1000
Rewards obtained: [6611.117803848752]
model train lenght 161000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:19<?, ?epoch(s)/s, Training loss(es)=[0.23241274 0.26461568 0.21844827 0.27583867 0.27467933]]Network training:  20%|█████▍                     | 1/5 [00:19<01:17, 19.35s/epoch(s), Training loss(es)=[0.23241274 0.26461568 0.21844827 0.27583867 0.27467933]]Network training:  20%|█████▍                     | 1/5 [00:40<02:40, 40.12s/epoch(s), Training loss(es)=[0.22141892 0.23948915 0.23468143 0.2608264  0.26129055]]Network training:  40%|██████████▊                | 2/5 [00:40<01:00, 20.06s/epoch(s), Training loss(es)=[0.22141892 0.23948915 0.23468143 0.2608264  0.26129055]]Network training:  40%|██████████▊                | 2/5 [01:00<01:30, 30.18s/epoch(s), Training loss(es)=[0.235719   0.22596118 0.28231844 0.2686578  0.22562432]]Network training:  60%|████████████████▏          | 3/5 [01:00<00:40, 20.12s/epoch(s), Training loss(es)=[0.235719   0.22596118 0.28231844 0.2686578  0.22562432]]Network training:  60%|████████████████▏          | 3/5 [01:19<00:53, 26.53s/epoch(s), Training loss(es)=[0.27194518 0.21197411 0.24124031 0.2531617  0.28642645]]Network training:  80%|█████████████████████▌     | 4/5 [01:19<00:19, 19.90s/epoch(s), Training loss(es)=[0.27194518 0.21197411 0.24124031 0.2531617  0.28642645]]Network training:  80%|█████████████████████▌     | 4/5 [01:50<00:27, 27.53s/epoch(s), Training loss(es)=[0.23541406 0.23662597 0.2595853  0.22768717 0.26534122]]Network training: 100%|███████████████████████████| 5/5 [01:50<00:00, 22.02s/epoch(s), Training loss(es)=[0.23541406 0.23662597 0.2595853  0.22768717 0.26534122]]
####################################################################
Starting training iteration 161.
Average action selection time:  0.36407509779930114
Rollout length:  1000
Rewards obtained: [7893.213365906952]
model train lenght 162000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.24568658 0.26289603 0.23109436 0.45570147 0.25592142]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.15s/epoch(s), Training loss(es)=[0.24568658 0.26289603 0.23109436 0.45570147 0.25592142]]Network training:  20%|█████▍                     | 1/5 [00:43<02:52, 43.00s/epoch(s), Training loss(es)=[0.31767026 0.31501836 0.30010796 0.25474274 0.22892562]]Network training:  40%|██████████▊                | 2/5 [00:43<01:04, 21.50s/epoch(s), Training loss(es)=[0.31767026 0.31501836 0.30010796 0.25474274 0.22892562]]Network training:  40%|██████████▊                | 2/5 [01:04<01:36, 32.31s/epoch(s), Training loss(es)=[0.2232819  0.25029215 0.24181628 0.21606201 0.26993093]]Network training:  60%|████████████████▏          | 3/5 [01:04<00:43, 21.54s/epoch(s), Training loss(es)=[0.2232819  0.25029215 0.24181628 0.21606201 0.26993093]]Network training:  60%|████████████████▏          | 3/5 [01:25<00:57, 28.56s/epoch(s), Training loss(es)=[0.22852384 0.24164021 0.3417679  0.2283635  0.22327715]]Network training:  80%|█████████████████████▌     | 4/5 [01:25<00:21, 21.42s/epoch(s), Training loss(es)=[0.22852384 0.24164021 0.3417679  0.2283635  0.22327715]]Network training:  80%|█████████████████████▌     | 4/5 [02:05<00:31, 31.26s/epoch(s), Training loss(es)=[0.23539829 0.27488163 0.21712686 0.23164001 0.21323615]]Network training: 100%|███████████████████████████| 5/5 [02:05<00:00, 25.01s/epoch(s), Training loss(es)=[0.23539829 0.27488163 0.21712686 0.23164001 0.21323615]]
####################################################################
Starting training iteration 162.
Average action selection time:  0.3553782024383545
Rollout length:  1000
Rewards obtained: [10011.729902221756]
model train lenght 163000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.251411   0.2640781  0.21898882 0.21865937 0.24293433]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.24s/epoch(s), Training loss(es)=[0.251411   0.2640781  0.21898882 0.21865937 0.24293433]]Network training:  20%|█████▍                     | 1/5 [00:42<02:51, 42.95s/epoch(s), Training loss(es)=[0.32768378 0.20782009 0.2172157  0.2376984  0.27663654]]Network training:  40%|██████████▊                | 2/5 [00:42<01:04, 21.47s/epoch(s), Training loss(es)=[0.32768378 0.20782009 0.2172157  0.2376984  0.27663654]]Network training:  40%|██████████▊                | 2/5 [01:03<01:35, 31.83s/epoch(s), Training loss(es)=[0.2736372  0.23936956 0.34892347 0.2577884  0.22173457]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.22s/epoch(s), Training loss(es)=[0.2736372  0.23936956 0.34892347 0.2577884  0.22173457]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.97s/epoch(s), Training loss(es)=[0.25235412 0.21877933 0.24850798 0.24462822 0.25663182]]Network training:  80%|█████████████████████▌     | 4/5 [01:23<00:20, 20.98s/epoch(s), Training loss(es)=[0.25235412 0.21877933 0.24850798 0.24462822 0.25663182]]Network training:  80%|█████████████████████▌     | 4/5 [02:05<00:31, 31.32s/epoch(s), Training loss(es)=[0.2631977  0.24473178 0.23398511 0.25562075 0.24330972]]Network training: 100%|███████████████████████████| 5/5 [02:05<00:00, 25.06s/epoch(s), Training loss(es)=[0.2631977  0.24473178 0.23398511 0.25562075 0.24330972]]
####################################################################
Starting training iteration 163.
Average action selection time:  0.3521547780036926
Rollout length:  1000
Rewards obtained: [8525.870997976339]
model train lenght 164000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.2524853  0.24836539 0.2598321  0.24371828 0.24083257]]Network training:  20%|█████▍                     | 1/5 [00:21<01:25, 21.27s/epoch(s), Training loss(es)=[0.2524853  0.24836539 0.2598321  0.24371828 0.24083257]]Network training:  20%|█████▍                     | 1/5 [00:40<02:41, 40.48s/epoch(s), Training loss(es)=[0.23340085 0.247126   0.25598833 0.27099305 0.29178086]]Network training:  40%|██████████▊                | 2/5 [00:40<01:00, 20.24s/epoch(s), Training loss(es)=[0.23340085 0.247126   0.25598833 0.27099305 0.29178086]]Network training:  40%|██████████▊                | 2/5 [01:01<01:31, 30.57s/epoch(s), Training loss(es)=[0.24510163 0.23369963 0.22111668 0.27714965 0.2121573 ]]Network training:  60%|████████████████▏          | 3/5 [01:01<00:40, 20.38s/epoch(s), Training loss(es)=[0.24510163 0.23369963 0.22111668 0.27714965 0.2121573 ]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.15s/epoch(s), Training loss(es)=[0.25457397 0.21050386 0.21671912 0.23954248 0.22786221]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.36s/epoch(s), Training loss(es)=[0.25457397 0.21050386 0.21671912 0.23954248 0.22786221]]Network training:  80%|█████████████████████▌     | 4/5 [02:05<00:31, 31.47s/epoch(s), Training loss(es)=[0.26318002 0.2413379  0.2313314  0.2602959  0.22498575]]Network training: 100%|███████████████████████████| 5/5 [02:05<00:00, 25.18s/epoch(s), Training loss(es)=[0.26318002 0.2413379  0.2313314  0.2602959  0.22498575]]
####################################################################
Starting training iteration 164.
Average action selection time:  0.3485105547904968
Rollout length:  1000
Rewards obtained: [8064.220544729767]
model train lenght 165000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.26012042 0.22540471 0.26317245 0.23660694 0.23794748]]Network training:  20%|█████▍                     | 1/5 [00:21<01:27, 21.92s/epoch(s), Training loss(es)=[0.26012042 0.22540471 0.26317245 0.23660694 0.23794748]]Network training:  20%|█████▍                     | 1/5 [00:43<02:54, 43.52s/epoch(s), Training loss(es)=[0.29462996 0.22721194 0.22316343 0.23811646 0.23233825]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.76s/epoch(s), Training loss(es)=[0.29462996 0.22721194 0.22316343 0.23811646 0.23233825]]Network training:  40%|██████████▊                | 2/5 [01:05<01:38, 32.80s/epoch(s), Training loss(es)=[0.29051036 0.24761574 0.2458677  0.21804874 0.23895547]]Network training:  60%|████████████████▏          | 3/5 [01:05<00:43, 21.87s/epoch(s), Training loss(es)=[0.29051036 0.24761574 0.2458677  0.21804874 0.23895547]]Network training:  60%|████████████████▏          | 3/5 [01:26<00:57, 28.90s/epoch(s), Training loss(es)=[0.22500052 0.23091006 0.24210726 0.23202957 0.296112  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:26<00:21, 21.67s/epoch(s), Training loss(es)=[0.22500052 0.23091006 0.24210726 0.23202957 0.296112  ]]Network training:  80%|█████████████████████▌     | 4/5 [02:15<00:33, 33.92s/epoch(s), Training loss(es)=[0.24795704 0.26989764 0.24492379 0.3479644  0.33740714]]Network training: 100%|███████████████████████████| 5/5 [02:15<00:00, 27.14s/epoch(s), Training loss(es)=[0.24795704 0.26989764 0.24492379 0.3479644  0.33740714]]
####################################################################
Starting training iteration 165.
Average action selection time:  0.34227424454689026
Rollout length:  1000
Rewards obtained: [12746.212955285735]
model train lenght 166000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.25393653 0.29185393 0.2363395  0.22959153 0.23081216]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.00s/epoch(s), Training loss(es)=[0.25393653 0.29185393 0.2363395  0.22959153 0.23081216]]Network training:  20%|█████▍                     | 1/5 [00:42<02:51, 42.76s/epoch(s), Training loss(es)=[0.31483874 0.24047227 0.23847437 0.28794998 0.26079205]]Network training:  40%|██████████▊                | 2/5 [00:42<01:04, 21.38s/epoch(s), Training loss(es)=[0.31483874 0.24047227 0.23847437 0.28794998 0.26079205]]Network training:  40%|██████████▊                | 2/5 [01:04<01:36, 32.20s/epoch(s), Training loss(es)=[0.24516201 0.22856447 0.40059313 0.27988452 0.2633152 ]]Network training:  60%|████████████████▏          | 3/5 [01:04<00:42, 21.47s/epoch(s), Training loss(es)=[0.24516201 0.22856447 0.40059313 0.27988452 0.2633152 ]]Network training:  60%|████████████████▏          | 3/5 [01:27<00:58, 29.03s/epoch(s), Training loss(es)=[0.26556697 0.2886059  0.2232178  0.22085789 0.24873237]]Network training:  80%|█████████████████████▌     | 4/5 [01:27<00:21, 21.77s/epoch(s), Training loss(es)=[0.26556697 0.2886059  0.2232178  0.22085789 0.24873237]]Network training:  80%|█████████████████████▌     | 4/5 [02:17<00:34, 34.36s/epoch(s), Training loss(es)=[0.22693892 0.24277651 0.23984617 0.2932731  0.30726644]]Network training: 100%|███████████████████████████| 5/5 [02:17<00:00, 27.49s/epoch(s), Training loss(es)=[0.22693892 0.24277651 0.23984617 0.2932731  0.30726644]]
####################################################################
Starting training iteration 166.
Average action selection time:  0.3385138726234436
Rollout length:  1000
Rewards obtained: [12632.164390620168]
model train lenght 167000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.20984957 0.28389144 0.26583496 0.23204441 0.26727247]]Network training:  20%|█████▍                     | 1/5 [00:20<01:20, 20.01s/epoch(s), Training loss(es)=[0.20984957 0.28389144 0.26583496 0.23204441 0.26727247]]Network training:  20%|█████▍                     | 1/5 [00:39<02:37, 39.30s/epoch(s), Training loss(es)=[0.25916028 0.25204974 0.25764155 0.27730432 0.23642361]]Network training:  40%|██████████▊                | 2/5 [00:39<00:58, 19.65s/epoch(s), Training loss(es)=[0.25916028 0.25204974 0.25764155 0.27730432 0.23642361]]Network training:  40%|██████████▊                | 2/5 [00:58<01:27, 29.21s/epoch(s), Training loss(es)=[0.21980764 0.22725376 0.21713991 0.27606088 0.2278024 ]]Network training:  60%|████████████████▏          | 3/5 [00:58<00:38, 19.47s/epoch(s), Training loss(es)=[0.21980764 0.22725376 0.21713991 0.27606088 0.2278024 ]]Network training:  60%|████████████████▏          | 3/5 [01:21<00:54, 27.14s/epoch(s), Training loss(es)=[0.26936167 0.24630179 0.24418506 0.23444463 0.2584397 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:21<00:20, 20.35s/epoch(s), Training loss(es)=[0.26936167 0.24630179 0.24418506 0.23444463 0.2584397 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:12<00:33, 33.03s/epoch(s), Training loss(es)=[0.20891775 0.21837986 0.25351512 0.28919706 0.25113523]]Network training: 100%|███████████████████████████| 5/5 [02:12<00:00, 26.42s/epoch(s), Training loss(es)=[0.20891775 0.21837986 0.25351512 0.28919706 0.25113523]]
####################################################################
Starting training iteration 167.
Average action selection time:  0.33588461780548096
Rollout length:  1000
Rewards obtained: [9338.258346311302]
model train lenght 168000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.24640241 0.27468702 0.22857273 0.25533524 0.26062286]]Network training:  20%|█████▍                     | 1/5 [00:22<01:29, 22.29s/epoch(s), Training loss(es)=[0.24640241 0.27468702 0.22857273 0.25533524 0.26062286]]Network training:  20%|█████▍                     | 1/5 [00:44<02:58, 44.59s/epoch(s), Training loss(es)=[0.22667539 0.25437057 0.2683147  0.2389285  0.24514756]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.29s/epoch(s), Training loss(es)=[0.22667539 0.25437057 0.2683147  0.2389285  0.24514756]]Network training:  40%|██████████▊                | 2/5 [01:06<01:39, 33.25s/epoch(s), Training loss(es)=[0.3103895  0.51519847 0.25437132 0.2649872  0.23646726]]Network training:  60%|████████████████▏          | 3/5 [01:06<00:44, 22.16s/epoch(s), Training loss(es)=[0.3103895  0.51519847 0.25437132 0.2649872  0.23646726]]Network training:  60%|████████████████▏          | 3/5 [01:37<01:04, 32.45s/epoch(s), Training loss(es)=[0.24763037 0.25441378 0.22155252 0.24032307 0.24497883]]Network training:  80%|█████████████████████▌     | 4/5 [01:37<00:24, 24.34s/epoch(s), Training loss(es)=[0.24763037 0.25441378 0.22155252 0.24032307 0.24497883]]Network training:  80%|█████████████████████▌     | 4/5 [02:28<00:37, 37.07s/epoch(s), Training loss(es)=[0.22994782 0.31581137 0.26024336 0.24765398 0.29014194]]Network training: 100%|███████████████████████████| 5/5 [02:28<00:00, 29.65s/epoch(s), Training loss(es)=[0.22994782 0.31581137 0.26024336 0.24765398 0.29014194]]
####################################################################
Starting training iteration 168.
Average action selection time:  0.3275082831382751
Rollout length:  1000
Rewards obtained: [8995.244943381]
model train lenght 169000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:19<?, ?epoch(s)/s, Training loss(es)=[0.25665486 0.2563147  0.23328389 0.26688033 0.2495978 ]]Network training:  20%|█████▍                     | 1/5 [00:19<01:16, 19.17s/epoch(s), Training loss(es)=[0.25665486 0.2563147  0.23328389 0.26688033 0.2495978 ]]Network training:  20%|█████▍                     | 1/5 [00:38<02:33, 38.27s/epoch(s), Training loss(es)=[0.2152137  0.2666669  0.24450268 0.2595432  0.21917105]]Network training:  40%|██████████▊                | 2/5 [00:38<00:57, 19.14s/epoch(s), Training loss(es)=[0.2152137  0.2666669  0.24450268 0.2595432  0.21917105]]Network training:  40%|██████████▊                | 2/5 [00:59<01:28, 29.58s/epoch(s), Training loss(es)=[0.25563198 0.2681064  0.2635265  0.24789688 0.25952333]]Network training:  60%|████████████████▏          | 3/5 [00:59<00:39, 19.72s/epoch(s), Training loss(es)=[0.25563198 0.2681064  0.2635265  0.24789688 0.25952333]]Network training:  60%|████████████████▏          | 3/5 [01:33<01:02, 31.07s/epoch(s), Training loss(es)=[0.27416784 0.26398006 0.25735453 0.23983672 0.25539827]]Network training:  80%|█████████████████████▌     | 4/5 [01:33<00:23, 23.31s/epoch(s), Training loss(es)=[0.27416784 0.26398006 0.25735453 0.23983672 0.25539827]]Network training:  80%|█████████████████████▌     | 4/5 [02:24<00:36, 36.10s/epoch(s), Training loss(es)=[0.23866397 0.2560262  0.2077135  0.27166474 0.23865281]]Network training: 100%|███████████████████████████| 5/5 [02:24<00:00, 28.88s/epoch(s), Training loss(es)=[0.23866397 0.2560262  0.2077135  0.27166474 0.23865281]]
####################################################################
Starting training iteration 169.
Average action selection time:  0.3208970415592194
Rollout length:  1000
Rewards obtained: [8683.036585028009]
model train lenght 170000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.25206953 0.25578085 0.3250606  0.22894283 0.25625804]]Network training:  20%|█████▍                     | 1/5 [00:21<01:27, 21.88s/epoch(s), Training loss(es)=[0.25206953 0.25578085 0.3250606  0.22894283 0.25625804]]Network training:  20%|█████▍                     | 1/5 [00:43<02:55, 43.80s/epoch(s), Training loss(es)=[0.23853767 0.23477708 0.24021597 0.27987233 0.2853144 ]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.90s/epoch(s), Training loss(es)=[0.23853767 0.23477708 0.24021597 0.27987233 0.2853144 ]]Network training:  40%|██████████▊                | 2/5 [01:03<01:34, 31.63s/epoch(s), Training loss(es)=[0.25884333 0.26586917 0.3448695  0.24003953 0.23522933]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.08s/epoch(s), Training loss(es)=[0.25884333 0.26586917 0.3448695  0.24003953 0.23522933]]Network training:  60%|████████████████▏          | 3/5 [01:46<01:10, 35.37s/epoch(s), Training loss(es)=[0.23748553 0.22557056 0.3298312  0.25467315 0.232419  ]]Network training:  80%|█████████████████████▌     | 4/5 [01:46<00:26, 26.53s/epoch(s), Training loss(es)=[0.23748553 0.22557056 0.3298312  0.25467315 0.232419  ]]Network training:  80%|█████████████████████▌     | 4/5 [02:37<00:39, 39.41s/epoch(s), Training loss(es)=[0.2677208  0.23965944 0.25426978 0.24160017 0.24123095]]Network training: 100%|███████████████████████████| 5/5 [02:37<00:00, 31.53s/epoch(s), Training loss(es)=[0.2677208  0.23965944 0.25426978 0.24160017 0.24123095]]
####################################################################
Starting training iteration 170.
Average action selection time:  0.30965037322044375
Rollout length:  1000
Rewards obtained: [13474.622361219368]
model train lenght 171000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.33184025 0.27241766 0.27960104 0.23538525 0.27765873]]Network training:  20%|█████▍                     | 1/5 [00:20<01:23, 20.94s/epoch(s), Training loss(es)=[0.33184025 0.27241766 0.27960104 0.23538525 0.27765873]]Network training:  20%|█████▍                     | 1/5 [00:41<02:45, 41.33s/epoch(s), Training loss(es)=[0.29364377 0.2537037  0.23046172 0.29671335 0.2575552 ]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.67s/epoch(s), Training loss(es)=[0.29364377 0.2537037  0.23046172 0.29671335 0.2575552 ]]Network training:  40%|██████████▊                | 2/5 [01:03<01:34, 31.62s/epoch(s), Training loss(es)=[0.23195402 0.23438235 0.3113773  0.24998417 0.26934063]]Network training:  60%|████████████████▏          | 3/5 [01:03<00:42, 21.08s/epoch(s), Training loss(es)=[0.23195402 0.23438235 0.3113773  0.24998417 0.26934063]]Network training:  60%|████████████████▏          | 3/5 [01:51<01:14, 37.08s/epoch(s), Training loss(es)=[0.25217912 0.22786684 0.22831714 0.22872114 0.23343508]]Network training:  80%|█████████████████████▌     | 4/5 [01:51<00:27, 27.81s/epoch(s), Training loss(es)=[0.25217912 0.22786684 0.22831714 0.22872114 0.23343508]]Network training:  80%|█████████████████████▌     | 4/5 [02:43<00:40, 40.79s/epoch(s), Training loss(es)=[0.26403973 0.254779   0.25084075 0.22488797 0.25503382]]Network training: 100%|███████████████████████████| 5/5 [02:43<00:00, 32.63s/epoch(s), Training loss(es)=[0.26403973 0.254779   0.25084075 0.22488797 0.25503382]]
####################################################################
Starting training iteration 171.
Average action selection time:  0.3042890827655792
Rollout length:  1000
Rewards obtained: [8027.366129304697]
model train lenght 172000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.45139262 0.21983096 0.28370154 0.29596522 0.27297685]]Network training:  20%|█████▍                     | 1/5 [00:20<01:23, 20.92s/epoch(s), Training loss(es)=[0.45139262 0.21983096 0.28370154 0.29596522 0.27297685]]Network training:  20%|█████▍                     | 1/5 [00:41<02:45, 41.48s/epoch(s), Training loss(es)=[0.32623866 0.2868943  0.27237323 0.23897676 0.26491955]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.74s/epoch(s), Training loss(es)=[0.32623866 0.2868943  0.27237323 0.23897676 0.26491955]]Network training:  40%|██████████▊                | 2/5 [01:02<01:34, 31.46s/epoch(s), Training loss(es)=[0.23598306 0.29619908 0.23588276 0.25260848 0.25764394]]Network training:  60%|████████████████▏          | 3/5 [01:02<00:41, 20.98s/epoch(s), Training loss(es)=[0.23598306 0.29619908 0.23588276 0.25260848 0.25764394]]Network training:  60%|████████████████▏          | 3/5 [01:54<01:16, 38.25s/epoch(s), Training loss(es)=[0.2669738  0.27588174 0.2657121  0.30107576 0.3363933 ]]Network training:  80%|█████████████████████▌     | 4/5 [01:54<00:28, 28.68s/epoch(s), Training loss(es)=[0.2669738  0.27588174 0.2657121  0.30107576 0.3363933 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:46<00:41, 41.73s/epoch(s), Training loss(es)=[0.2423896  0.22878836 0.2485258  0.24881248 0.23574448]]Network training: 100%|███████████████████████████| 5/5 [02:46<00:00, 33.38s/epoch(s), Training loss(es)=[0.2423896  0.22878836 0.2485258  0.24881248 0.23574448]]
####################################################################
Starting training iteration 172.
Average action selection time:  0.29919605851173403
Rollout length:  1000
Rewards obtained: [10363.722168566585]
model train lenght 173000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.24091709 0.26727018 0.28948218 0.26732376 0.28633818]]Network training:  20%|█████▍                     | 1/5 [00:20<01:22, 20.60s/epoch(s), Training loss(es)=[0.24091709 0.26727018 0.28948218 0.26732376 0.28633818]]Network training:  20%|█████▍                     | 1/5 [00:42<02:48, 42.08s/epoch(s), Training loss(es)=[0.27445486 0.2613445  0.2795137  0.24733426 0.2941351 ]]Network training:  40%|██████████▊                | 2/5 [00:42<01:03, 21.04s/epoch(s), Training loss(es)=[0.27445486 0.2613445  0.2795137  0.24733426 0.2941351 ]]Network training:  40%|██████████▊                | 2/5 [01:05<01:38, 32.83s/epoch(s), Training loss(es)=[0.23791099 0.27947843 0.244109   0.25187984 0.26241058]]Network training:  60%|████████████████▏          | 3/5 [01:05<00:43, 21.89s/epoch(s), Training loss(es)=[0.23791099 0.27947843 0.244109   0.25187984 0.26241058]]Network training:  60%|████████████████▏          | 3/5 [01:58<01:18, 39.37s/epoch(s), Training loss(es)=[0.23930734 0.25233546 0.25700122 0.26626304 0.27451733]]Network training:  80%|█████████████████████▌     | 4/5 [01:58<00:29, 29.53s/epoch(s), Training loss(es)=[0.23930734 0.25233546 0.25700122 0.26626304 0.27451733]]Network training:  80%|█████████████████████▌     | 4/5 [02:50<00:42, 42.64s/epoch(s), Training loss(es)=[0.21871899 0.22675137 0.30189085 0.3939157  0.25135112]]Network training: 100%|███████████████████████████| 5/5 [02:50<00:00, 34.12s/epoch(s), Training loss(es)=[0.21871899 0.22675137 0.30189085 0.3939157  0.25135112]]
####################################################################
Starting training iteration 173.
Average action selection time:  0.29396864891052243
Rollout length:  1000
Rewards obtained: [7437.648541028063]
model train lenght 174000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.26261678 0.24729334 0.30700475 0.26653743 0.2602198 ]]Network training:  20%|█████▍                     | 1/5 [00:20<01:20, 20.07s/epoch(s), Training loss(es)=[0.26261678 0.24729334 0.30700475 0.26653743 0.2602198 ]]Network training:  20%|█████▍                     | 1/5 [00:41<02:47, 41.91s/epoch(s), Training loss(es)=[0.2435925  0.26993197 0.21283239 0.23307763 0.23588222]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.95s/epoch(s), Training loss(es)=[0.2435925  0.26993197 0.21283239 0.23307763 0.23588222]]Network training:  40%|██████████▊                | 2/5 [01:10<01:45, 35.11s/epoch(s), Training loss(es)=[0.2735575  0.32241815 0.2616711  0.23876926 0.22617055]]Network training:  60%|████████████████▏          | 3/5 [01:10<00:46, 23.41s/epoch(s), Training loss(es)=[0.2735575  0.32241815 0.2616711  0.23876926 0.22617055]]Network training:  60%|████████████████▏          | 3/5 [02:02<01:21, 40.97s/epoch(s), Training loss(es)=[0.26047096 0.27246377 0.2346266  0.2570029  0.36900654]]Network training:  80%|█████████████████████▌     | 4/5 [02:02<00:30, 30.73s/epoch(s), Training loss(es)=[0.26047096 0.27246377 0.2346266  0.2570029  0.36900654]]Network training:  80%|█████████████████████▌     | 4/5 [02:55<00:43, 43.93s/epoch(s), Training loss(es)=[0.26448658 0.22422954 0.24115601 0.2427336  0.24364737]]Network training: 100%|███████████████████████████| 5/5 [02:55<00:00, 35.14s/epoch(s), Training loss(es)=[0.26448658 0.22422954 0.24115601 0.2427336  0.24364737]]
####################################################################
Starting training iteration 174.
Average action selection time:  0.28882088589668276
Rollout length:  1000
Rewards obtained: [9018.863438175244]
model train lenght 175000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.31515077 0.25913388 0.25947544 0.33019182 0.2544201 ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:30, 22.52s/epoch(s), Training loss(es)=[0.31515077 0.25913388 0.25947544 0.33019182 0.2544201 ]]Network training:  20%|█████▍                     | 1/5 [00:44<02:56, 44.02s/epoch(s), Training loss(es)=[0.28796786 0.26142353 0.23564588 0.22511601 0.25576827]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.01s/epoch(s), Training loss(es)=[0.28796786 0.26142353 0.23564588 0.22511601 0.25576827]]Network training:  40%|██████████▊                | 2/5 [01:14<01:52, 37.35s/epoch(s), Training loss(es)=[0.25676066 0.2847123  0.23970525 0.28061026 0.6059517 ]]Network training:  60%|████████████████▏          | 3/5 [01:14<00:49, 24.90s/epoch(s), Training loss(es)=[0.25676066 0.2847123  0.23970525 0.28061026 0.6059517 ]]Network training:  60%|████████████████▏          | 3/5 [02:07<01:25, 42.59s/epoch(s), Training loss(es)=[0.2493978  0.23838863 0.27549362 0.2819351  0.2326776 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:07<00:31, 31.94s/epoch(s), Training loss(es)=[0.2493978  0.23838863 0.27549362 0.2819351  0.2326776 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:00<00:45, 45.23s/epoch(s), Training loss(es)=[0.26241958 0.23717749 0.28664356 0.28940284 0.25514418]]Network training: 100%|███████████████████████████| 5/5 [03:00<00:00, 36.18s/epoch(s), Training loss(es)=[0.26241958 0.23717749 0.28664356 0.28940284 0.25514418]]
####################################################################
Starting training iteration 175.
Average action selection time:  0.2837616031169891
Rollout length:  1000
Rewards obtained: [10618.38357104649]
model train lenght 176000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.26327986 0.2217037  0.24143413 0.2988816  0.30757618]]Network training:  20%|█████▍                     | 1/5 [00:23<01:32, 23.02s/epoch(s), Training loss(es)=[0.26327986 0.2217037  0.24143413 0.2988816  0.30757618]]Network training:  20%|█████▍                     | 1/5 [00:45<03:02, 45.71s/epoch(s), Training loss(es)=[0.22837593 0.28365025 0.25445294 0.2703852  0.2876085 ]]Network training:  40%|██████████▊                | 2/5 [00:45<01:08, 22.85s/epoch(s), Training loss(es)=[0.22837593 0.28365025 0.25445294 0.2703852  0.2876085 ]]Network training:  40%|██████████▊                | 2/5 [01:23<02:05, 41.70s/epoch(s), Training loss(es)=[0.26989567 0.2604739  0.24442585 0.25923893 0.24208096]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.80s/epoch(s), Training loss(es)=[0.26989567 0.2604739  0.24442585 0.25923893 0.24208096]]Network training:  60%|████████████████▏          | 3/5 [02:16<01:31, 45.58s/epoch(s), Training loss(es)=[0.2749681  0.21248096 0.23537286 0.2524774  0.25598043]]Network training:  80%|█████████████████████▌     | 4/5 [02:16<00:34, 34.19s/epoch(s), Training loss(es)=[0.2749681  0.21248096 0.23537286 0.2524774  0.25598043]]Network training:  80%|█████████████████████▌     | 4/5 [03:10<00:47, 47.54s/epoch(s), Training loss(es)=[0.25231993 0.23495068 0.24087632 0.26749536 0.27452037]]Network training: 100%|███████████████████████████| 5/5 [03:10<00:00, 38.03s/epoch(s), Training loss(es)=[0.25231993 0.23495068 0.24087632 0.26749536 0.27452037]]
####################################################################
Starting training iteration 176.
Average action selection time:  0.27550245451927186
Rollout length:  1000
Rewards obtained: [9550.550218209892]
model train lenght 177000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.26917177 0.27097094 0.2562979  0.28999117 0.2751821 ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:28, 22.15s/epoch(s), Training loss(es)=[0.26917177 0.27097094 0.2562979  0.28999117 0.2751821 ]]Network training:  20%|█████▍                     | 1/5 [00:43<02:55, 43.97s/epoch(s), Training loss(es)=[0.25588474 0.24314176 0.2528734  0.24212536 0.24902229]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.98s/epoch(s), Training loss(es)=[0.25588474 0.24314176 0.2528734  0.24212536 0.24902229]]Network training:  40%|██████████▊                | 2/5 [01:23<02:04, 41.51s/epoch(s), Training loss(es)=[0.2737302  0.25080514 0.2730947  0.28417915 0.28295195]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.67s/epoch(s), Training loss(es)=[0.2737302  0.25080514 0.2730947  0.28417915 0.28295195]]Network training:  60%|████████████████▏          | 3/5 [02:16<01:31, 45.58s/epoch(s), Training loss(es)=[0.24206199 0.2503011  0.27205482 0.24270909 0.2800835 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:16<00:34, 34.19s/epoch(s), Training loss(es)=[0.24206199 0.2503011  0.27205482 0.24270909 0.2800835 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:10<00:47, 47.63s/epoch(s), Training loss(es)=[0.37658367 0.26473364 0.23785906 0.30886617 0.24903135]]Network training: 100%|███████████████████████████| 5/5 [03:10<00:00, 38.10s/epoch(s), Training loss(es)=[0.37658367 0.26473364 0.23785906 0.30886617 0.24903135]]
####################################################################
Starting training iteration 177.
Average action selection time:  0.27820088601112364
Rollout length:  1000
Rewards obtained: [12437.134338240057]
model train lenght 178000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.25397605 0.2523304  0.26142955 0.24901962 0.2801505 ]]Network training:  20%|█████▍                     | 1/5 [00:20<01:22, 20.58s/epoch(s), Training loss(es)=[0.25397605 0.2523304  0.26142955 0.24901962 0.2801505 ]]Network training:  20%|█████▍                     | 1/5 [00:41<02:47, 41.81s/epoch(s), Training loss(es)=[0.26432386 0.41445443 0.2507481  0.26390776 0.25501832]]Network training:  40%|██████████▊                | 2/5 [00:41<01:02, 20.91s/epoch(s), Training loss(es)=[0.26432386 0.41445443 0.2507481  0.26390776 0.25501832]]Network training:  40%|██████████▊                | 2/5 [01:11<01:47, 35.96s/epoch(s), Training loss(es)=[0.25002486 0.2518692  0.23891145 0.2590099  0.29096708]]Network training:  60%|████████████████▏          | 3/5 [01:11<00:47, 23.97s/epoch(s), Training loss(es)=[0.25002486 0.2518692  0.23891145 0.2590099  0.29096708]]Network training:  60%|████████████████▏          | 3/5 [02:05<01:23, 41.97s/epoch(s), Training loss(es)=[0.27020448 0.2739901  0.25611386 0.26225638 0.26332387]]Network training:  80%|█████████████████████▌     | 4/5 [02:05<00:31, 31.48s/epoch(s), Training loss(es)=[0.27020448 0.2739901  0.25611386 0.26225638 0.26332387]]Network training:  80%|█████████████████████▌     | 4/5 [02:59<00:44, 44.99s/epoch(s), Training loss(es)=[0.33458674 0.31411245 0.23227404 0.27646577 0.27737918]]Network training: 100%|███████████████████████████| 5/5 [02:59<00:00, 35.99s/epoch(s), Training loss(es)=[0.33458674 0.31411245 0.23227404 0.27646577 0.27737918]]
####################################################################
Starting training iteration 178.
Average action selection time:  0.28479179286956785
Rollout length:  1000
Rewards obtained: [10561.68353108847]
model train lenght 179000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.25642914 0.29109228 0.26431873 0.28288072 0.2582916 ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:30, 22.71s/epoch(s), Training loss(es)=[0.25642914 0.29109228 0.26431873 0.28288072 0.2582916 ]]Network training:  20%|█████▍                     | 1/5 [00:43<02:52, 43.04s/epoch(s), Training loss(es)=[0.314908   0.24645779 0.23461016 0.2789943  0.24349502]]Network training:  40%|██████████▊                | 2/5 [00:43<01:04, 21.52s/epoch(s), Training loss(es)=[0.314908   0.24645779 0.23461016 0.2789943  0.24349502]]Network training:  40%|██████████▊                | 2/5 [01:16<01:54, 38.26s/epoch(s), Training loss(es)=[0.277775   0.23360156 0.24326985 0.29924887 0.25987512]]Network training:  60%|████████████████▏          | 3/5 [01:16<00:51, 25.51s/epoch(s), Training loss(es)=[0.277775   0.23360156 0.24326985 0.29924887 0.25987512]]Network training:  60%|████████████████▏          | 3/5 [02:10<01:27, 43.59s/epoch(s), Training loss(es)=[0.2718506  0.23942164 0.24324107 0.26230952 0.24088223]]Network training:  80%|█████████████████████▌     | 4/5 [02:10<00:32, 32.70s/epoch(s), Training loss(es)=[0.2718506  0.23942164 0.24324107 0.26230952 0.24088223]]Network training:  80%|█████████████████████▌     | 4/5 [03:05<00:46, 46.29s/epoch(s), Training loss(es)=[0.4965076  0.24325058 0.25557023 0.24080935 0.23928837]]Network training: 100%|███████████████████████████| 5/5 [03:05<00:00, 37.03s/epoch(s), Training loss(es)=[0.4965076  0.24325058 0.25557023 0.24080935 0.23928837]]
####################################################################
Starting training iteration 179.
Average action selection time:  0.27922311282157897
Rollout length:  1000
Rewards obtained: [8805.900545694478]
model train lenght 180000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.25413078 0.29545343 0.23249888 0.23995884 0.27092332]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.19s/epoch(s), Training loss(es)=[0.25413078 0.29545343 0.23249888 0.23995884 0.27092332]]Network training:  20%|█████▍                     | 1/5 [00:43<02:54, 43.66s/epoch(s), Training loss(es)=[0.25163195 0.29780522 0.36605078 0.22620374 0.2815016 ]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.83s/epoch(s), Training loss(es)=[0.25163195 0.29780522 0.36605078 0.22620374 0.2815016 ]]Network training:  40%|██████████▊                | 2/5 [01:20<02:00, 40.22s/epoch(s), Training loss(es)=[0.2522658  0.34807366 0.26671553 0.25121993 0.25784984]]Network training:  60%|████████████████▏          | 3/5 [01:20<00:53, 26.81s/epoch(s), Training loss(es)=[0.2522658  0.34807366 0.26671553 0.25121993 0.25784984]]Network training:  60%|███████████████████▏            | 3/5 [02:14<01:29, 44.99s/epoch(s), Training loss(es)=[0.2826694 0.2882835 0.2582102 0.2700728 0.2646535]]Network training:  80%|█████████████████████████▌      | 4/5 [02:14<00:33, 33.74s/epoch(s), Training loss(es)=[0.2826694 0.2882835 0.2582102 0.2700728 0.2646535]]Network training:  80%|█████████████████████▌     | 4/5 [03:09<00:47, 47.39s/epoch(s), Training loss(es)=[0.27255192 0.25270975 0.2618174  0.27017447 0.22873253]]Network training: 100%|███████████████████████████| 5/5 [03:09<00:00, 37.91s/epoch(s), Training loss(es)=[0.27255192 0.25270975 0.2618174  0.27017447 0.22873253]]
####################################################################
Starting training iteration 180.
Average action selection time:  0.2754936099052429
Rollout length:  1000
Rewards obtained: [11295.955060926733]
model train lenght 181000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:20<?, ?epoch(s)/s, Training loss(es)=[0.26343465 0.310604   0.24458252 0.23443936 0.24749221]]Network training:  20%|█████▍                     | 1/5 [00:20<01:23, 20.99s/epoch(s), Training loss(es)=[0.26343465 0.310604   0.24458252 0.23443936 0.24749221]]Network training:  20%|█████▍                     | 1/5 [00:42<02:51, 42.85s/epoch(s), Training loss(es)=[0.29370308 0.25903353 0.31667948 0.28310442 0.24954617]]Network training:  40%|██████████▊                | 2/5 [00:42<01:04, 21.42s/epoch(s), Training loss(es)=[0.29370308 0.25903353 0.31667948 0.28310442 0.24954617]]Network training:  40%|██████████▊                | 2/5 [01:22<02:03, 41.19s/epoch(s), Training loss(es)=[0.2857355  0.2512972  0.28392437 0.24556313 0.2686522 ]]Network training:  60%|████████████████▏          | 3/5 [01:22<00:54, 27.46s/epoch(s), Training loss(es)=[0.2857355  0.2512972  0.28392437 0.24556313 0.2686522 ]]Network training:  60%|████████████████▏          | 3/5 [02:17<01:31, 45.73s/epoch(s), Training loss(es)=[0.27618173 0.27946177 0.3214174  0.26192895 0.26511067]]Network training:  80%|█████████████████████▌     | 4/5 [02:17<00:34, 34.30s/epoch(s), Training loss(es)=[0.27618173 0.27946177 0.3214174  0.26192895 0.26511067]]Network training:  80%|█████████████████████▌     | 4/5 [03:12<00:48, 48.02s/epoch(s), Training loss(es)=[0.3901423  0.23709343 0.28814927 0.2604711  0.23304309]]Network training: 100%|███████████████████████████| 5/5 [03:12<00:00, 38.41s/epoch(s), Training loss(es)=[0.3901423  0.23709343 0.28814927 0.2604711  0.23304309]]
####################################################################
Starting training iteration 181.
Average action selection time:  0.27101970410346987
Rollout length:  1000
Rewards obtained: [9309.785007444687]
model train lenght 182000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.3452871  0.24037568 0.25846484 0.267092   0.2480145 ]]Network training:  20%|█████▍                     | 1/5 [00:21<01:24, 21.14s/epoch(s), Training loss(es)=[0.3452871  0.24037568 0.25846484 0.267092   0.2480145 ]]Network training:  20%|█████▍                     | 1/5 [00:43<02:55, 43.91s/epoch(s), Training loss(es)=[0.2266409  0.25464565 0.2814565  0.2690992  0.25890473]]Network training:  40%|██████████▊                | 2/5 [00:43<01:05, 21.95s/epoch(s), Training loss(es)=[0.2266409  0.25464565 0.2814565  0.2690992  0.25890473]]Network training:  40%|██████████▊                | 2/5 [01:27<02:10, 43.56s/epoch(s), Training loss(es)=[0.2674573  0.26733917 0.24626562 0.26847258 0.25931004]]Network training:  60%|████████████████▏          | 3/5 [01:27<00:58, 29.04s/epoch(s), Training loss(es)=[0.2674573  0.26733917 0.24626562 0.26847258 0.25931004]]Network training:  60%|████████████████▏          | 3/5 [02:22<01:34, 47.45s/epoch(s), Training loss(es)=[0.2525517  0.3032278  0.23498003 0.2490947  0.26867983]]Network training:  80%|█████████████████████▌     | 4/5 [02:22<00:35, 35.58s/epoch(s), Training loss(es)=[0.2525517  0.3032278  0.23498003 0.2490947  0.26867983]]Network training:  80%|█████████████████████▌     | 4/5 [03:17<00:49, 49.38s/epoch(s), Training loss(es)=[0.32013676 0.24535853 0.22955903 0.26581407 0.30268452]]Network training: 100%|███████████████████████████| 5/5 [03:17<00:00, 39.51s/epoch(s), Training loss(es)=[0.32013676 0.24535853 0.22955903 0.26581407 0.30268452]]
####################################################################
Starting training iteration 182.
Average action selection time:  0.2660218744277954
Rollout length:  1000
Rewards obtained: [12416.506511962158]
model train lenght 183000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:21<?, ?epoch(s)/s, Training loss(es)=[0.30744535 0.26913851 0.24224876 0.27810338 0.25656143]]Network training:  20%|█████▍                     | 1/5 [00:21<01:26, 21.57s/epoch(s), Training loss(es)=[0.30744535 0.26913851 0.24224876 0.27810338 0.25656143]]Network training:  20%|█████▍                     | 1/5 [00:44<02:56, 44.24s/epoch(s), Training loss(es)=[0.2966729  0.26136664 0.2511322  0.2401925  0.27375928]]Network training:  40%|██████████▊                | 2/5 [00:44<01:06, 22.12s/epoch(s), Training loss(es)=[0.2966729  0.26136664 0.2511322  0.2401925  0.27375928]]Network training:  40%|██████████▊                | 2/5 [01:29<02:14, 44.95s/epoch(s), Training loss(es)=[0.27987006 0.22687142 0.2621162  0.26805648 0.27777067]]Network training:  60%|████████████████▏          | 3/5 [01:29<00:59, 29.97s/epoch(s), Training loss(es)=[0.27987006 0.22687142 0.2621162  0.26805648 0.27777067]]Network training:  60%|████████████████▏          | 3/5 [02:25<01:36, 48.48s/epoch(s), Training loss(es)=[0.2780307  0.25168124 0.24621765 0.27200562 0.27829364]]Network training:  80%|█████████████████████▌     | 4/5 [02:25<00:36, 36.36s/epoch(s), Training loss(es)=[0.2780307  0.25168124 0.24621765 0.27200562 0.27829364]]Network training:  80%|█████████████████████▌     | 4/5 [03:21<00:50, 50.25s/epoch(s), Training loss(es)=[0.25919238 0.27664217 0.2904518  0.25085473 0.30386025]]Network training: 100%|███████████████████████████| 5/5 [03:21<00:00, 40.20s/epoch(s), Training loss(es)=[0.25919238 0.27664217 0.2904518  0.25085473 0.30386025]]
####################################################################
Starting training iteration 183.
Average action selection time:  0.26331832790374754
Rollout length:  1000
Rewards obtained: [9815.892063808611]
model train lenght 184000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.2682016  0.2393259  0.23286228 0.24865647 0.27630013]]Network training:  20%|█████▍                     | 1/5 [00:24<01:37, 24.33s/epoch(s), Training loss(es)=[0.2682016  0.2393259  0.23286228 0.24865647 0.27630013]]Network training:  20%|█████▍                     | 1/5 [00:47<03:10, 47.67s/epoch(s), Training loss(es)=[0.25074196 0.2704058  0.2913505  0.26253048 0.28587884]]Network training:  40%|██████████▊                | 2/5 [00:47<01:11, 23.83s/epoch(s), Training loss(es)=[0.25074196 0.2704058  0.2913505  0.26253048 0.28587884]]Network training:  40%|██████████▊                | 2/5 [01:39<02:29, 49.82s/epoch(s), Training loss(es)=[0.28031585 0.43544707 0.25525293 0.26922342 0.29986995]]Network training:  60%|████████████████▏          | 3/5 [01:39<01:06, 33.21s/epoch(s), Training loss(es)=[0.28031585 0.43544707 0.25525293 0.26922342 0.29986995]]Network training:  60%|████████████████▏          | 3/5 [02:35<01:43, 51.84s/epoch(s), Training loss(es)=[0.24728034 0.23516856 0.26472908 0.331376   0.28112656]]Network training:  80%|█████████████████████▌     | 4/5 [02:35<00:38, 38.88s/epoch(s), Training loss(es)=[0.24728034 0.23516856 0.26472908 0.331376   0.28112656]]Network training:  80%|█████████████████████▌     | 4/5 [03:31<00:52, 52.85s/epoch(s), Training loss(es)=[0.28048858 0.27420956 0.27807587 0.24775922 0.24206291]]Network training: 100%|███████████████████████████| 5/5 [03:31<00:00, 42.28s/epoch(s), Training loss(es)=[0.28048858 0.27420956 0.27807587 0.24775922 0.24206291]]
####################################################################
Starting training iteration 184.
Average action selection time:  0.2545621507167816
Rollout length:  1000
Rewards obtained: [7163.547853977011]
model train lenght 185000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.26371783 0.2286822  0.27755365 0.29671657 0.23639217]]Network training:  20%|█████▍                     | 1/5 [00:22<01:31, 22.78s/epoch(s), Training loss(es)=[0.26371783 0.2286822  0.27755365 0.29671657 0.23639217]]Network training:  20%|█████▍                     | 1/5 [00:45<03:03, 45.86s/epoch(s), Training loss(es)=[0.26641217 0.27765307 0.27903157 0.26336858 0.24061057]]Network training:  40%|██████████▊                | 2/5 [00:45<01:08, 22.93s/epoch(s), Training loss(es)=[0.26641217 0.27765307 0.27903157 0.26336858 0.24061057]]Network training:  40%|██████████▊                | 2/5 [01:37<02:25, 48.58s/epoch(s), Training loss(es)=[0.33445185 0.27358276 0.26097664 0.2593148  0.26600412]]Network training:  60%|████████████████▏          | 3/5 [01:37<01:04, 32.39s/epoch(s), Training loss(es)=[0.33445185 0.27358276 0.26097664 0.2593148  0.26600412]]Network training:  60%|████████████████▏          | 3/5 [02:33<01:42, 51.11s/epoch(s), Training loss(es)=[0.2636892  0.24715373 0.32530177 0.25546587 0.24648659]]Network training:  80%|█████████████████████▌     | 4/5 [02:33<00:38, 38.33s/epoch(s), Training loss(es)=[0.2636892  0.24715373 0.32530177 0.25546587 0.24648659]]Network training:  80%|█████████████████████▌     | 4/5 [03:29<00:52, 52.39s/epoch(s), Training loss(es)=[0.26918066 0.2566727  0.2926375  0.25047618 0.26988956]]Network training: 100%|███████████████████████████| 5/5 [03:29<00:00, 41.91s/epoch(s), Training loss(es)=[0.26918066 0.2566727  0.2926375  0.25047618 0.26988956]]
####################################################################
Starting training iteration 185.
Average action selection time:  0.25470147633552553
Rollout length:  1000
Rewards obtained: [6722.664730137347]
model train lenght 186000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.26026225 0.2764549  0.329284   0.2772877  0.25263578]]Network training:  20%|█████▍                     | 1/5 [00:22<01:28, 22.25s/epoch(s), Training loss(es)=[0.26026225 0.2764549  0.329284   0.2772877  0.25263578]]Network training:  20%|█████▍                     | 1/5 [00:46<03:06, 46.72s/epoch(s), Training loss(es)=[0.26115024 0.3086102  0.26667485 0.31851596 0.30458453]]Network training:  40%|██████████▊                | 2/5 [00:46<01:10, 23.36s/epoch(s), Training loss(es)=[0.26115024 0.3086102  0.26667485 0.31851596 0.30458453]]Network training:  40%|██████████▊                | 2/5 [01:40<02:31, 50.39s/epoch(s), Training loss(es)=[0.23229013 0.2610948  0.24259521 0.2759797  0.27941856]]Network training:  60%|████████████████▏          | 3/5 [01:40<01:07, 33.59s/epoch(s), Training loss(es)=[0.23229013 0.2610948  0.24259521 0.2759797  0.27941856]]Network training:  60%|████████████████▏          | 3/5 [02:37<01:44, 52.43s/epoch(s), Training loss(es)=[0.2584131  0.26980084 0.2575293  0.2803093  0.23553464]]Network training:  80%|█████████████████████▌     | 4/5 [02:37<00:39, 39.32s/epoch(s), Training loss(es)=[0.2584131  0.26980084 0.2575293  0.2803093  0.23553464]]Network training:  80%|█████████████████████▌     | 4/5 [03:33<00:53, 53.45s/epoch(s), Training loss(es)=[0.25744027 0.28122905 0.27013275 0.23101628 0.28322992]]Network training: 100%|███████████████████████████| 5/5 [03:33<00:00, 42.76s/epoch(s), Training loss(es)=[0.25744027 0.28122905 0.27013275 0.23101628 0.28322992]]
####################################################################
Starting training iteration 186.
Average action selection time:  0.2513499116897583
Rollout length:  1000
Rewards obtained: [12990.527422709774]
model train lenght 187000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:25<?, ?epoch(s)/s, Training loss(es)=[0.2672489  0.25874862 0.38815784 0.28534684 0.29451525]]Network training:  20%|█████▍                     | 1/5 [00:25<01:40, 25.01s/epoch(s), Training loss(es)=[0.2672489  0.25874862 0.38815784 0.28534684 0.29451525]]Network training:  20%|█████▍                     | 1/5 [00:52<03:30, 52.64s/epoch(s), Training loss(es)=[0.27955118 0.2486052  0.24030408 0.3087117  0.24571721]]Network training:  40%|██████████▊                | 2/5 [00:52<01:18, 26.32s/epoch(s), Training loss(es)=[0.27955118 0.2486052  0.24030408 0.3087117  0.24571721]]Network training:  40%|██████████▊                | 2/5 [01:49<02:44, 54.70s/epoch(s), Training loss(es)=[0.23355459 0.3004192  0.25990754 0.28774863 0.2634722 ]]Network training:  60%|████████████████▏          | 3/5 [01:49<01:12, 36.47s/epoch(s), Training loss(es)=[0.23355459 0.3004192  0.25990754 0.28774863 0.2634722 ]]Network training:  60%|████████████████▏          | 3/5 [02:46<01:50, 55.41s/epoch(s), Training loss(es)=[0.24761072 0.2798472  0.27314883 0.25274616 0.27225757]]Network training:  80%|█████████████████████▌     | 4/5 [02:46<00:41, 41.56s/epoch(s), Training loss(es)=[0.24761072 0.2798472  0.27314883 0.25274616 0.27225757]]Network training:  80%|█████████████████████▌     | 4/5 [03:43<00:55, 55.75s/epoch(s), Training loss(es)=[0.22707342 0.29199728 0.28131452 0.26980782 0.25474653]]Network training: 100%|███████████████████████████| 5/5 [03:43<00:00, 44.60s/epoch(s), Training loss(es)=[0.22707342 0.29199728 0.28131452 0.26980782 0.25474653]]
####################################################################
Starting training iteration 187.
Average action selection time:  0.24207381010055543
Rollout length:  1000
Rewards obtained: [8348.696988344174]
model train lenght 188000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.32975504 0.2877272  0.273813   0.2738164  0.23608916]]Network training:  20%|█████▍                     | 1/5 [00:23<01:33, 23.33s/epoch(s), Training loss(es)=[0.32975504 0.2877272  0.273813   0.2738164  0.23608916]]Network training:  20%|█████▍                     | 1/5 [00:56<03:44, 56.05s/epoch(s), Training loss(es)=[0.2846027  0.2931052  0.26834074 0.2749571  0.2671511 ]]Network training:  40%|██████████▊                | 2/5 [00:56<01:24, 28.03s/epoch(s), Training loss(es)=[0.2846027  0.2931052  0.26834074 0.2749571  0.2671511 ]]Network training:  40%|████████████▊                   | 2/5 [01:53<02:49, 56.51s/epoch(s), Training loss(es)=[0.2660201 0.2669584 0.2583489 0.2586821 0.2581196]]Network training:  60%|███████████████████▏            | 3/5 [01:53<01:15, 37.68s/epoch(s), Training loss(es)=[0.2660201 0.2669584 0.2583489 0.2586821 0.2581196]]Network training:  60%|████████████████▏          | 3/5 [02:50<01:53, 56.71s/epoch(s), Training loss(es)=[0.27295238 0.25223893 0.25894088 0.24410234 0.26908615]]Network training:  80%|█████████████████████▌     | 4/5 [02:50<00:42, 42.54s/epoch(s), Training loss(es)=[0.27295238 0.25223893 0.25894088 0.24410234 0.26908615]]Network training:  80%|█████████████████████▌     | 4/5 [03:47<00:56, 56.82s/epoch(s), Training loss(es)=[0.23438467 0.29115242 0.31683114 0.2877587  0.2795585 ]]Network training: 100%|███████████████████████████| 5/5 [03:47<00:00, 45.45s/epoch(s), Training loss(es)=[0.23438467 0.29115242 0.31683114 0.2877587  0.2795585 ]]
####################################################################
Starting training iteration 188.
Average action selection time:  0.23572402596473693
Rollout length:  1000
Rewards obtained: [9239.982016200354]
model train lenght 189000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.25019777 0.29249823 0.24153784 0.30365697 0.26407757]]Network training:  20%|█████▍                     | 1/5 [00:22<01:31, 22.99s/epoch(s), Training loss(es)=[0.25019777 0.29249823 0.24153784 0.30365697 0.26407757]]Network training:  20%|█████▍                     | 1/5 [00:53<03:32, 53.25s/epoch(s), Training loss(es)=[0.2546073  0.2603513  0.278824   0.23869124 0.2732501 ]]Network training:  40%|██████████▊                | 2/5 [00:53<01:19, 26.62s/epoch(s), Training loss(es)=[0.2546073  0.2603513  0.278824   0.23869124 0.2732501 ]]Network training:  40%|██████████▊                | 2/5 [01:50<02:45, 55.30s/epoch(s), Training loss(es)=[0.328255   0.275759   0.26680133 0.24679494 0.33589545]]Network training:  60%|████████████████▏          | 3/5 [01:50<01:13, 36.87s/epoch(s), Training loss(es)=[0.328255   0.275759   0.26680133 0.24679494 0.33589545]]Network training:  60%|████████████████▏          | 3/5 [02:47<01:51, 56.00s/epoch(s), Training loss(es)=[0.27020878 0.273374   0.21822293 0.27529716 0.29756692]]Network training:  80%|█████████████████████▌     | 4/5 [02:47<00:41, 42.00s/epoch(s), Training loss(es)=[0.27020878 0.273374   0.21822293 0.27529716 0.29756692]]Network training:  80%|█████████████████████▌     | 4/5 [03:45<00:56, 56.35s/epoch(s), Training loss(es)=[0.26655045 0.25682816 0.36367682 0.2637353  0.23086023]]Network training: 100%|███████████████████████████| 5/5 [03:45<00:00, 45.08s/epoch(s), Training loss(es)=[0.26655045 0.25682816 0.36367682 0.2637353  0.23086023]]
####################################################################
Starting training iteration 189.
Average action selection time:  0.23686807322502137
Rollout length:  1000
Rewards obtained: [7991.975791579034]
model train lenght 190000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:22<?, ?epoch(s)/s, Training loss(es)=[0.2767032  0.25389203 0.26069376 0.30825529 0.3087716 ]]Network training:  20%|█████▍                     | 1/5 [00:22<01:31, 22.84s/epoch(s), Training loss(es)=[0.2767032  0.25389203 0.26069376 0.30825529 0.3087716 ]]Network training:  20%|█████▍                     | 1/5 [00:57<03:49, 57.30s/epoch(s), Training loss(es)=[0.2705273  0.2710269  0.291982   0.29086393 0.256035  ]]Network training:  40%|██████████▊                | 2/5 [00:57<01:25, 28.65s/epoch(s), Training loss(es)=[0.2705273  0.2710269  0.291982   0.29086393 0.256035  ]]Network training:  40%|██████████▊                | 2/5 [01:55<02:52, 57.55s/epoch(s), Training loss(es)=[0.26105568 0.2733508  0.2654771  0.26575285 0.24258298]]Network training:  60%|████████████████▏          | 3/5 [01:55<01:16, 38.36s/epoch(s), Training loss(es)=[0.26105568 0.2733508  0.2654771  0.26575285 0.24258298]]Network training:  60%|████████████████▏          | 3/5 [02:52<01:55, 57.60s/epoch(s), Training loss(es)=[0.3067722  0.2790527  0.2755282  0.28779328 0.27132654]]Network training:  80%|█████████████████████▌     | 4/5 [02:52<00:43, 43.20s/epoch(s), Training loss(es)=[0.3067722  0.2790527  0.2755282  0.28779328 0.27132654]]Network training:  80%|█████████████████████▌     | 4/5 [03:50<00:57, 57.65s/epoch(s), Training loss(es)=[0.37634397 0.22542115 0.23960283 0.27960888 0.24438408]]Network training: 100%|███████████████████████████| 5/5 [03:50<00:00, 46.12s/epoch(s), Training loss(es)=[0.37634397 0.22542115 0.23960283 0.27960888 0.24438408]]
####################################################################
Starting training iteration 190.
Average action selection time:  0.23042055797576905
Rollout length:  1000
Rewards obtained: [14863.714807559858]
model train lenght 191000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.31020474 0.24444163 0.25747898 0.23452131 0.30264688]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.07s/epoch(s), Training loss(es)=[0.31020474 0.24444163 0.25747898 0.23452131 0.30264688]]Network training:  20%|█████▍                     | 1/5 [01:04<04:17, 64.36s/epoch(s), Training loss(es)=[0.27956998 0.24687469 0.25763926 0.28215078 0.27396935]]Network training:  40%|██████████▊                | 2/5 [01:04<01:36, 32.18s/epoch(s), Training loss(es)=[0.27956998 0.24687469 0.25763926 0.28215078 0.27396935]]Network training:  40%|██████████▊                | 2/5 [02:02<03:03, 61.18s/epoch(s), Training loss(es)=[0.24161452 0.27079752 0.25184205 0.24889877 0.28541538]]Network training:  60%|████████████████▏          | 3/5 [02:02<01:21, 40.79s/epoch(s), Training loss(es)=[0.24161452 0.27079752 0.25184205 0.24889877 0.28541538]]Network training:  60%|████████████████▏          | 3/5 [03:00<02:00, 60.16s/epoch(s), Training loss(es)=[0.31584322 0.2736188  0.33431298 0.23786968 0.25609526]]Network training:  80%|█████████████████████▌     | 4/5 [03:00<00:45, 45.12s/epoch(s), Training loss(es)=[0.31584322 0.2736188  0.33431298 0.23786968 0.25609526]]Network training:  80%|█████████████████████▌     | 4/5 [03:58<00:59, 59.62s/epoch(s), Training loss(es)=[0.24710959 0.2366656  0.22361404 0.24621189 0.26689857]]Network training: 100%|███████████████████████████| 5/5 [03:58<00:00, 47.69s/epoch(s), Training loss(es)=[0.24710959 0.2366656  0.22361404 0.24621189 0.26689857]]
####################################################################
Starting training iteration 191.
Average action selection time:  0.22367475414276122
Rollout length:  1000
Rewards obtained: [13670.179650782124]
model train lenght 192000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.256513   0.25858304 0.2978797  0.24676977 0.29734972]]Network training:  20%|█████▍                     | 1/5 [00:23<01:34, 23.66s/epoch(s), Training loss(es)=[0.256513   0.25858304 0.2978797  0.24676977 0.29734972]]Network training:  20%|█████▍                     | 1/5 [01:06<04:26, 66.71s/epoch(s), Training loss(es)=[0.24790828 0.27539214 0.28360695 0.2883529  0.2894833 ]]Network training:  40%|██████████▊                | 2/5 [01:06<01:40, 33.35s/epoch(s), Training loss(es)=[0.24790828 0.27539214 0.28360695 0.2883529  0.2894833 ]]Network training:  40%|██████████▊                | 2/5 [02:05<03:07, 62.50s/epoch(s), Training loss(es)=[0.2993117  0.26837736 0.28281894 0.26491034 0.25383064]]Network training:  60%|████████████████▏          | 3/5 [02:05<01:23, 41.67s/epoch(s), Training loss(es)=[0.2993117  0.26837736 0.28281894 0.26491034 0.25383064]]Network training:  60%|████████████████▏          | 3/5 [03:03<02:02, 61.09s/epoch(s), Training loss(es)=[0.2588511  0.30354425 0.23472041 0.27735582 0.28273058]]Network training:  80%|█████████████████████▌     | 4/5 [03:03<00:45, 45.81s/epoch(s), Training loss(es)=[0.2588511  0.30354425 0.23472041 0.27735582 0.28273058]]Network training:  80%|█████████████████████▌     | 4/5 [04:01<01:00, 60.40s/epoch(s), Training loss(es)=[0.30501541 0.28943583 0.2666041  0.26777238 0.25060526]]Network training: 100%|███████████████████████████| 5/5 [04:01<00:00, 48.32s/epoch(s), Training loss(es)=[0.30501541 0.28943583 0.2666041  0.26777238 0.25060526]]
####################################################################
Starting training iteration 192.
Average action selection time:  0.21873810148239137
Rollout length:  1000
Rewards obtained: [17192.65374619077]
model train lenght 193000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.25875187 0.27742672 0.3390064  0.31461605 0.2783358 ]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.16s/epoch(s), Training loss(es)=[0.25875187 0.27742672 0.3390064  0.31461605 0.2783358 ]]Network training:  20%|█████▍                     | 1/5 [01:08<04:32, 68.08s/epoch(s), Training loss(es)=[0.2867343  0.2939164  0.2727959  0.3459238  0.26843378]]Network training:  40%|██████████▊                | 2/5 [01:08<01:42, 34.04s/epoch(s), Training loss(es)=[0.2867343  0.2939164  0.2727959  0.3459238  0.26843378]]Network training:  40%|██████████▊                | 2/5 [02:06<03:09, 63.31s/epoch(s), Training loss(es)=[0.2589875  0.28509176 0.26725298 0.27807894 0.31663826]]Network training:  60%|████████████████▏          | 3/5 [02:06<01:24, 42.21s/epoch(s), Training loss(es)=[0.2589875  0.28509176 0.26725298 0.27807894 0.31663826]]Network training:  60%|████████████████▏          | 3/5 [03:05<02:03, 61.74s/epoch(s), Training loss(es)=[0.28243455 0.25155067 0.293246   0.2457499  0.28157675]]Network training:  80%|█████████████████████▌     | 4/5 [03:05<00:46, 46.30s/epoch(s), Training loss(es)=[0.28243455 0.25155067 0.293246   0.2457499  0.28157675]]Network training:  80%|█████████████████████▌     | 4/5 [04:03<01:00, 60.84s/epoch(s), Training loss(es)=[0.26392162 0.27477843 0.27458516 0.27550375 0.2687782 ]]Network training: 100%|███████████████████████████| 5/5 [04:03<00:00, 48.67s/epoch(s), Training loss(es)=[0.26392162 0.27477843 0.27458516 0.27550375 0.2687782 ]]
####################################################################
Starting training iteration 193.
Average action selection time:  0.2177588951587677
Rollout length:  1000
Rewards obtained: [9158.183424610417]
model train lenght 194000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.26528797 0.25244278 0.31012255 0.27316764 0.32561094]]Network training:  20%|█████▍                     | 1/5 [00:23<01:34, 23.62s/epoch(s), Training loss(es)=[0.26528797 0.25244278 0.31012255 0.27316764 0.32561094]]Network training:  20%|█████▍                     | 1/5 [01:07<04:29, 67.26s/epoch(s), Training loss(es)=[0.27343163 0.27602944 0.30952147 0.27665183 0.2870891 ]]Network training:  40%|██████████▊                | 2/5 [01:07<01:40, 33.63s/epoch(s), Training loss(es)=[0.27343163 0.27602944 0.30952147 0.27665183 0.2870891 ]]Network training:  40%|██████████▊                | 2/5 [02:06<03:09, 63.05s/epoch(s), Training loss(es)=[0.25519788 0.30429962 0.30689093 0.25006023 0.36220983]]Network training:  60%|████████████████▏          | 3/5 [02:06<01:24, 42.03s/epoch(s), Training loss(es)=[0.25519788 0.30429962 0.30689093 0.25006023 0.36220983]]Network training:  60%|████████████████▏          | 3/5 [03:04<02:03, 61.65s/epoch(s), Training loss(es)=[0.32820883 0.29723302 0.26547897 0.25086975 0.26943368]]Network training:  80%|█████████████████████▌     | 4/5 [03:04<00:46, 46.24s/epoch(s), Training loss(es)=[0.32820883 0.29723302 0.26547897 0.25086975 0.26943368]]Network training:  80%|█████████████████████▌     | 4/5 [04:03<01:00, 60.81s/epoch(s), Training loss(es)=[0.25935668 0.27845457 0.32507712 0.25756937 0.3085901 ]]Network training: 100%|███████████████████████████| 5/5 [04:03<00:00, 48.65s/epoch(s), Training loss(es)=[0.25935668 0.27845457 0.32507712 0.25756937 0.3085901 ]]
####################################################################
Starting training iteration 194.
Average action selection time:  0.2176618630886078
Rollout length:  1000
Rewards obtained: [11712.674699432608]
model train lenght 195000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.25416008 0.268754   0.27084035 0.41204864 0.27191818]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 24.00s/epoch(s), Training loss(es)=[0.25416008 0.268754   0.27084035 0.41204864 0.27191818]]Network training:  20%|█████▍                     | 1/5 [01:07<04:29, 67.40s/epoch(s), Training loss(es)=[0.28914878 0.27846447 0.26436877 0.26678392 0.22970684]]Network training:  40%|██████████▊                | 2/5 [01:07<01:41, 33.70s/epoch(s), Training loss(es)=[0.28914878 0.27846447 0.26436877 0.26678392 0.22970684]]Network training:  40%|██████████▊                | 2/5 [02:06<03:09, 63.30s/epoch(s), Training loss(es)=[0.26727057 0.24759878 0.27453    0.24555384 0.28153726]]Network training:  60%|████████████████▏          | 3/5 [02:06<01:24, 42.20s/epoch(s), Training loss(es)=[0.26727057 0.24759878 0.27453    0.24555384 0.28153726]]Network training:  60%|████████████████▏          | 3/5 [03:05<02:03, 61.95s/epoch(s), Training loss(es)=[0.3281853  0.2697275  0.2891995  0.23502015 0.2898275 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:05<00:46, 46.46s/epoch(s), Training loss(es)=[0.3281853  0.2697275  0.2891995  0.23502015 0.2898275 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:03<01:00, 60.91s/epoch(s), Training loss(es)=[0.26919013 0.2571845  0.27505183 0.2843598  0.27964908]]Network training: 100%|███████████████████████████| 5/5 [04:03<00:00, 48.73s/epoch(s), Training loss(es)=[0.26919013 0.2571845  0.27505183 0.2843598  0.27964908]]
####################################################################
Starting training iteration 195.
Average action selection time:  0.21779921793937684
Rollout length:  1000
Rewards obtained: [8940.940234946338]
model train lenght 196000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:25<?, ?epoch(s)/s, Training loss(es)=[0.24383059 0.29219195 0.266174   0.26878783 0.2817765 ]]Network training:  20%|█████▍                     | 1/5 [00:25<01:40, 25.13s/epoch(s), Training loss(es)=[0.24383059 0.29219195 0.266174   0.26878783 0.2817765 ]]Network training:  20%|█████▍                     | 1/5 [01:11<04:47, 71.99s/epoch(s), Training loss(es)=[0.27691832 0.26236346 0.3407198  0.30522567 0.290483  ]]Network training:  40%|██████████▊                | 2/5 [01:11<01:47, 36.00s/epoch(s), Training loss(es)=[0.27691832 0.26236346 0.3407198  0.30522567 0.290483  ]]Network training:  40%|██████████▊                | 2/5 [02:11<03:17, 65.71s/epoch(s), Training loss(es)=[0.23737063 0.22893623 0.27165282 0.30638272 0.30815977]]Network training:  60%|████████████████▏          | 3/5 [02:11<01:27, 43.81s/epoch(s), Training loss(es)=[0.23737063 0.22893623 0.27165282 0.30638272 0.30815977]]Network training:  60%|████████████████▏          | 3/5 [03:10<02:07, 63.61s/epoch(s), Training loss(es)=[0.26320216 0.26417816 0.30085826 0.27644092 0.2889911 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:10<00:47, 47.71s/epoch(s), Training loss(es)=[0.26320216 0.26417816 0.30085826 0.27644092 0.2889911 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:06<01:01, 61.54s/epoch(s), Training loss(es)=[0.2768935  0.2381219  0.27308372 0.27548873 0.26415136]]Network training: 100%|███████████████████████████| 5/5 [04:06<00:00, 49.23s/epoch(s), Training loss(es)=[0.2768935  0.2381219  0.27308372 0.27548873 0.26415136]]
####################################################################
Starting training iteration 196.
Average action selection time:  0.21760151529312133
Rollout length:  1000
Rewards obtained: [16776.306748153984]
model train lenght 197000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.3032597  0.2552774  0.31175962 0.31852093 0.25511742]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.19s/epoch(s), Training loss(es)=[0.3032597  0.2552774  0.31175962 0.31852093 0.25511742]]Network training:  20%|█████▍                     | 1/5 [01:11<04:44, 71.06s/epoch(s), Training loss(es)=[0.2788558  0.29325932 0.27202603 0.29672226 0.31324023]]Network training:  40%|██████████▊                | 2/5 [01:11<01:46, 35.53s/epoch(s), Training loss(es)=[0.2788558  0.29325932 0.27202603 0.29672226 0.31324023]]Network training:  40%|██████████▊                | 2/5 [02:10<03:16, 65.43s/epoch(s), Training loss(es)=[0.29006916 0.36838523 0.26947436 0.26984936 0.30064926]]Network training:  60%|████████████████▏          | 3/5 [02:10<01:27, 43.62s/epoch(s), Training loss(es)=[0.29006916 0.36838523 0.26947436 0.26984936 0.30064926]]Network training:  60%|████████████████▏          | 3/5 [03:10<02:07, 63.58s/epoch(s), Training loss(es)=[0.28294224 0.33980498 0.26435158 0.3516184  0.28867364]]Network training:  80%|█████████████████████▌     | 4/5 [03:10<00:47, 47.69s/epoch(s), Training loss(es)=[0.28294224 0.33980498 0.26435158 0.3516184  0.28867364]]Network training:  80%|█████████████████████▌     | 4/5 [04:05<01:01, 61.36s/epoch(s), Training loss(es)=[0.29007816 0.31857795 0.26378334 0.26428425 0.28643063]]Network training: 100%|███████████████████████████| 5/5 [04:05<00:00, 49.09s/epoch(s), Training loss(es)=[0.29007816 0.31857795 0.26378334 0.26428425 0.28643063]]
####################################################################
Starting training iteration 197.
Average action selection time:  0.21737736749649048
Rollout length:  1000
Rewards obtained: [15250.207388369534]
model train lenght 198000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.28260618 0.2605983  0.30159453 0.28750372 0.2747763 ]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 23.83s/epoch(s), Training loss(es)=[0.28260618 0.2605983  0.30159453 0.28750372 0.2747763 ]]Network training:  20%|█████▍                     | 1/5 [01:15<05:00, 75.01s/epoch(s), Training loss(es)=[0.26208454 0.3048674  0.29797208 0.32035315 0.30050516]]Network training:  40%|██████████▊                | 2/5 [01:15<01:52, 37.51s/epoch(s), Training loss(es)=[0.26208454 0.3048674  0.29797208 0.32035315 0.30050516]]Network training:  40%|██████████▊                | 2/5 [02:15<03:22, 67.52s/epoch(s), Training loss(es)=[0.30693358 0.29450724 0.27183568 0.28714547 0.3956781 ]]Network training:  60%|████████████████▏          | 3/5 [02:15<01:30, 45.01s/epoch(s), Training loss(es)=[0.30693358 0.29450724 0.27183568 0.28714547 0.3956781 ]]Network training:  60%|████████████████▏          | 3/5 [03:15<02:10, 65.04s/epoch(s), Training loss(es)=[0.27913654 0.2611269  0.33457476 0.2800931  0.2943544 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:15<00:48, 48.78s/epoch(s), Training loss(es)=[0.27913654 0.2611269  0.33457476 0.2800931  0.2943544 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:05<01:01, 61.36s/epoch(s), Training loss(es)=[0.29892465 0.24689838 0.26344404 0.25046524 0.27158737]]Network training: 100%|███████████████████████████| 5/5 [04:05<00:00, 49.09s/epoch(s), Training loss(es)=[0.29892465 0.24689838 0.26344404 0.25046524 0.27158737]]
####################################################################
Starting training iteration 198.
Average action selection time:  0.21757552027702332
Rollout length:  1000
Rewards obtained: [9902.198373620784]
model train lenght 199000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:23<?, ?epoch(s)/s, Training loss(es)=[0.3266659  0.25231725 0.31056806 0.26197916 0.24407573]]Network training:  20%|█████▍                     | 1/5 [00:23<01:35, 23.87s/epoch(s), Training loss(es)=[0.3266659  0.25231725 0.31056806 0.26197916 0.24407573]]Network training:  20%|█████▍                     | 1/5 [01:13<04:54, 73.73s/epoch(s), Training loss(es)=[0.32151094 0.28871432 0.23332578 0.28877115 0.27363274]]Network training:  40%|██████████▊                | 2/5 [01:13<01:50, 36.87s/epoch(s), Training loss(es)=[0.32151094 0.28871432 0.23332578 0.28877115 0.27363274]]Network training:  40%|██████████▊                | 2/5 [02:14<03:21, 67.08s/epoch(s), Training loss(es)=[0.2618338  0.34587386 0.23379624 0.2507261  0.29689574]]Network training:  60%|████████████████▏          | 3/5 [02:14<01:29, 44.72s/epoch(s), Training loss(es)=[0.2618338  0.34587386 0.23379624 0.2507261  0.29689574]]Network training:  60%|████████████████▏          | 3/5 [03:14<02:09, 64.86s/epoch(s), Training loss(es)=[0.25461003 0.23503643 0.29646    0.28140932 0.20456368]]Network training:  80%|█████████████████████▌     | 4/5 [03:14<00:48, 48.64s/epoch(s), Training loss(es)=[0.25461003 0.23503643 0.29646    0.28140932 0.20456368]]Network training:  80%|█████████████████████▌     | 4/5 [04:06<01:01, 61.51s/epoch(s), Training loss(es)=[0.27080634 0.27821952 0.28232583 0.2829365  0.2673032 ]]Network training: 100%|███████████████████████████| 5/5 [04:06<00:00, 49.21s/epoch(s), Training loss(es)=[0.27080634 0.27821952 0.28232583 0.2829365  0.2673032 ]]
####################################################################
Starting training iteration 199.
Average action selection time:  0.21708524918556213
Rollout length:  1000
Rewards obtained: [13769.368647645717]
model train lenght 200000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:24<?, ?epoch(s)/s, Training loss(es)=[0.2978268  0.30651405 0.28950563 0.2652851  0.30485892]]Network training:  20%|█████▍                     | 1/5 [00:24<01:36, 24.22s/epoch(s), Training loss(es)=[0.2978268  0.30651405 0.28950563 0.2652851  0.30485892]]Network training:  20%|█████▍                     | 1/5 [01:17<05:08, 77.02s/epoch(s), Training loss(es)=[0.27233967 0.31694874 0.26346374 0.2972748  0.39931807]]Network training:  40%|██████████▊                | 2/5 [01:17<01:55, 38.51s/epoch(s), Training loss(es)=[0.27233967 0.31694874 0.26346374 0.2972748  0.39931807]]Network training:  40%|██████████▊                | 2/5 [02:17<03:26, 68.83s/epoch(s), Training loss(es)=[0.3174536  0.285159   0.26032045 0.26735938 0.2995974 ]]Network training:  60%|████████████████▏          | 3/5 [02:17<01:31, 45.88s/epoch(s), Training loss(es)=[0.3174536  0.285159   0.26032045 0.26735938 0.2995974 ]]Network training:  60%|████████████████▏          | 3/5 [03:18<02:12, 66.10s/epoch(s), Training loss(es)=[0.2820056  0.26739752 0.34589815 0.27225643 0.2644157 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:18<00:49, 49.57s/epoch(s), Training loss(es)=[0.2820056  0.26739752 0.34589815 0.27225643 0.2644157 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:06<01:01, 61.56s/epoch(s), Training loss(es)=[0.34489003 0.2487578  0.262713   0.24476536 0.26132342]]Network training: 100%|███████████████████████████| 5/5 [04:06<00:00, 49.25s/epoch(s), Training loss(es)=[0.34489003 0.2487578  0.262713   0.24476536 0.26132342]]
####################################################################
Starting training iteration 200.
Average action selection time:  0.21743664598464965
Rollout length:  1000
Rewards obtained: [13340.044337674639]
model train lenght 201000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:26<?, ?epoch(s)/s, Training loss(es)=[0.27755466 0.24754405 0.24123265 0.2661075  0.34572917]]Network training:  20%|█████▍                     | 1/5 [00:26<01:44, 26.14s/epoch(s), Training loss(es)=[0.27755466 0.24754405 0.24123265 0.2661075  0.34572917]]Network training:  20%|█████▍                     | 1/5 [01:25<05:42, 85.62s/epoch(s), Training loss(es)=[0.27512643 0.32576102 0.25680128 0.27097473 0.2920606 ]]Network training:  40%|██████████▊                | 2/5 [01:25<02:08, 42.81s/epoch(s), Training loss(es)=[0.27512643 0.32576102 0.25680128 0.27097473 0.2920606 ]]Network training:  40%|██████████▊                | 2/5 [02:26<03:39, 73.27s/epoch(s), Training loss(es)=[0.2593018  0.27046984 0.31484735 0.27888337 0.31986865]]Network training:  60%|████████████████▏          | 3/5 [02:26<01:37, 48.85s/epoch(s), Training loss(es)=[0.2593018  0.27046984 0.31484735 0.27888337 0.31986865]]Network training:  60%|████████████████▏          | 3/5 [03:27<02:18, 69.19s/epoch(s), Training loss(es)=[0.29985362 0.26719162 0.38016537 0.28091645 0.25951412]]Network training:  80%|█████████████████████▌     | 4/5 [03:27<00:51, 51.89s/epoch(s), Training loss(es)=[0.29985362 0.26719162 0.38016537 0.28091645 0.25951412]]Network training:  80%|█████████████████████▌     | 4/5 [04:10<01:02, 62.66s/epoch(s), Training loss(es)=[0.29427037 0.24665684 0.25492978 0.28842518 0.29345715]]Network training: 100%|███████████████████████████| 5/5 [04:10<00:00, 50.13s/epoch(s), Training loss(es)=[0.29427037 0.24665684 0.25492978 0.28842518 0.29345715]]
####################################################################
Starting training iteration 201.
Average action selection time:  0.21740863347053527
Rollout length:  1000
Rewards obtained: [6465.185405622623]
model train lenght 202000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:33<?, ?epoch(s)/s, Training loss(es)=[0.29572013 0.27789813 0.29278398 0.2722647  0.31061026]]Network training:  20%|█████▍                     | 1/5 [00:33<02:12, 33.02s/epoch(s), Training loss(es)=[0.29572013 0.27789813 0.29278398 0.2722647  0.31061026]]Network training:  20%|█████▍                     | 1/5 [01:34<06:17, 94.40s/epoch(s), Training loss(es)=[0.31635234 0.29398668 0.29306698 0.2562431  0.26052254]]Network training:  40%|██████████▊                | 2/5 [01:34<02:21, 47.20s/epoch(s), Training loss(es)=[0.31635234 0.29398668 0.29306698 0.2562431  0.26052254]]Network training:  40%|██████████▊                | 2/5 [02:35<03:53, 77.83s/epoch(s), Training loss(es)=[0.2737739  0.31816977 0.30365446 0.32409522 0.27602872]]Network training:  60%|████████████████▏          | 3/5 [02:35<01:43, 51.89s/epoch(s), Training loss(es)=[0.2737739  0.31816977 0.30365446 0.32409522 0.27602872]]Network training:  60%|████████████████▏          | 3/5 [03:37<02:24, 72.37s/epoch(s), Training loss(es)=[0.2540073  0.24349988 0.25636768 0.30237812 0.280813  ]]Network training:  80%|█████████████████████▌     | 4/5 [03:37<00:54, 54.27s/epoch(s), Training loss(es)=[0.2540073  0.24349988 0.25636768 0.30237812 0.280813  ]]Network training:  80%|█████████████████████▌     | 4/5 [04:10<01:02, 62.73s/epoch(s), Training loss(es)=[0.26557985 0.2984073  0.2635846  0.21782441 0.26251224]]Network training: 100%|███████████████████████████| 5/5 [04:10<00:00, 50.18s/epoch(s), Training loss(es)=[0.26557985 0.2984073  0.2635846  0.21782441 0.26251224]]
####################################################################
Starting training iteration 202.
Average action selection time:  0.2174125406742096
Rollout length:  1000
Rewards obtained: [12377.172932240124]
model train lenght 203000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:38<?, ?epoch(s)/s, Training loss(es)=[0.30665824 0.306899   0.24859898 0.22387908 0.25318843]]Network training:  20%|█████▍                     | 1/5 [00:38<02:33, 38.49s/epoch(s), Training loss(es)=[0.30665824 0.306899   0.24859898 0.22387908 0.25318843]]Network training:  20%|█████▏                    | 1/5 [01:40<06:40, 100.08s/epoch(s), Training loss(es)=[0.259297   0.2998529  0.28435048 0.27361625 0.38479337]]Network training:  40%|██████████▊                | 2/5 [01:40<02:30, 50.04s/epoch(s), Training loss(es)=[0.259297   0.2998529  0.28435048 0.27361625 0.38479337]]Network training:  40%|██████████▊                | 2/5 [02:41<04:02, 80.83s/epoch(s), Training loss(es)=[0.2613626  0.27374154 0.30102566 0.2600874  0.2522423 ]]Network training:  60%|████████████████▏          | 3/5 [02:41<01:47, 53.89s/epoch(s), Training loss(es)=[0.2613626  0.27374154 0.30102566 0.2600874  0.2522423 ]]Network training:  60%|████████████████▏          | 3/5 [03:43<02:28, 74.47s/epoch(s), Training loss(es)=[0.25474516 0.28944674 0.43852338 0.33075225 0.29608276]]Network training:  80%|█████████████████████▌     | 4/5 [03:43<00:55, 55.85s/epoch(s), Training loss(es)=[0.25474516 0.28944674 0.43852338 0.33075225 0.29608276]]Network training:  80%|█████████████████████▌     | 4/5 [04:11<01:02, 62.78s/epoch(s), Training loss(es)=[0.29089552 0.24791528 0.28067577 0.25683427 0.25745082]]Network training: 100%|███████████████████████████| 5/5 [04:11<00:00, 50.23s/epoch(s), Training loss(es)=[0.29089552 0.24791528 0.28067577 0.25683427 0.25745082]]
####################################################################
Starting training iteration 203.
Average action selection time:  0.21752527213096617
Rollout length:  1000
Rewards obtained: [10778.465967181115]
model train lenght 204000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:39<?, ?epoch(s)/s, Training loss(es)=[0.27044755 0.3397171  0.25010255 0.3088411  0.27540624]]Network training:  20%|█████▍                     | 1/5 [00:39<02:37, 39.49s/epoch(s), Training loss(es)=[0.27044755 0.3397171  0.25010255 0.3088411  0.27540624]]Network training:  20%|█████▏                    | 1/5 [01:41<06:45, 101.45s/epoch(s), Training loss(es)=[0.28598058 0.29068035 0.29113084 0.2819978  0.25954565]]Network training:  40%|██████████▊                | 2/5 [01:41<02:32, 50.73s/epoch(s), Training loss(es)=[0.28598058 0.29068035 0.29113084 0.2819978  0.25954565]]Network training:  40%|██████████▊                | 2/5 [02:43<04:04, 81.67s/epoch(s), Training loss(es)=[0.28836378 0.31350932 0.32081679 0.2901935  0.23859668]]Network training:  60%|████████████████▏          | 3/5 [02:43<01:48, 54.44s/epoch(s), Training loss(es)=[0.28836378 0.31350932 0.32081679 0.2901935  0.23859668]]Network training:  60%|████████████████▏          | 3/5 [03:44<02:29, 74.84s/epoch(s), Training loss(es)=[0.2770296  0.3115124  0.27688766 0.3112869  0.28431153]]Network training:  80%|█████████████████████▌     | 4/5 [03:44<00:56, 56.13s/epoch(s), Training loss(es)=[0.2770296  0.3115124  0.27688766 0.3112869  0.28431153]]Network training:  80%|█████████████████████▌     | 4/5 [04:10<01:02, 62.69s/epoch(s), Training loss(es)=[0.26454088 0.3143065  0.27708277 0.29877514 0.24816918]]Network training: 100%|███████████████████████████| 5/5 [04:10<00:00, 50.15s/epoch(s), Training loss(es)=[0.26454088 0.3143065  0.27708277 0.29877514 0.24816918]]
####################################################################
Starting training iteration 204.
Average action selection time:  0.21745369172096252
Rollout length:  1000
Rewards obtained: [6951.516830730495]
model train lenght 205000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:41<?, ?epoch(s)/s, Training loss(es)=[0.35149214 0.32749715 0.29308474 0.2352228  0.24861011]]Network training:  20%|█████▍                     | 1/5 [00:41<02:46, 41.52s/epoch(s), Training loss(es)=[0.35149214 0.32749715 0.29308474 0.2352228  0.24861011]]Network training:  20%|█████▏                    | 1/5 [01:43<06:54, 103.69s/epoch(s), Training loss(es)=[0.3498535  0.25755185 0.27193183 0.25869045 0.2630548 ]]Network training:  40%|██████████▊                | 2/5 [01:43<02:35, 51.84s/epoch(s), Training loss(es)=[0.3498535  0.25755185 0.27193183 0.25869045 0.2630548 ]]Network training:  40%|██████████▊                | 2/5 [02:45<04:08, 82.99s/epoch(s), Training loss(es)=[0.331517   0.316318   0.27697247 0.2710257  0.33681595]]Network training:  60%|████████████████▏          | 3/5 [02:45<01:50, 55.33s/epoch(s), Training loss(es)=[0.331517   0.316318   0.27697247 0.2710257  0.33681595]]Network training:  60%|████████████████▏          | 3/5 [03:45<02:30, 75.10s/epoch(s), Training loss(es)=[0.2751845  0.2559197  0.25217706 0.26295194 0.28240624]]Network training:  80%|█████████████████████▌     | 4/5 [03:45<00:56, 56.33s/epoch(s), Training loss(es)=[0.2751845  0.2559197  0.25217706 0.26295194 0.28240624]]Network training:  80%|█████████████████████▌     | 4/5 [04:12<01:03, 63.17s/epoch(s), Training loss(es)=[0.3104947  0.40017134 0.30503622 0.2729347  0.26220223]]Network training: 100%|███████████████████████████| 5/5 [04:12<00:00, 50.54s/epoch(s), Training loss(es)=[0.3104947  0.40017134 0.30503622 0.2729347  0.26220223]]
####################################################################
Starting training iteration 205.
Average action selection time:  0.21750325775146484
Rollout length:  1000
Rewards obtained: [11883.664472265888]
model train lenght 206000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:49<?, ?epoch(s)/s, Training loss(es)=[0.281103   0.2778371  0.37530702 0.2839533  0.25566795]]Network training:  20%|█████▍                     | 1/5 [00:49<03:17, 49.41s/epoch(s), Training loss(es)=[0.281103   0.2778371  0.37530702 0.2839533  0.25566795]]Network training:  20%|█████▏                    | 1/5 [01:51<07:27, 111.91s/epoch(s), Training loss(es)=[0.37935242 0.2785349  0.29045835 0.27340126 0.3954418 ]]Network training:  40%|██████████▊                | 2/5 [01:51<02:47, 55.95s/epoch(s), Training loss(es)=[0.37935242 0.2785349  0.29045835 0.27340126 0.3954418 ]]Network training:  40%|██████████▊                | 2/5 [02:54<04:21, 87.24s/epoch(s), Training loss(es)=[0.30485865 0.3028617  0.2805479  0.3034318  0.28521752]]Network training:  60%|████████████████▏          | 3/5 [02:54<01:56, 58.16s/epoch(s), Training loss(es)=[0.30485865 0.3028617  0.2805479  0.3034318  0.28521752]]Network training:  60%|████████████████▏          | 3/5 [03:45<02:30, 75.32s/epoch(s), Training loss(es)=[0.35376987 0.32028636 0.29403794 0.2928034  0.2956838 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:45<00:56, 56.49s/epoch(s), Training loss(es)=[0.35376987 0.32028636 0.29403794 0.2928034  0.2956838 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:12<01:03, 63.03s/epoch(s), Training loss(es)=[0.26900747 0.28999257 0.29138175 0.2912189  0.28764832]]Network training: 100%|███████████████████████████| 5/5 [04:12<00:00, 50.42s/epoch(s), Training loss(es)=[0.26900747 0.28999257 0.29138175 0.2912189  0.28764832]]
####################################################################
Starting training iteration 206.
Average action selection time:  0.21751498270034791
Rollout length:  1000
Rewards obtained: [10810.570940029138]
model train lenght 207000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:51<?, ?epoch(s)/s, Training loss(es)=[0.2695836  0.30962592 0.24901868 0.28895265 0.28289515]]Network training:  20%|█████▍                     | 1/5 [00:51<03:24, 51.20s/epoch(s), Training loss(es)=[0.2695836  0.30962592 0.24901868 0.28895265 0.28289515]]Network training:  20%|█████▏                    | 1/5 [01:54<07:36, 114.06s/epoch(s), Training loss(es)=[0.299611   0.29375064 0.26308432 0.29092485 0.28134513]]Network training:  40%|██████████▊                | 2/5 [01:54<02:51, 57.03s/epoch(s), Training loss(es)=[0.299611   0.29375064 0.26308432 0.29092485 0.28134513]]Network training:  40%|██████████▊                | 2/5 [02:56<04:25, 88.49s/epoch(s), Training loss(es)=[0.33499962 0.27047423 0.29101247 0.3306838  0.25756133]]Network training:  60%|████████████████▏          | 3/5 [02:56<01:57, 58.99s/epoch(s), Training loss(es)=[0.33499962 0.27047423 0.29101247 0.3306838  0.25756133]]Network training:  60%|████████████████▏          | 3/5 [03:47<02:31, 75.70s/epoch(s), Training loss(es)=[0.3101786  0.29600608 0.2722295  0.29099476 0.2823933 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:47<00:56, 56.77s/epoch(s), Training loss(es)=[0.3101786  0.29600608 0.2722295  0.29099476 0.2823933 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:15<01:03, 63.88s/epoch(s), Training loss(es)=[0.27422225 0.25875595 0.24177085 0.2423402  0.2752543 ]]Network training: 100%|███████████████████████████| 5/5 [04:15<00:00, 51.11s/epoch(s), Training loss(es)=[0.27422225 0.25875595 0.24177085 0.2423402  0.2752543 ]]
####################################################################
Starting training iteration 207.
Average action selection time:  0.2176693570613861
Rollout length:  1000
Rewards obtained: [6113.14120602585]
model train lenght 208000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:00<?, ?epoch(s)/s, Training loss(es)=[0.29300445 0.3285836  0.2937373  0.3221428  0.2532538 ]]Network training:  20%|█████▍                     | 1/5 [01:00<04:02, 60.70s/epoch(s), Training loss(es)=[0.29300445 0.3285836  0.2937373  0.3221428  0.2532538 ]]Network training:  20%|█████▏                    | 1/5 [02:03<08:15, 123.93s/epoch(s), Training loss(es)=[0.29517794 0.2829553  0.3135609  0.27102545 0.2827721 ]]Network training:  40%|██████████▊                | 2/5 [02:03<03:05, 61.97s/epoch(s), Training loss(es)=[0.29517794 0.2829553  0.3135609  0.27102545 0.2827721 ]]Network training:  40%|██████████▊                | 2/5 [03:07<04:40, 93.58s/epoch(s), Training loss(es)=[0.29262596 0.29544735 0.26815236 0.2766508  0.29064533]]Network training:  60%|████████████████▏          | 3/5 [03:07<02:04, 62.39s/epoch(s), Training loss(es)=[0.29262596 0.29544735 0.26815236 0.2766508  0.29064533]]Network training:  60%|████████████████▏          | 3/5 [03:48<02:32, 76.21s/epoch(s), Training loss(es)=[0.28185093 0.30622935 0.26916203 0.27023652 0.2811559 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:48<00:57, 57.15s/epoch(s), Training loss(es)=[0.28185093 0.30622935 0.26916203 0.27023652 0.2811559 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:14<01:03, 63.71s/epoch(s), Training loss(es)=[0.26479003 0.31141877 0.25076625 0.2626842  0.29227313]]Network training: 100%|███████████████████████████| 5/5 [04:14<00:00, 50.97s/epoch(s), Training loss(es)=[0.26479003 0.31141877 0.25076625 0.2626842  0.29227313]]
####################################################################
Starting training iteration 208.
Average action selection time:  0.21949365520477296
Rollout length:  1000
Rewards obtained: [12640.292311816103]
model train lenght 209000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:03<?, ?epoch(s)/s, Training loss(es)=[0.32851705 0.29299676 0.30812374 0.2998319  0.26945734]]Network training:  20%|█████▍                     | 1/5 [01:03<04:13, 63.38s/epoch(s), Training loss(es)=[0.32851705 0.29299676 0.30812374 0.2998319  0.26945734]]Network training:  20%|█████▏                    | 1/5 [02:06<08:27, 126.88s/epoch(s), Training loss(es)=[0.30474654 0.26098505 0.26954103 0.32543737 0.37553266]]Network training:  40%|██████████▊                | 2/5 [02:06<03:10, 63.44s/epoch(s), Training loss(es)=[0.30474654 0.26098505 0.26954103 0.32543737 0.37553266]]Network training:  40%|██████████▊                | 2/5 [03:10<04:45, 95.19s/epoch(s), Training loss(es)=[0.50389826 0.27036494 0.25497675 0.2666339  0.2627325 ]]Network training:  60%|████████████████▏          | 3/5 [03:10<02:06, 63.46s/epoch(s), Training loss(es)=[0.50389826 0.27036494 0.25497675 0.2666339  0.2627325 ]]Network training:  60%|████████████████▏          | 3/5 [03:47<02:31, 75.76s/epoch(s), Training loss(es)=[0.29383478 0.2702937  0.31790876 0.27879745 0.27774623]]Network training:  80%|█████████████████████▌     | 4/5 [03:47<00:56, 56.82s/epoch(s), Training loss(es)=[0.29383478 0.2702937  0.31790876 0.27879745 0.27774623]]Network training:  80%|█████████████████████▌     | 4/5 [04:12<01:03, 63.23s/epoch(s), Training loss(es)=[0.3246715  0.3042507  0.29173365 0.27574533 0.26788244]]Network training: 100%|███████████████████████████| 5/5 [04:12<00:00, 50.58s/epoch(s), Training loss(es)=[0.3246715  0.3042507  0.29173365 0.27574533 0.26788244]]
####################################################################
Starting training iteration 209.
Average action selection time:  0.22213671898841858
Rollout length:  1000
Rewards obtained: [17390.137276675476]
model train lenght 210000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:03<?, ?epoch(s)/s, Training loss(es)=[0.2933295  0.2696021  0.3162854  0.31219858 0.3064708 ]]Network training:  20%|█████▍                     | 1/5 [01:03<04:15, 63.88s/epoch(s), Training loss(es)=[0.2933295  0.2696021  0.3162854  0.31219858 0.3064708 ]]Network training:  20%|█████▏                    | 1/5 [02:07<08:30, 127.69s/epoch(s), Training loss(es)=[0.3103893  0.27645326 0.2834654  0.29491404 0.2789958 ]]Network training:  40%|██████████▊                | 2/5 [02:07<03:11, 63.84s/epoch(s), Training loss(es)=[0.3103893  0.27645326 0.2834654  0.29491404 0.2789958 ]]Network training:  40%|██████████▊                | 2/5 [03:11<04:47, 95.77s/epoch(s), Training loss(es)=[0.27067408 0.2702179  0.27249017 0.26752603 0.27646977]]Network training:  60%|████████████████▏          | 3/5 [03:11<02:07, 63.85s/epoch(s), Training loss(es)=[0.27067408 0.2702179  0.27249017 0.26752603 0.27646977]]Network training:  60%|████████████████▏          | 3/5 [03:44<02:29, 74.69s/epoch(s), Training loss(es)=[0.3283206  0.3191798  0.260752   0.32775712 0.3628685 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:44<00:56, 56.02s/epoch(s), Training loss(es)=[0.3283206  0.3191798  0.260752   0.32775712 0.3628685 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:11<01:02, 62.91s/epoch(s), Training loss(es)=[0.3030072  0.25921154 0.27651343 0.29624116 0.27046722]]Network training: 100%|███████████████████████████| 5/5 [04:11<00:00, 50.32s/epoch(s), Training loss(es)=[0.3030072  0.25921154 0.27651343 0.29624116 0.27046722]]
####################################################################
Starting training iteration 210.
Average action selection time:  0.22336351585388184
Rollout length:  1000
Rewards obtained: [7920.4450114206265]
model train lenght 211000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:03<?, ?epoch(s)/s, Training loss(es)=[0.3416651  0.27944657 0.26052934 0.2329601  0.2808199 ]]Network training:  20%|█████▍                     | 1/5 [01:03<04:15, 64.00s/epoch(s), Training loss(es)=[0.3416651  0.27944657 0.26052934 0.2329601  0.2808199 ]]Network training:  20%|█████▏                    | 1/5 [02:08<08:32, 128.12s/epoch(s), Training loss(es)=[0.5223185  0.30172616 0.2608675  0.32544202 0.3580274 ]]Network training:  40%|██████████▊                | 2/5 [02:08<03:12, 64.06s/epoch(s), Training loss(es)=[0.5223185  0.30172616 0.2608675  0.32544202 0.3580274 ]]Network training:  40%|██████████▊                | 2/5 [03:12<04:48, 96.07s/epoch(s), Training loss(es)=[0.42528197 0.28159145 0.407836   0.32558638 0.27800313]]Network training:  60%|████████████████▏          | 3/5 [03:12<02:08, 64.05s/epoch(s), Training loss(es)=[0.42528197 0.28159145 0.407836   0.32558638 0.27800313]]Network training:  60%|████████████████▏          | 3/5 [03:44<02:29, 74.73s/epoch(s), Training loss(es)=[0.29695383 0.30179995 0.28533313 0.2510645  0.29481852]]Network training:  80%|█████████████████████▌     | 4/5 [03:44<00:56, 56.05s/epoch(s), Training loss(es)=[0.29695383 0.30179995 0.28533313 0.2510645  0.29481852]]Network training:  80%|█████████████████████▌     | 4/5 [04:11<01:02, 62.82s/epoch(s), Training loss(es)=[0.26631314 0.27707002 0.23375317 0.25401247 0.28220648]]Network training: 100%|███████████████████████████| 5/5 [04:11<00:00, 50.25s/epoch(s), Training loss(es)=[0.26631314 0.27707002 0.23375317 0.25401247 0.28220648]]
####################################################################
Starting training iteration 211.
Average action selection time:  0.22634965896606446
Rollout length:  1000
Rewards obtained: [14062.831388625356]
model train lenght 212000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:04<?, ?epoch(s)/s, Training loss(es)=[0.30184105 0.29639307 0.31151962 0.25469384 0.3022879 ]]Network training:  20%|█████▍                     | 1/5 [01:04<04:17, 64.32s/epoch(s), Training loss(es)=[0.30184105 0.29639307 0.31151962 0.25469384 0.3022879 ]]Network training:  20%|█████▏                    | 1/5 [02:08<08:34, 128.57s/epoch(s), Training loss(es)=[0.2699729  0.27741307 0.29437688 0.31059015 0.2973325 ]]Network training:  40%|██████████▊                | 2/5 [02:08<03:12, 64.28s/epoch(s), Training loss(es)=[0.2699729  0.27741307 0.29437688 0.31059015 0.2973325 ]]Network training:  40%|██████████▊                | 2/5 [03:12<04:49, 96.47s/epoch(s), Training loss(es)=[0.30649716 0.28056836 0.27190876 0.2664151  0.40309983]]Network training:  60%|████████████████▏          | 3/5 [03:12<02:08, 64.31s/epoch(s), Training loss(es)=[0.30649716 0.28056836 0.27190876 0.2664151  0.40309983]]Network training:  60%|████████████████▏          | 3/5 [03:41<02:27, 73.80s/epoch(s), Training loss(es)=[0.35959965 0.28432357 0.26653808 0.29998097 0.3681841 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:41<00:55, 55.35s/epoch(s), Training loss(es)=[0.35959965 0.28432357 0.26653808 0.29998097 0.3681841 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:09<01:02, 62.48s/epoch(s), Training loss(es)=[0.2511806  0.28380692 0.317411   0.28080946 0.2503652 ]]Network training: 100%|███████████████████████████| 5/5 [04:09<00:00, 49.98s/epoch(s), Training loss(es)=[0.2511806  0.28380692 0.317411   0.28080946 0.2503652 ]]
####################################################################
Starting training iteration 212.
Average action selection time:  0.23067527556419373
Rollout length:  1000
Rewards obtained: [8454.174853713732]
model train lenght 213000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:04<?, ?epoch(s)/s, Training loss(es)=[0.29954663 0.28830004 0.33713531 0.31626454 0.2892815 ]]Network training:  20%|█████▍                     | 1/5 [01:04<04:18, 64.59s/epoch(s), Training loss(es)=[0.29954663 0.28830004 0.33713531 0.31626454 0.2892815 ]]Network training:  20%|█████▏                    | 1/5 [02:09<08:37, 129.37s/epoch(s), Training loss(es)=[0.2661738  0.31846383 0.32901746 0.32526433 0.29764006]]Network training:  40%|██████████▊                | 2/5 [02:09<03:14, 64.68s/epoch(s), Training loss(es)=[0.2661738  0.31846383 0.32901746 0.32526433 0.29764006]]Network training:  40%|████████████▊                   | 2/5 [03:12<04:48, 96.27s/epoch(s), Training loss(es)=[0.3349012 0.2842262 0.2472912 0.279724  0.3118623]]Network training:  60%|███████████████████▏            | 3/5 [03:12<02:08, 64.18s/epoch(s), Training loss(es)=[0.3349012 0.2842262 0.2472912 0.279724  0.3118623]]Network training:  60%|████████████████▏          | 3/5 [03:41<02:27, 73.80s/epoch(s), Training loss(es)=[0.3509516  0.2840747  0.38001114 0.2892546  0.3339856 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:41<00:55, 55.35s/epoch(s), Training loss(es)=[0.3509516  0.2840747  0.38001114 0.2892546  0.3339856 ]]Network training:  80%|█████████████████████▌     | 4/5 [04:10<01:02, 62.57s/epoch(s), Training loss(es)=[0.25886935 0.26028356 0.24652307 0.33894128 0.27817446]]Network training: 100%|███████████████████████████| 5/5 [04:10<00:00, 50.06s/epoch(s), Training loss(es)=[0.25886935 0.26028356 0.24652307 0.33894128 0.27817446]]
####################################################################
Starting training iteration 213.
Average action selection time:  0.24572353482246398
Rollout length:  1000
Rewards obtained: [12163.075936241792]
model train lenght 214000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:05<?, ?epoch(s)/s, Training loss(es)=[0.33203855 0.2703998  0.30308485 0.34175918 0.2801074 ]]Network training:  20%|█████▍                     | 1/5 [01:05<04:20, 65.03s/epoch(s), Training loss(es)=[0.33203855 0.2703998  0.30308485 0.34175918 0.2801074 ]]Network training:  20%|█████▏                    | 1/5 [02:10<08:40, 130.05s/epoch(s), Training loss(es)=[0.25345093 0.32643324 0.27641502 0.255177   0.2756098 ]]Network training:  40%|██████████▊                | 2/5 [02:10<03:15, 65.02s/epoch(s), Training loss(es)=[0.25345093 0.32643324 0.27641502 0.255177   0.2756098 ]]Network training:  40%|██████████▊                | 2/5 [03:01<04:32, 90.68s/epoch(s), Training loss(es)=[0.27259147 0.30619746 0.28282106 0.3306348  0.2795767 ]]Network training:  60%|████████████████▏          | 3/5 [03:01<02:00, 60.46s/epoch(s), Training loss(es)=[0.27259147 0.30619746 0.28282106 0.3306348  0.2795767 ]]Network training:  60%|████████████████▏          | 3/5 [03:27<02:18, 69.33s/epoch(s), Training loss(es)=[0.31152633 0.2987958  0.26445785 0.26227129 0.35143447]]Network training:  80%|█████████████████████▌     | 4/5 [03:27<00:51, 52.00s/epoch(s), Training loss(es)=[0.31152633 0.2987958  0.26445785 0.26227129 0.35143447]]Network training:  80%|█████████████████████▌     | 4/5 [03:54<00:58, 58.68s/epoch(s), Training loss(es)=[0.30709976 0.34022182 0.2644922  0.2801563  0.29546592]]Network training: 100%|███████████████████████████| 5/5 [03:54<00:00, 46.94s/epoch(s), Training loss(es)=[0.30709976 0.34022182 0.2644922  0.2801563  0.29546592]]
####################################################################
Starting training iteration 214.
Average action selection time:  0.24016547179222106
Rollout length:  1000
Rewards obtained: [13021.360339290291]
model train lenght 215000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:05<?, ?epoch(s)/s, Training loss(es)=[0.26601744 0.28493077 0.33780757 0.29741377 0.3310679 ]]Network training:  20%|█████▍                     | 1/5 [01:05<04:20, 65.22s/epoch(s), Training loss(es)=[0.26601744 0.28493077 0.33780757 0.29741377 0.3310679 ]]Network training:  20%|█████▏                    | 1/5 [02:10<08:41, 130.40s/epoch(s), Training loss(es)=[0.32031617 0.26897478 0.32148424 0.355557   0.2865197 ]]Network training:  40%|██████████▊                | 2/5 [02:10<03:15, 65.20s/epoch(s), Training loss(es)=[0.32031617 0.26897478 0.32148424 0.355557   0.2865197 ]]Network training:  40%|██████████▊                | 2/5 [03:06<04:39, 93.20s/epoch(s), Training loss(es)=[0.26005003 0.34858653 0.31516808 0.29841027 0.29301757]]Network training:  60%|████████████████▏          | 3/5 [03:06<02:04, 62.13s/epoch(s), Training loss(es)=[0.26005003 0.34858653 0.31516808 0.29841027 0.29301757]]Network training:  60%|████████████████▏          | 3/5 [03:34<02:22, 71.36s/epoch(s), Training loss(es)=[0.30980843 0.28989083 0.28288215 0.2875585  0.27508202]]Network training:  80%|█████████████████████▌     | 4/5 [03:34<00:53, 53.52s/epoch(s), Training loss(es)=[0.30980843 0.28989083 0.28288215 0.2875585  0.27508202]]Network training:  80%|█████████████████████▌     | 4/5 [04:01<01:00, 60.32s/epoch(s), Training loss(es)=[0.29110363 0.2918807  0.2677011  0.27548805 0.2863299 ]]Network training: 100%|███████████████████████████| 5/5 [04:01<00:00, 48.26s/epoch(s), Training loss(es)=[0.29110363 0.2918807  0.2677011  0.27548805 0.2863299 ]]
####################################################################
Starting training iteration 215.
Average action selection time:  0.24137524914741515
Rollout length:  1000
Rewards obtained: [11173.791492741413]
model train lenght 216000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:05<?, ?epoch(s)/s, Training loss(es)=[0.31805634 0.37681615 0.32099068 0.30497667 0.337974  ]]Network training:  20%|█████▍                     | 1/5 [01:05<04:22, 65.51s/epoch(s), Training loss(es)=[0.31805634 0.37681615 0.32099068 0.30497667 0.337974  ]]Network training:  20%|█████▏                    | 1/5 [02:11<08:44, 131.05s/epoch(s), Training loss(es)=[0.2763896  0.29949376 0.27465138 0.5088036  0.2832929 ]]Network training:  40%|██████████▊                | 2/5 [02:11<03:16, 65.52s/epoch(s), Training loss(es)=[0.2763896  0.29949376 0.27465138 0.5088036  0.2832929 ]]Network training:  40%|██████████▊                | 2/5 [03:05<04:38, 92.85s/epoch(s), Training loss(es)=[0.2670317  0.28679654 0.38301954 0.3072092  0.27079687]]Network training:  60%|████████████████▏          | 3/5 [03:05<02:03, 61.90s/epoch(s), Training loss(es)=[0.2670317  0.28679654 0.38301954 0.3072092  0.27079687]]Network training:  60%|████████████████▏          | 3/5 [03:34<02:23, 71.60s/epoch(s), Training loss(es)=[0.301894   0.31991845 0.27030525 0.30067617 0.25702417]]Network training:  80%|█████████████████████▌     | 4/5 [03:34<00:53, 53.70s/epoch(s), Training loss(es)=[0.301894   0.31991845 0.27030525 0.30067617 0.25702417]]Network training:  80%|█████████████████████▌     | 4/5 [04:02<01:00, 60.64s/epoch(s), Training loss(es)=[0.25220817 0.28971657 0.28384915 0.32950482 0.26825774]]Network training: 100%|███████████████████████████| 5/5 [04:02<00:00, 48.51s/epoch(s), Training loss(es)=[0.25220817 0.28971657 0.28384915 0.32950482 0.26825774]]
####################################################################
Starting training iteration 216.
Average action selection time:  0.25257513332366943
Rollout length:  1000
Rewards obtained: [13529.631519087945]
model train lenght 217000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:05<?, ?epoch(s)/s, Training loss(es)=[0.41805714 0.35155785 0.30040357 0.30518207 0.28359318]]Network training:  20%|█████▍                     | 1/5 [01:05<04:23, 65.82s/epoch(s), Training loss(es)=[0.41805714 0.35155785 0.30040357 0.30518207 0.28359318]]Network training:  20%|█████▏                    | 1/5 [02:11<08:46, 131.66s/epoch(s), Training loss(es)=[0.36575434 0.26604292 0.29495177 0.28183436 0.30455607]]Network training:  40%|██████████▊                | 2/5 [02:11<03:17, 65.83s/epoch(s), Training loss(es)=[0.36575434 0.26604292 0.29495177 0.28183436 0.30455607]]Network training:  40%|██████████▊                | 2/5 [02:58<04:27, 89.05s/epoch(s), Training loss(es)=[0.26998216 0.29396427 0.29867142 0.33178186 0.28648028]]Network training:  60%|████████████████▏          | 3/5 [02:58<01:58, 59.36s/epoch(s), Training loss(es)=[0.26998216 0.29396427 0.29867142 0.33178186 0.28648028]]Network training:  60%|████████████████▏          | 3/5 [03:27<02:18, 69.01s/epoch(s), Training loss(es)=[0.27568012 0.34638998 0.2723984  0.26286322 0.30869392]]Network training:  80%|█████████████████████▌     | 4/5 [03:27<00:51, 51.76s/epoch(s), Training loss(es)=[0.27568012 0.34638998 0.2723984  0.26286322 0.30869392]]Network training:  80%|█████████████████████▌     | 4/5 [03:56<00:59, 59.06s/epoch(s), Training loss(es)=[0.32728788 0.287413   0.32210872 0.2615416  0.27350265]]Network training: 100%|███████████████████████████| 5/5 [03:56<00:00, 47.25s/epoch(s), Training loss(es)=[0.32728788 0.287413   0.32210872 0.2615416  0.27350265]]
####################################################################
Starting training iteration 217.
Average action selection time:  0.26895491218566897
Rollout length:  1000
Rewards obtained: [16678.261540847936]
model train lenght 218000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:06<?, ?epoch(s)/s, Training loss(es)=[0.3129729  0.2777632  0.36705187 0.25322232 0.33719662]]Network training:  20%|█████▍                     | 1/5 [01:06<04:24, 66.24s/epoch(s), Training loss(es)=[0.3129729  0.2777632  0.36705187 0.25322232 0.33719662]]Network training:  20%|█████▏                    | 1/5 [02:12<08:49, 132.42s/epoch(s), Training loss(es)=[0.34939846 0.3170333  0.28612593 0.36091688 0.35073653]]Network training:  40%|██████████▊                | 2/5 [02:12<03:18, 66.21s/epoch(s), Training loss(es)=[0.34939846 0.3170333  0.28612593 0.36091688 0.35073653]]Network training:  40%|██████████▊                | 2/5 [02:45<04:08, 82.97s/epoch(s), Training loss(es)=[0.30294138 0.28765497 0.28840685 0.3299707  0.3067115 ]]Network training:  60%|████████████████▏          | 3/5 [02:45<01:50, 55.32s/epoch(s), Training loss(es)=[0.30294138 0.28765497 0.28840685 0.3299707  0.3067115 ]]Network training:  60%|████████████████▏          | 3/5 [03:15<02:10, 65.09s/epoch(s), Training loss(es)=[0.32738912 0.32482347 0.3025477  0.29842985 0.35780156]]Network training:  80%|█████████████████████▌     | 4/5 [03:15<00:48, 48.82s/epoch(s), Training loss(es)=[0.32738912 0.32482347 0.3025477  0.29842985 0.35780156]]Network training:  80%|█████████████████████▌     | 4/5 [03:44<00:56, 56.09s/epoch(s), Training loss(es)=[0.2692899  0.30469838 0.27173454 0.29547253 0.28481925]]Network training: 100%|███████████████████████████| 5/5 [03:44<00:00, 44.87s/epoch(s), Training loss(es)=[0.2692899  0.30469838 0.27173454 0.29547253 0.28481925]]
####################################################################
Starting training iteration 218.
Average action selection time:  0.2862181651592255
Rollout length:  1000
Rewards obtained: [6596.330595725557]
model train lenght 219000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:06<?, ?epoch(s)/s, Training loss(es)=[0.30873424 0.28900835 0.2965021  0.28535298 0.3288968 ]]Network training:  20%|█████▍                     | 1/5 [01:06<04:25, 66.49s/epoch(s), Training loss(es)=[0.30873424 0.28900835 0.2965021  0.28535298 0.3288968 ]]Network training:  20%|█████▏                    | 1/5 [02:04<08:19, 124.91s/epoch(s), Training loss(es)=[0.30910036 0.28816608 0.24773672 0.2806622  0.26678258]]Network training:  40%|██████████▊                | 2/5 [02:04<03:07, 62.46s/epoch(s), Training loss(es)=[0.30910036 0.28816608 0.24773672 0.2806622  0.26678258]]Network training:  40%|██████████▊                | 2/5 [02:32<03:49, 76.40s/epoch(s), Training loss(es)=[0.31373447 0.29972696 0.283969   0.27963674 0.28033304]]Network training:  60%|████████████████▏          | 3/5 [02:32<01:41, 50.94s/epoch(s), Training loss(es)=[0.31373447 0.29972696 0.283969   0.27963674 0.28033304]]Network training:  60%|████████████████▏          | 3/5 [02:59<01:59, 59.97s/epoch(s), Training loss(es)=[0.3312889  0.2825583  0.25449798 0.29769766 0.3203243 ]]Network training:  80%|█████████████████████▌     | 4/5 [02:59<00:44, 44.98s/epoch(s), Training loss(es)=[0.3312889  0.2825583  0.25449798 0.29769766 0.3203243 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:26<00:51, 51.61s/epoch(s), Training loss(es)=[0.27985612 0.27525148 0.32536963 0.33732265 0.44318047]]Network training: 100%|███████████████████████████| 5/5 [03:26<00:00, 41.29s/epoch(s), Training loss(es)=[0.27985612 0.27525148 0.32536963 0.33732265 0.44318047]]
####################################################################
Starting training iteration 219.
Average action selection time:  0.28420753693580625
Rollout length:  1000
Rewards obtained: [10549.773607922463]
model train lenght 220000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:06<?, ?epoch(s)/s, Training loss(es)=[0.30820048 0.29947168 0.28731343 0.30410072 0.29334882]]Network training:  20%|█████▍                     | 1/5 [01:06<04:27, 66.79s/epoch(s), Training loss(es)=[0.30820048 0.29947168 0.28731343 0.30410072 0.29334882]]Network training:  20%|█████▏                    | 1/5 [02:06<08:24, 126.00s/epoch(s), Training loss(es)=[0.29507634 0.30561256 0.42836675 0.298977   0.28103283]]Network training:  40%|██████████▊                | 2/5 [02:06<03:09, 63.00s/epoch(s), Training loss(es)=[0.29507634 0.30561256 0.42836675 0.298977   0.28103283]]Network training:  40%|██████████▊                | 2/5 [02:33<03:49, 76.56s/epoch(s), Training loss(es)=[0.25299874 0.41708288 0.2772828  0.27261472 0.386689  ]]Network training:  60%|████████████████▏          | 3/5 [02:33<01:42, 51.04s/epoch(s), Training loss(es)=[0.25299874 0.41708288 0.2772828  0.27261472 0.386689  ]]Network training:  60%|████████████████▏          | 3/5 [03:01<02:01, 60.58s/epoch(s), Training loss(es)=[0.28021482 0.33478692 0.30244976 0.30162135 0.2706749 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:01<00:45, 45.43s/epoch(s), Training loss(es)=[0.28021482 0.33478692 0.30244976 0.30162135 0.2706749 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:30<00:52, 52.68s/epoch(s), Training loss(es)=[0.33420116 0.41904238 0.33069965 0.26698488 0.31811276]]Network training: 100%|███████████████████████████| 5/5 [03:30<00:00, 42.15s/epoch(s), Training loss(es)=[0.33420116 0.41904238 0.33069965 0.26698488 0.31811276]]
####################################################################
Starting training iteration 220.
Average action selection time:  0.2991078221797943
Rollout length:  1000
Rewards obtained: [6568.454476020248]
model train lenght 221000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:07<?, ?epoch(s)/s, Training loss(es)=[0.40726954 0.30903366 0.27207297 0.2919145  0.34867284]]Network training:  20%|█████▍                     | 1/5 [01:07<04:28, 67.10s/epoch(s), Training loss(es)=[0.40726954 0.30903366 0.27207297 0.2919145  0.34867284]]Network training:  20%|█████▏                    | 1/5 [01:55<07:42, 115.65s/epoch(s), Training loss(es)=[0.2841125  0.28111085 0.3231748  0.31110927 0.31226227]]Network training:  40%|██████████▊                | 2/5 [01:55<02:53, 57.83s/epoch(s), Training loss(es)=[0.2841125  0.28111085 0.3231748  0.31110927 0.31226227]]Network training:  40%|██████████▊                | 2/5 [02:21<03:32, 70.88s/epoch(s), Training loss(es)=[0.31583735 0.24391484 0.2694414  0.40024295 0.28790915]]Network training:  60%|████████████████▏          | 3/5 [02:21<01:34, 47.26s/epoch(s), Training loss(es)=[0.31583735 0.24391484 0.2694414  0.40024295 0.28790915]]Network training:  60%|████████████████▏          | 3/5 [02:49<01:52, 56.43s/epoch(s), Training loss(es)=[0.30727914 0.2567649  0.25714836 0.32134834 0.31938213]]Network training:  80%|█████████████████████▌     | 4/5 [02:49<00:42, 42.32s/epoch(s), Training loss(es)=[0.30727914 0.2567649  0.25714836 0.32134834 0.31938213]]Network training:  80%|█████████████████████▌     | 4/5 [03:14<00:48, 48.74s/epoch(s), Training loss(es)=[0.2563276  0.3264799  0.28867307 0.26912028 0.28908175]]Network training: 100%|███████████████████████████| 5/5 [03:14<00:00, 38.99s/epoch(s), Training loss(es)=[0.2563276  0.3264799  0.28867307 0.26912028 0.28908175]]
####################################################################
Starting training iteration 221.
Average action selection time:  0.4283301076889038
Rollout length:  1000
Rewards obtained: [12839.42395077759]
model train lenght 222000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:07<?, ?epoch(s)/s, Training loss(es)=[0.34635136 0.31599712 0.30841407 0.31247073 0.28548682]]Network training:  20%|█████▍                     | 1/5 [01:07<04:29, 67.42s/epoch(s), Training loss(es)=[0.34635136 0.31599712 0.30841407 0.31247073 0.28548682]]Network training:  20%|█████▏                    | 1/5 [01:56<07:46, 116.73s/epoch(s), Training loss(es)=[0.30368483 0.29592657 0.2680026  0.2801029  0.35940167]]Network training:  40%|██████████▊                | 2/5 [01:56<02:55, 58.37s/epoch(s), Training loss(es)=[0.30368483 0.29592657 0.2680026  0.2801029  0.35940167]]Network training:  40%|██████████▊                | 2/5 [02:26<03:39, 73.26s/epoch(s), Training loss(es)=[0.28458095 0.33506352 0.32264093 0.30462414 0.30321905]]Network training:  60%|████████████████▏          | 3/5 [02:26<01:37, 48.84s/epoch(s), Training loss(es)=[0.28458095 0.33506352 0.32264093 0.30462414 0.30321905]]Network training:  60%|████████████████▏          | 3/5 [02:56<01:57, 58.79s/epoch(s), Training loss(es)=[0.30181172 0.2839872  0.37900132 0.31380174 0.24295175]]Network training:  80%|█████████████████████▌     | 4/5 [02:56<00:44, 44.10s/epoch(s), Training loss(es)=[0.30181172 0.2839872  0.37900132 0.31380174 0.24295175]]Network training:  80%|█████████████████████▌     | 4/5 [03:26<00:51, 51.58s/epoch(s), Training loss(es)=[0.28121275 0.27625445 0.31768084 0.34840012 0.3432703 ]]Network training: 100%|███████████████████████████| 5/5 [03:26<00:00, 41.26s/epoch(s), Training loss(es)=[0.28121275 0.27625445 0.31768084 0.34840012 0.3432703 ]]
####################################################################
Starting training iteration 222.
Average action selection time:  0.330863507270813
Rollout length:  1000
Rewards obtained: [9323.542454445254]
model train lenght 223000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [01:04<?, ?epoch(s)/s, Training loss(es)=[0.2964334  0.26322764 0.34956872 0.25956875 0.35843384]]Network training:  20%|█████▍                     | 1/5 [01:04<04:17, 64.44s/epoch(s), Training loss(es)=[0.2964334  0.26322764 0.34956872 0.25956875 0.35843384]]Network training:  20%|█████▍                     | 1/5 [01:33<06:15, 93.90s/epoch(s), Training loss(es)=[0.31789878 0.28246725 0.31398764 0.26953495 0.3689829 ]]Network training:  40%|██████████▊                | 2/5 [01:33<02:20, 46.95s/epoch(s), Training loss(es)=[0.31789878 0.28246725 0.31398764 0.26953495 0.3689829 ]]Network training:  40%|██████████▊                | 2/5 [02:04<03:06, 62.00s/epoch(s), Training loss(es)=[0.26725692 0.30059347 0.31875893 0.28744018 0.31300387]]Network training:  60%|████████████████▏          | 3/5 [02:04<01:22, 41.34s/epoch(s), Training loss(es)=[0.26725692 0.30059347 0.31875893 0.28744018 0.31300387]]Network training:  60%|████████████████▏          | 3/5 [02:34<01:42, 51.37s/epoch(s), Training loss(es)=[0.29811683 0.28192955 0.3278712  0.28187722 0.31855863]]Network training:  80%|█████████████████████▌     | 4/5 [02:34<00:38, 38.53s/epoch(s), Training loss(es)=[0.29811683 0.28192955 0.3278712  0.28187722 0.31855863]]Network training:  80%|█████████████████████▌     | 4/5 [03:04<00:46, 46.07s/epoch(s), Training loss(es)=[0.3042082  0.2985525  0.35847992 0.259631   0.49653742]]Network training: 100%|███████████████████████████| 5/5 [03:04<00:00, 36.85s/epoch(s), Training loss(es)=[0.3042082  0.2985525  0.35847992 0.259631   0.49653742]]
####################################################################
Starting training iteration 223.
Average action selection time:  0.3550383434295654
Rollout length:  1000
Rewards obtained: [8717.749538983559]
model train lenght 224000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:47<?, ?epoch(s)/s, Training loss(es)=[0.2747139  0.28808105 0.31305814 0.3276486  0.3738899 ]]Network training:  20%|█████▍                     | 1/5 [00:47<03:10, 47.51s/epoch(s), Training loss(es)=[0.2747139  0.28808105 0.31305814 0.3276486  0.3738899 ]]Network training:  20%|█████▍                     | 1/5 [01:17<05:10, 77.72s/epoch(s), Training loss(es)=[0.3006082  0.2982599  0.32883993 0.2952703  0.27894717]]Network training:  40%|██████████▊                | 2/5 [01:17<01:56, 38.86s/epoch(s), Training loss(es)=[0.3006082  0.2982599  0.32883993 0.2952703  0.27894717]]Network training:  40%|██████████▊                | 2/5 [03:03<04:34, 91.55s/epoch(s), Training loss(es)=[0.37396017 0.29885158 0.27871442 0.2943273  0.28372   ]]Network training:  60%|████████████████▏          | 3/5 [03:03<02:02, 61.03s/epoch(s), Training loss(es)=[0.37396017 0.29885158 0.27871442 0.2943273  0.28372   ]]Network training:  60%|████████████████▏          | 3/5 [03:30<02:20, 70.02s/epoch(s), Training loss(es)=[0.2781195  0.34245968 0.28297243 0.27607957 0.3194509 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:30<00:52, 52.51s/epoch(s), Training loss(es)=[0.2781195  0.34245968 0.28297243 0.27607957 0.3194509 ]]Network training:  80%|█████████████████████▌     | 4/5 [03:56<00:59, 59.17s/epoch(s), Training loss(es)=[0.30909696 0.30452022 0.26607716 0.26234934 0.38511676]]Network training: 100%|███████████████████████████| 5/5 [03:56<00:00, 47.34s/epoch(s), Training loss(es)=[0.30909696 0.30452022 0.26607716 0.26234934 0.38511676]]
####################################################################
Starting training iteration 224.
Average action selection time:  0.346528666973114
Rollout length:  1000
Rewards obtained: [8313.007832526439]
model train lenght 225000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:54<?, ?epoch(s)/s, Training loss(es)=[0.3447465  0.29366758 0.28913254 0.27960265 0.31232607]]Network training:  20%|█████▍                     | 1/5 [00:54<03:37, 54.32s/epoch(s), Training loss(es)=[0.3447465  0.29366758 0.28913254 0.27960265 0.31232607]]Network training:  20%|█████▍                     | 1/5 [01:25<05:41, 85.30s/epoch(s), Training loss(es)=[0.28643638 0.28402176 0.29660958 0.28733978 0.30891448]]Network training:  40%|██████████▊                | 2/5 [01:25<02:07, 42.65s/epoch(s), Training loss(es)=[0.28643638 0.28402176 0.29660958 0.28733978 0.30891448]]Network training:  40%|██████████▊                | 2/5 [01:55<02:53, 57.71s/epoch(s), Training loss(es)=[0.30548128 0.294098   0.26879495 0.3064065  0.30354452]]Network training:  60%|████████████████▏          | 3/5 [01:55<01:16, 38.47s/epoch(s), Training loss(es)=[0.30548128 0.294098   0.26879495 0.3064065  0.30354452]]Network training:  60%|████████████████▏          | 3/5 [02:24<01:36, 48.15s/epoch(s), Training loss(es)=[0.29492655 0.33430916 0.27763435 0.26258117 0.28785577]]Network training:  80%|█████████████████████▌     | 4/5 [02:24<00:36, 36.11s/epoch(s), Training loss(es)=[0.29492655 0.33430916 0.27763435 0.26258117 0.28785577]]Network training:  80%|█████████████████████▌     | 4/5 [02:52<00:43, 43.03s/epoch(s), Training loss(es)=[0.2678438  0.2816835  0.30172777 0.30613917 0.2975041 ]]Network training: 100%|███████████████████████████| 5/5 [02:52<00:00, 34.43s/epoch(s), Training loss(es)=[0.2678438  0.2816835  0.30172777 0.30613917 0.2975041 ]]
####################################################################
Starting training iteration 225.
Average action selection time:  0.3686990191936493
Rollout length:  1000
Rewards obtained: [16914.618991819494]
model train lenght 226000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:39<?, ?epoch(s)/s, Training loss(es)=[0.2966153  0.31265205 0.3508895  0.278219   0.35134584]]Network training:  20%|█████▍                     | 1/5 [00:39<02:37, 39.29s/epoch(s), Training loss(es)=[0.2966153  0.31265205 0.3508895  0.278219   0.35134584]]Network training:  20%|█████▏                    | 1/5 [04:29<17:59, 269.84s/epoch(s), Training loss(es)=[0.3295829  0.3410598  0.29257655 0.29071417 0.33522427]]Network training:  40%|██████████▍               | 2/5 [04:29<06:44, 134.92s/epoch(s), Training loss(es)=[0.3295829  0.3410598  0.29257655 0.29071417 0.33522427]]Network training:  40%|██████████▍               | 2/5 [04:57<07:25, 148.55s/epoch(s), Training loss(es)=[0.27629736 0.29942814 0.32289764 0.29796427 0.31852764]]Network training:  60%|████████████████▏          | 3/5 [04:57<03:18, 99.03s/epoch(s), Training loss(es)=[0.27629736 0.29942814 0.32289764 0.29796427 0.31852764]]Network training:  60%|███████████████▌          | 3/5 [05:25<03:36, 108.48s/epoch(s), Training loss(es)=[0.27969083 0.3051795  0.28884396 0.33862916 0.30030996]]Network training:  80%|█████████████████████▌     | 4/5 [05:25<01:21, 81.36s/epoch(s), Training loss(es)=[0.27969083 0.3051795  0.28884396 0.33862916 0.30030996]]Network training:  80%|█████████████████████▌     | 4/5 [05:54<01:28, 88.59s/epoch(s), Training loss(es)=[0.29783374 0.28372976 0.36393583 0.37479275 0.3109987 ]]Network training: 100%|███████████████████████████| 5/5 [05:54<00:00, 70.87s/epoch(s), Training loss(es)=[0.29783374 0.28372976 0.36393583 0.37479275 0.3109987 ]]
####################################################################
Starting training iteration 226.
Average action selection time:  0.18456984710693358
Rollout length:  1000
Rewards obtained: [7212.534746592368]
model train lenght 227000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:28<?, ?epoch(s)/s, Training loss(es)=[0.3276817  0.2982201  0.3329385  0.36964628 0.33142495]]Network training:  20%|█████▍                     | 1/5 [00:28<01:52, 28.18s/epoch(s), Training loss(es)=[0.3276817  0.2982201  0.3329385  0.36964628 0.33142495]]Network training:  20%|█████▍                     | 1/5 [00:56<03:46, 56.58s/epoch(s), Training loss(es)=[0.32328925 0.28385225 0.29535633 0.29278886 0.3285802 ]]Network training:  40%|██████████▊                | 2/5 [00:56<01:24, 28.29s/epoch(s), Training loss(es)=[0.32328925 0.28385225 0.29535633 0.29278886 0.3285802 ]]Network training:  40%|██████████▊                | 2/5 [01:24<02:07, 42.33s/epoch(s), Training loss(es)=[0.27233353 0.3597127  0.28828856 0.30202198 0.29318517]]Network training:  60%|████████████████▏          | 3/5 [01:24<00:56, 28.22s/epoch(s), Training loss(es)=[0.27233353 0.3597127  0.28828856 0.30202198 0.29318517]]Network training:  60%|████████████████▏          | 3/5 [01:54<01:16, 38.02s/epoch(s), Training loss(es)=[0.27680796 0.3244996  0.34505883 0.32377934 0.34565458]]Network training:  80%|█████████████████████▌     | 4/5 [01:54<00:28, 28.51s/epoch(s), Training loss(es)=[0.27680796 0.3244996  0.34505883 0.32377934 0.34565458]]Network training:  80%|█████████████████████▌     | 4/5 [02:23<00:35, 35.77s/epoch(s), Training loss(es)=[0.36563668 0.3168388  0.29268542 0.3104612  0.309233  ]]Network training: 100%|███████████████████████████| 5/5 [02:23<00:00, 28.61s/epoch(s), Training loss(es)=[0.36563668 0.3168388  0.29268542 0.3104612  0.309233  ]]
####################################################################
Starting training iteration 227.
Average action selection time:  0.18389030075073243
Rollout length:  1000
Rewards obtained: [13281.711869439463]
model train lenght 228000
Network training:   0%|                                                                                                               | 0/5 [00:00<?, ?epoch(s)/s]Network training:   0%|                                   | 0/5 [00:27<?, ?epoch(s)/s, Training loss(es)=[0.33131847 0.2983502  0.33559218 0.30114383 0.30092284]]Network training:  20%|█████▍                     | 1/5 [00:27<01:51, 27.76s/epoch(s), Training loss(es)=[0.33131847 0.2983502  0.33559218 0.30114383 0.30092284]]Network training:  20%|█████▍                     | 1/5 [00:56<03:44, 56.02s/epoch(s), Training loss(es)=[0.28251952 0.27871537 0.25797364 0.32003862 0.28071412]]Network training:  40%|██████████▊                | 2/5 [00:56<01:24, 28.01s/epoch(s), Training loss(es)=[0.28251952 0.27871537 0.25797364 0.32003862 0.28071412]]Network training:  40%|██████████▊                | 2/5 [01:23<02:05, 41.93s/epoch(s), Training loss(es)=[0.34638783 0.27523637 0.3357081  0.31513703 0.3262639 ]]Network training:  60%|████████████████▏          | 3/5 [01:23<00:55, 27.95s/epoch(s), Training loss(es)=[0.34638783 0.27523637 0.3357081  0.31513703 0.3262639 ]]Network training:  60%|████████████████▏          | 3/5 [01:51<01:14, 37.30s/epoch(s), Training loss(es)=[0.28667626 0.32444414 0.35776836 0.32181415 0.32368204]]Network training:  80%|█████████████████████▌     | 4/5 [01:51<00:27, 27.98s/epoch(s), Training loss(es)=[0.28667626 0.32444414 0.35776836 0.32181415 0.32368204]]Network training:  80%|█████████████████████▌     | 4/5 [02:20<00:35, 35.20s/epoch(s), Training loss(es)=[0.2812796  0.2808821  0.3399567  0.26372832 0.27394825]]Network training: 100%|███████████████████████████| 5/5 [02:20<00:00, 28.16s/epoch(s), Training loss(es)=[0.2812796  0.2808821  0.3399567  0.26372832 0.27394825]]
####################################################################
Starting training iteration 228.
Killed
(pets2) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials[00m$ python scripts/mbexp.py -env halfcheetah -ca model-type PE -ca prop-type TSinf -ca opt-type CEM -logdir log//halfcheetah_PE_TSinf_CEM[A(pets2) [01;32mShenShuo@gpu-53[00m:[01;34m~/workspace/handful-of-trials[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccd ..onda activate pets2