{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/ShenShuo/miniconda3/envs/pets2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a\n"
     ]
    }
   ],
   "source": [
    "a = ''\n",
    "if a is None:\n",
    "    print(\"not None\")\n",
    "if not a :\n",
    "    print(\"not a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a[9:])\n",
    "print(a[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n",
      "  [1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]\n",
      "  [6]\n",
      "  [7]\n",
      "  [8]\n",
      "  [9]]]\n"
     ]
    }
   ],
   "source": [
    "print(a.reshape([1,10,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3) (4, 3, 2)\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[0 2 2]\n",
      " [0 2 2]\n",
      " [2 1 2]\n",
      " [1 1 2]]\n",
      "[[[0 1]\n",
      "  [4 5]\n",
      "  [4 5]]\n",
      "\n",
      " [[0 1]\n",
      "  [4 5]\n",
      "  [4 5]]\n",
      "\n",
      " [[4 5]\n",
      "  [2 3]\n",
      "  [4 5]]\n",
      "\n",
      " [[2 3]\n",
      "  [2 3]\n",
      "  [4 5]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(6).reshape(3,2)\n",
    "idxs = np.random.randint(a.shape[0], size=[4, a.shape[0]])\n",
    "print(idxs.shape, a[idxs].shape)\n",
    "print(a)\n",
    "print(idxs)\n",
    "print(a[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorStandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorStandardScaler:\n",
    "    \"\"\"Helper class for automatically normalizing inputs into the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_dim):\n",
    "        \"\"\"Initializes a scaler.\n",
    "\n",
    "        Arguments:\n",
    "        x_dim (int): The dimensionality of the inputs into the scaler.\n",
    "\n",
    "        Returns: None.\n",
    "        \"\"\"\n",
    "        self.fitted = False\n",
    "        with tf.variable_scope(\"Scaler\"):\n",
    "            self.mu = tf.get_variable(\n",
    "                name=\"scaler_mu\", shape=[1, x_dim], initializer=tf.constant_initializer(0.0),\n",
    "                trainable=False\n",
    "            )\n",
    "            self.sigma = tf.get_variable(\n",
    "                name=\"scaler_std\", shape=[1, x_dim], initializer=tf.constant_initializer(1.0),\n",
    "                trainable=False\n",
    "            )\n",
    "\n",
    "        self.cached_mu, self.cached_sigma = np.zeros([0, x_dim]), np.ones([1, x_dim])\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Runs two ops, one for assigning the mean of the data to the internal mean, and\n",
    "        another for assigning the standard deviation of the data to the internal standard deviation.\n",
    "        This function must be called within a 'with <session>.as_default()' block.\n",
    "\n",
    "        Arguments:\n",
    "        data (np.ndarray): A numpy array containing the input\n",
    "\n",
    "        Returns: None.\n",
    "        \"\"\"\n",
    "        mu = np.mean(data, axis=0, keepdims=True)\n",
    "        sigma = np.std(data, axis=0, keepdims=True)\n",
    "        sigma[sigma < 1e-12] = 1.0\n",
    "\n",
    "        # equal to tf.assign in tf2\n",
    "        self.mu.load(mu)\n",
    "        self.sigma.load(sigma)\n",
    "        self.fitted = True\n",
    "        self.cache()\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Transforms the input matrix data using the parameters of this scaler.\n",
    "\n",
    "        Arguments:\n",
    "        data (np.array): A numpy array containing the points to be transformed.\n",
    "\n",
    "        Returns: (np.array) The transformed dataset.\n",
    "        \"\"\"\n",
    "        return (data - self.mu) / self.sigma\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"Undoes the transformation performed by this scaler.\n",
    "\n",
    "        Arguments:\n",
    "        data (np.array): A numpy array containing the points to be transformed.\n",
    "\n",
    "        Returns: (np.array) The transformed dataset.\n",
    "        \"\"\"\n",
    "        return self.sigma * data + self.mu\n",
    "\n",
    "    def get_vars(self):\n",
    "        \"\"\"Returns a list of variables managed by this object.\n",
    "\n",
    "        Returns: (list<tf.Variable>) The list of variables.\n",
    "        \"\"\"\n",
    "        return [self.mu, self.sigma]\n",
    "\n",
    "    def cache(self):\n",
    "        \"\"\"Caches current values of this scaler.\n",
    "\n",
    "        Returns: None.\n",
    "        \"\"\"\n",
    "\n",
    "        # use a default session, return the value of this variable\n",
    "        self.cached_mu = self.mu.eval()\n",
    "        self.cached_sigma = self.sigma.eval()\n",
    "\n",
    "    def load_cache(self):\n",
    "        \"\"\"Loads values from the cache\n",
    "\n",
    "        Returns: None.\n",
    "        \"\"\"\n",
    "        self.mu.load(self.cached_mu)\n",
    "        self.sigma.load(self.cached_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]] [[1. 1. 1. 1.]]\n",
      "[[-1.2247448 -1.2247448 -1.2247448 -1.2247448]\n",
      " [ 0.         0.         0.         0.       ]\n",
      " [ 1.2247448  1.2247448  1.2247448  1.2247448]]\n",
      "[[4. 5. 6. 7.]] [[3.2659864 3.2659864 3.2659864 3.2659864]]\n"
     ]
    }
   ],
   "source": [
    "# scaler = TensorStandardScaler(4)\n",
    "data = np.arange(12).reshape(3,4)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # print(scaler.fitted)\n",
    "    # print(scaler.cached_mu, scaler.cached_sigma)\n",
    "    mu, var = sess.run(scaler.get_vars())\n",
    "    print(mu, var)\n",
    "    scaler.fit(data)\n",
    "    tran_data = sess.run(scaler.transform(data))\n",
    "    print(tran_data)\n",
    "    mu, var = sess.run(scaler.get_vars())\n",
    "    print(mu, var)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n",
      "(3, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "def shuffle_rows(arr):\n",
    "    idxs = np.argsort(np.random.uniform(size=arr.shape), axis=-1)\n",
    "    return arr[np.arange(arr.shape[0])[:, None], idxs]\n",
    "\n",
    "a = np.random.uniform(size=(3,3,3))\n",
    "b = a.shape\n",
    "print(b)\n",
    "a = shuffle_rows(a)\n",
    "c = a.shape\n",
    "print(c) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (3,1) (3,2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c4a332c5c003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (3,1) (3,2,2) "
     ]
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,2,2)\n",
    "print(a)\n",
    "idxs = a.argsort()\n",
    "b = a[np.array([0,1,2])[:,None], idxs]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function RandomState.randint>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint()\n",
    "np.random.permutation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC ._compile_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3) (2, 2, 1, 3) (2, 2, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# action seq\n",
    "a = np.arange(12).reshape(2,2,3)\n",
    "b = a[:, :, None]\n",
    "c = np.tile(b, [1, 1, 5, 1])\n",
    "print(a.shape, b.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3) (1, 4, 3)\n",
      "[[[0 1 2]\n",
      "  [3 4 5]]] \n",
      "\n",
      "[[[0 1 2]\n",
      "  [3 4 5]\n",
      "  [0 1 2]\n",
      "  [3 4 5]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# obs seq\n",
    "a = np.arange(6).reshape(2,3)[None]\n",
    "b = np.tile(a, [2, 1])\n",
    "print(a.shape, b.shape)\n",
    "print(a, \"\\n\")\n",
    "print(b, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98492837 0.15708661 0.30006194 0.57380354 0.5511217 ]\n",
      " [0.2919929  0.4022026  0.1956563  0.8473238  0.49093473]\n",
      " [0.87433267 0.7644963  0.6649406  0.49275243 0.86384547]\n",
      " [0.5642768  0.6708387  0.93194366 0.21606135 0.71665406]\n",
      " [0.1282978  0.01437759 0.50262654 0.32990038 0.5678843 ]\n",
      " [0.37182093 0.62550235 0.11662447 0.34997082 0.18829215]\n",
      " [0.57517385 0.47611594 0.70101523 0.22044003 0.3974806 ]\n",
      " [0.16406643 0.15351188 0.40816474 0.08074033 0.11120546]] \n",
      " [[0 3 4 2 1]\n",
      " [3 4 1 0 2]\n",
      " [0 4 1 2 3]\n",
      " [2 4 1 0 3]\n",
      " [4 2 3 0 1]\n",
      " [1 0 3 4 2]\n",
      " [2 0 1 4 3]\n",
      " [2 0 1 4 3]] \n",
      " (8, 5)\n"
     ]
    }
   ],
   "source": [
    "random_array = tf.random_uniform([8, 5])\n",
    "sort_idxs = tf.nn.top_k(\n",
    "    random_array,\n",
    "    k=5\n",
    ").indices\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    random_array, idx = sess.run([random_array, sort_idxs])\n",
    "print(random_array, \"\\n\",idx,  \"\\n\", idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 1)\n",
      "(8, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "tmp = tf.tile(tf.range(8)[:, None], [1, 5])[:, :, None]\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(tmp)\n",
    "print(result.shape)\n",
    "\n",
    "idxs = np.concatenate([result,idx[:,:,None]],axis=-1)\n",
    "print(idxs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def make_bool(arg):\n",
    "    if arg == \"False\" or arg == \"false\" or not bool(arg):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "print(make_bool('False'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "nsembled models must have more than one net.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-75e7acdb2396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_read_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nsembled models must have more than one net.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-75e7acdb2396>\u001b[0m in \u001b[0;36mread_only\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_read_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: nsembled models must have more than one net."
     ]
    }
   ],
   "source": [
    "def create_read_only(message):\n",
    "    def read_only(arg):\n",
    "        raise RuntimeError(message)\n",
    "    return read_only\n",
    "\n",
    "a = create_read_only(\"nsembled models must have more than one net.\")\n",
    "a(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "pop=2\n",
    "plan_hor=3\n",
    "dU = 4\n",
    "npart=2\n",
    "ac_seqs = tf.range(0, 24)\n",
    "ac_seqs = tf.reshape(ac_seqs,[2,3,4])\n",
    "print(ac_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 0  1  2  3]\n",
      "  [12 13 14 15]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[ 4  5  6  7]\n",
      "  [ 4  5  6  7]\n",
      "  [16 17 18 19]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[ 8  9 10 11]\n",
      "  [ 8  9 10 11]\n",
      "  [20 21 22 23]\n",
      "  [20 21 22 23]]], shape=(3, 4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ac_seqs1 = tf.reshape(tf.tile(\n",
    "    tf.transpose(ac_seqs, [1, 0, 2])[:, :, None],\n",
    "    [1, 1, npart, 1]\n",
    "), [plan_hor, -1, dU])\n",
    "print(ac_seqs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_seqs2 = tf.reshape(tf.tile(\n",
    "    tf.transpose(ac_seqs, [1, 0, 2])[:, :, None],\n",
    "    [1, 1, npart, 1]\n",
    "), [plan_hor, -1, dU])\n",
    "print(ac_seqs1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
